{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tqdm\n",
    "import xarray as xr\n",
    "import torch\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "from holodecml.models import load_model\n",
    "from holodecml.propagation import InferencePropagator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OGPropagator(InferencePropagator):\n",
    "    \n",
    "    def get_sub_images_labeled(self,\n",
    "                               image_tnsr,\n",
    "                               z_sub_set,\n",
    "                               z_counter,\n",
    "                               xp, yp, zp, dp,\n",
    "                               infocus_mask,\n",
    "                               z_part_bin_idx,\n",
    "                               batch_size=32,\n",
    "                               return_arrays=False,\n",
    "                               return_metrics=False,\n",
    "                               thresholds=None,\n",
    "                               obs_threshold=None):\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # build the torch tensor for reconstruction\n",
    "            z_plane = torch.tensor(\n",
    "                z_sub_set*1e-6, device=self.device).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "            # reconstruct the selected planes\n",
    "            E_out = self.torch_holo_set(image_tnsr, z_plane)\n",
    "\n",
    "            if self.color_dim == 2:\n",
    "                stacked_image = torch.cat([\n",
    "                    torch.abs(E_out).unsqueeze(1), torch.angle(E_out).unsqueeze(1)], 1)\n",
    "            elif self.color_dim == 1:\n",
    "                stacked_image = torch.abs(E_out).unsqueeze(1)\n",
    "            else:\n",
    "                raise OSError(f\"Unrecognized color dimension {self.color_dim}\")\n",
    "            stacked_image = self.apply_transforms(\n",
    "                stacked_image.squeeze(0)).unsqueeze(0)\n",
    "\n",
    "            size = (E_out.shape[1], E_out.shape[2])\n",
    "            true_output = torch.zeros(size).to(self.device)\n",
    "            pred_proba = torch.zeros(size).to(self.device)\n",
    "            counter = torch.zeros(size).to(self.device)\n",
    "\n",
    "            chunked = np.array_split(\n",
    "                list(self.idx2slice.items()),\n",
    "                int(np.ceil(len(self.idx2slice) / batch_size))\n",
    "            )\n",
    "\n",
    "            inputs, masks, preds = [], [], []\n",
    "            for z_idx in range(E_out.shape[0]):\n",
    "\n",
    "                unet_mask = torch.zeros(E_out.shape[1:]).to(\n",
    "                    self.device)  # initialize the UNET mask\n",
    "                # locate all particles in this plane\n",
    "                part_in_plane_idx = np.where(\n",
    "                    z_part_bin_idx == z_idx+z_counter)[0]\n",
    "\n",
    "                # build the UNET mask for this z plane\n",
    "                for part_idx in part_in_plane_idx:\n",
    "                    unet_mask += torch.from_numpy(\n",
    "                        (self.y_arr[None, :]*1e6-yp[part_idx])**2 +\n",
    "                        (self.x_arr[:, None]*1e6-xp[part_idx]\n",
    "                         )**2 < (dp[part_idx]/2)**2\n",
    "                    ).float().to(self.device)\n",
    "\n",
    "                worker = partial(\n",
    "                    self.collate_masks,\n",
    "                    image=stacked_image[z_idx, :].float(),\n",
    "                    mask=unet_mask\n",
    "                )\n",
    "\n",
    "                for chunk in chunked:\n",
    "                    slices, x, true_mask_tile = worker(chunk)\n",
    "                    pred_proba_tile = self.model(x).squeeze(1)\n",
    "\n",
    "                    for k, ((row_idx, col_idx), (row_slice, col_slice)) in enumerate(slices):\n",
    "                        counter[row_slice, col_slice] += 1\n",
    "                        true_output[row_slice,\n",
    "                                    col_slice] += true_mask_tile[k]\n",
    "                        pred_proba[row_slice,\n",
    "                                   col_slice] += pred_proba_tile[k]\n",
    "            \n",
    "                #print(pred_proba)\n",
    "                                \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPropagator(InferencePropagator):\n",
    "    \n",
    "    def get_sub_images_labeled(self,\n",
    "                               image_tnsr,\n",
    "                               z_sub_set,\n",
    "                               z_counter,\n",
    "                               xp, yp, zp, dp,\n",
    "                               infocus_mask,\n",
    "                               z_part_bin_idx,\n",
    "                               batch_size=32,\n",
    "                               return_arrays=False,\n",
    "                               return_metrics=False,\n",
    "                               thresholds=None,\n",
    "                               obs_threshold=None):\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # build the torch tensor for reconstruction\n",
    "            z_plane = torch.tensor(\n",
    "                z_sub_set*1e-6, device=self.device).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "            # reconstruct the selected planes\n",
    "            E_out = self.torch_holo_set(image_tnsr, z_plane)\n",
    "\n",
    "            if self.color_dim == 2:\n",
    "                image = torch.cat([\n",
    "                    torch.abs(E_out).unsqueeze(1), torch.angle(E_out).unsqueeze(1)], 1)\n",
    "            elif self.color_dim == 1:\n",
    "                image = torch.abs(E_out).unsqueeze(1)\n",
    "            else:\n",
    "                raise OSError(f\"Unrecognized color dimension {self.color_dim}\")\n",
    "            stacked_image = self.apply_transforms(\n",
    "                image.squeeze(0)).unsqueeze(0)\n",
    "\n",
    "            size = (E_out.shape[1], E_out.shape[2])\n",
    "            for z_idx in range(E_out.shape[0]):\n",
    "\n",
    "                unet_mask = torch.zeros(E_out.shape[1:]).to(\n",
    "                    self.device)  # initialize the UNET mask\n",
    "                # locate all particles in this plane\n",
    "                part_in_plane_idx = np.where(\n",
    "                    z_part_bin_idx == z_idx+z_counter)[0]\n",
    "\n",
    "                # build the UNET mask for this z plane\n",
    "                for part_idx in part_in_plane_idx:\n",
    "                    unet_mask += torch.from_numpy(\n",
    "                        (self.y_arr[None, :]*1e6-yp[part_idx])**2 +\n",
    "                        (self.x_arr[:, None]*1e6-xp[part_idx]\n",
    "                         )**2 < (dp[part_idx]/2)**2\n",
    "                    ).float().to(self.device)\n",
    "                    \n",
    "                # Calculate the expected number of tiles\n",
    "                Nx_tile = self.Nx//self.step_size\n",
    "                Ny_tile = self.Ny//self.step_size\n",
    "\n",
    "                # For a complex field E_out, this generalizes the functional \n",
    "                # operations that define the color channels\n",
    "                # the result E_out_tile has dimensions\n",
    "                # (z, tile, color, x, y)\n",
    "                \n",
    "                \n",
    "                func_lst = [torch.abs, torch.angle]\n",
    "                image = torch.stack([\n",
    "                    F.unfold(fnc(image), (self.tile_size, self.tile_size), stride=self.step_size).permute(1,2,0).reshape(\n",
    "                        self.tile_size, self.tile_size, image.shape[0], -1) for fnc in func_lst\n",
    "                ], dim = -1).permute(2,3,4,0,1).squeeze(0)[:, 0:1, :, :]\n",
    "                \n",
    "                # Make mask tiles\n",
    "#                 mask_tile = F.unfold(\n",
    "#                     unet_mask.unsqueeze(0).unsqueeze(0), \n",
    "#                     (self.tile_size, self.tile_size), \n",
    "#                     stride=self.step_size\n",
    "#                 )\n",
    "#                 mask_tile = mask_tile.reshape(\n",
    "#                     mask_tile.shape[2], self.tile_size, self.tile_size\n",
    "#                 )\n",
    "                \n",
    "                # predict then fold the predictions back into full size         \n",
    "                pred_masks = torch.cat([\n",
    "                    self.model(tile.float())\n",
    "                    for tile in np.array_split(image, image.shape[0] // batch_size)\n",
    "                ], axis = 0)\n",
    "                # (no tiles, 1, tile size, tile size\n",
    "\n",
    "                pred_masks = pred_masks.permute(2,3,0,1).reshape(\n",
    "                    self.tile_size*self.tile_size, pred_masks.shape[1], pred_masks.shape[0]\n",
    "                ).permute(1, 0, 2)\n",
    "                # (1, tile size * tile size, no of tiles)\n",
    "                \n",
    "                pred_masks = F.fold(pred_masks,\n",
    "                    output_size = (Nx_tile*self.step_size, Ny_tile*self.step_size), \n",
    "                    kernel_size = self.tile_size, \n",
    "                    stride = self.step_size\n",
    "                )\n",
    "                # (1, 1, 4864, 3200)\n",
    "                #print(pred_masks)\n",
    "                \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\") if not is_cuda else torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_name = \"../config/model_segmentation.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_name) as cf:\n",
    "    conf = yaml.load(cf, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = conf[\"seed\"]\n",
    "n_bins = conf[\"data\"][\"n_bins\"]\n",
    "tile_size = conf[\"data\"][\"tile_size\"]\n",
    "step_size = conf[\"data\"][\"step_size\"]\n",
    "marker_size = conf[\"data\"][\"marker_size\"]\n",
    "total_positive = int(conf[\"data\"][\"total_positive\"])\n",
    "total_negative = int(conf[\"data\"][\"total_negative\"])\n",
    "total_examples = int(conf[\"data\"][\"total_training\"])\n",
    "\n",
    "# Do not load the image transformations\n",
    "transform_mode = \"None\"\n",
    "tile_transforms = None\n",
    "color_dim = conf[\"model\"][\"in_channels\"]\n",
    "batch_size = conf[\"inference\"][\"batch_size\"]\n",
    "inference_mode = conf[\"inference\"][\"mode\"]\n",
    "\n",
    "name_tag = f\"{tile_size}_{step_size}_{total_positive}_{total_negative}_{total_examples}_{transform_mode}\"\n",
    "\n",
    "# Load the model\n",
    "model = load_model(conf[\"model\"]).to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = conf[\"style\"][\"raw\"][\"path\"]\n",
    "#holograms_per_dataset = style_conf[\"data\"][\"raw\"][\"holograms_per_dataset\"]\n",
    "tiles_per_reconstruction = conf[\"style\"][\"raw\"][\"tiles_per_reconstruction\"]\n",
    "reconstruction_per_hologram = conf[\"style\"][\"raw\"][\"reconstruction_per_hologram\"]\n",
    "save_path = conf[\"style\"][\"raw\"][\"save_path\"]\n",
    "sampler = conf[\"style\"][\"raw\"][\"sampler\"]\n",
    "name_tag = f\"{sampler}_{name_tag}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = CustomPropagator(\n",
    "    data_set,\n",
    "    n_bins=n_bins,\n",
    "    color_dim=color_dim,\n",
    "    tile_size=tile_size,\n",
    "    step_size=step_size,\n",
    "    marker_size=marker_size,\n",
    "    transform_mode=transform_mode,\n",
    "    device=device,\n",
    "    model=model,\n",
    "    mode=inference_mode,\n",
    "    probability_threshold=0.5,\n",
    "    transforms=tile_transforms\n",
    ")\n",
    "\n",
    "og_prop = OGPropagator(\n",
    "    data_set,\n",
    "    n_bins=n_bins,\n",
    "    color_dim=color_dim,\n",
    "    tile_size=tile_size,\n",
    "    step_size=step_size,\n",
    "    marker_size=marker_size,\n",
    "    transform_mode=transform_mode,\n",
    "    device=device,\n",
    "    model=model,\n",
    "    mode=inference_mode,\n",
    "    probability_threshold=0.5,\n",
    "    transforms=tile_transforms\n",
    ")\n",
    "\n",
    "# Create a list of z-values to propagate to\n",
    "z_list = prop.create_z_plane_lst(planes_per_call=1)\n",
    "random.shuffle(z_list)\n",
    "z_list = z_list[:reconstruction_per_hologram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_range = prop.h_ds.hologram_number.values\n",
    "h_range_prime = list(set(h_range) - set(range(10, 20)))\n",
    "\n",
    "# split into train/test/valid\n",
    "h_train, rest_data = train_test_split(h_range_prime, train_size=0.8)\n",
    "h_valid, h_test = train_test_split(rest_data, test_size=0.45)\n",
    "h_test += list(range(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.23858022689819\n",
      "55.917946100234985\n"
     ]
    }
   ],
   "source": [
    "h_splits = [h_train, h_valid, h_test]\n",
    "split_names = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "for split, h_split in zip(split_names, h_splits):\n",
    "\n",
    "    total = len(h_split) * tiles_per_reconstruction * reconstruction_per_hologram\n",
    "    X = np.zeros((total, 512, 512))\n",
    "    Y = np.zeros((total, 1))\n",
    "\n",
    "    c = 0\n",
    "    # Main loop to call the generator, predict with the model, and aggregate and save the results\n",
    "    for nc, h_idx in enumerate(h_split):\n",
    "        \n",
    "        # Create a list of z-values to propagate to\n",
    "        z_list = prop.create_z_plane_lst(planes_per_call=1)\n",
    "        random.shuffle(z_list)\n",
    "        z_list = z_list[:reconstruction_per_hologram]\n",
    "        \n",
    "        planes_processed = n_bins\n",
    "        inference_generator = prop.get_next_z_planes_labeled(\n",
    "            h_idx,\n",
    "            z_list,\n",
    "            batch_size=batch_size,\n",
    "            thresholds=[0.5],\n",
    "            return_arrays=False,\n",
    "            return_metrics=False,\n",
    "            obs_threshold=0.5,\n",
    "            start_z_counter=planes_processed\n",
    "        )\n",
    "\n",
    "        t0 = time.time()\n",
    "        count = 0\n",
    "        for z_idx, results_dict in enumerate(inference_generator):\n",
    "            count += 1 \n",
    "            if count == 10:\n",
    "                break\n",
    "        print(time.time() - t0)\n",
    "            \n",
    "            \n",
    "        inference_generator = og_prop.get_next_z_planes_labeled(\n",
    "            h_idx,\n",
    "            z_list,\n",
    "            batch_size=batch_size,\n",
    "            thresholds=[0.5],\n",
    "            return_arrays=False,\n",
    "            return_metrics=False,\n",
    "            obs_threshold=0.5,\n",
    "            start_z_counter=n_bins\n",
    "        )\n",
    "        \n",
    "        t0 = time.time()\n",
    "        count = 0\n",
    "        for z_idx, results_dict in enumerate(inference_generator):\n",
    "            count += 1 \n",
    "            if count == 10:\n",
    "                break\n",
    "           \n",
    "        print(time.time() - t0)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "del prop\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holodec",
   "language": "python",
   "name": "holodec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
