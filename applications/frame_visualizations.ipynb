{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a575b36-2617-47bf-b025-1f523a5f6436",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28e4f0-d7a3-4878-b3bf-4e8e3190d9dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Libraries, Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff86707-cc39-4df1-a6b2-edef5cca34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import xarray as xr\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from holodecml.transforms import LoadTransformations\n",
    "from echo.src.base_objective import BaseObjective\n",
    "\n",
    "# from holodecml.seed import seed_everything\n",
    "from holodecml.data import XarrayReader\n",
    "from holodecml.models import load_model\n",
    "from holodecml.losses import load_loss\n",
    "\n",
    "from collections import defaultdict\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import torch.fft\n",
    "import logging\n",
    "import shutil\n",
    "import random\n",
    "import psutil\n",
    "import optuna\n",
    "import torch\n",
    "import time\n",
    "import tqdm\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import yaml\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e329c8d7-b121-4f59-88d2-2857deac148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0677629-00c3-4278-b01f-0d5c83c0af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "print(is_cuda)\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")\n",
    "print(device)\n",
    "if is_cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    #torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00601ee-f398-4e16-b6f5-396c7a1b4d43",
   "metadata": {},
   "source": [
    "### Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196a54d2-b374-4ac0-8e66-d8914c2145da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_training.nc\"\n",
    "test_dataset_path = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_validation.nc\"\n",
    "\n",
    "conf_file_path = \"../results/batch7/model.yml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44639ef1-df3c-49b9-b91a-3a2528054548",
   "metadata": {},
   "source": [
    "### Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d621df-5574-41c2-9041-a0c1c31bc06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29c76903-9f83-4e98-9db5-fd320e2c0020",
   "metadata": {},
   "source": [
    "### Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ca7777-4ea8-4eb4-93fb-81ea40d14ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavePropagator(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 n_bins=1000,\n",
    "                 step_size=128,\n",
    "                 tile_size = 128,\n",
    "                 marker_size=10,\n",
    "                 transform_mode=None,\n",
    "                 device=\"cpu\"):\n",
    "\n",
    "        self.h_ds = xr.open_dataset(data_path)\n",
    "\n",
    "\n",
    "        if 'zMin' in self.h_ds.attrs:\n",
    "            self.zMin = self.h_ds.attrs['zMin']  # minimum z in sample volume\n",
    "            self.zMax = self.h_ds.attrs['zMax']\n",
    "        else:  # some of the raw data does not have this parameter\n",
    "            # should warn the user here through the logger\n",
    "            self.zMin = 0.014\n",
    "            self.zMax = 0.158 #15.8 - 1.4 / (1000)\n",
    "\n",
    "        self.n_bins = n_bins\n",
    "        self.z_bins = np.linspace(\n",
    "            self.zMin, self.zMax, n_bins+1)*1e6  # histogram bin edges\n",
    "        self.z_centers = self.z_bins[:-1] + 0.5 * \\\n",
    "            np.diff(self.z_bins)  # histogram bin center\n",
    "        \n",
    "        self.tile_size = tile_size\n",
    "        self.step_size = step_size\n",
    "        \n",
    "        # UNET gaussian marker width (standard deviation) in um\n",
    "        self.marker_size = marker_size\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "        self.dx = self.h_ds.attrs['dx']      # horizontal resolution\n",
    "        self.dy = self.h_ds.attrs['dy']      # vertical resolution\n",
    "        self.Nx = int(self.h_ds.attrs['Nx'])  # number of horizontal pixels\n",
    "        self.Ny = int(self.h_ds.attrs['Ny'])  # number of vertical pixels\n",
    "        self.lam = self.h_ds.attrs['lambda']  # wavelength\n",
    "        self.image_norm = 255.0\n",
    "        self.transform_mode = transform_mode\n",
    "        self.x_arr = np.arange(-self.Nx//2, self.Nx//2)*self.dx\n",
    "        self.y_arr = np.arange(-self.Ny//2, self.Ny//2)*self.dy\n",
    "\n",
    "        self.tile_x_bins = np.arange(-self.Nx//2,\n",
    "                                     self.Nx//2, self.step_size)*self.dx*1e6\n",
    "        self.tile_y_bins = np.arange(-self.Ny//2,\n",
    "                                     self.Ny//2, self.step_size)*self.dy*1e6\n",
    "\n",
    "        self.fx = torch.fft.fftfreq(\n",
    "            self.Nx, self.dx, device=self.device).unsqueeze(0).unsqueeze(2)\n",
    "        self.fy = torch.fft.fftfreq(\n",
    "            self.Ny, self.dy, device=self.device).unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        \n",
    "        self.create_mapping()\n",
    "    def torch_holo_set(self,\n",
    "                       Ein: torch.tensor,\n",
    "                       z_tnsr: torch.tensor):\n",
    "        \"\"\"\n",
    "        Propagates an electric field a distance z\n",
    "        Ein complex torch.tensor\n",
    "        - input electric field\n",
    "\n",
    "        fx:real torch.tensor\n",
    "        - x frequency axis (3D, setup to broadcast)\n",
    "\n",
    "        fy: real torch.tensor\n",
    "        - y frequency axis (3D, setup to broadcast)\n",
    "\n",
    "        z_tnsr: torch.tensor\n",
    "        - tensor of distances to propagate the wave Ein\n",
    "            expected to have dims (Nz,1,1) where Nz is the number of z\n",
    "            dimensions\n",
    "\n",
    "        lam: float\n",
    "        - wavelength\n",
    "\n",
    "        returns: complex torch.tensor with dims (Nz,fy,fx)\n",
    "\n",
    "        Note the torch.fft library uses dtype=torch.complex64\n",
    "        This may be an issue for GPU implementation\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.transform_mode == \"standard\":\n",
    "            Ein = Ein.float()\n",
    "            Ein -= torch.mean(Ein)\n",
    "            Ein /= torch.std(Ein)\n",
    "\n",
    "        elif self.transform_mode == \"min-max\":\n",
    "            Ein = Ein.float()\n",
    "            Ein -= torch.min(Ein)\n",
    "            Ein /= torch.max(Ein)\n",
    "\n",
    "        Etfft = torch.fft.fft2(Ein)\n",
    "        Eofft = Etfft*torch.exp(1j*2*np.pi*z_tnsr/self.lam *\n",
    "                                torch.sqrt(1-self.lam**2*(self.fx**2+self.fy**2)))\n",
    "\n",
    "        # It might be helpful if we could omit this step.  It would save an inverse fft.\n",
    "        Eout = torch.fft.ifft2(Eofft)\n",
    "        return Eout\n",
    "    \n",
    "    \n",
    "    def create_mapping(self):\n",
    "        \"\"\"\n",
    "        Create map from tile coordinates (x,y) to indices to slice in image to extract that tile. \n",
    "        \"\"\"\n",
    "        self.idx2slice = {}\n",
    "        for row_idx in range(self.Nx//self.step_size):\n",
    "\n",
    "            if row_idx*self.step_size+self.tile_size > self.Nx:\n",
    "                image_pixel_x = self.Nx-self.tile_size\n",
    "                row_slice = slice(-self.tile_size, None)\n",
    "                row_break = True\n",
    "            else:\n",
    "                image_pixel_x = row_idx*self.step_size\n",
    "                row_slice = slice(row_idx*self.step_size,\n",
    "                                  row_idx*self.step_size+self.tile_size)\n",
    "                row_break = False\n",
    "\n",
    "            for col_idx in range(self.Ny//self.step_size):\n",
    "\n",
    "                if col_idx*self.step_size+self.tile_size > self.Ny:\n",
    "                    image_pixel_y = self.Ny-self.tile_size\n",
    "                    col_slice = slice(-self.tile_size, None)\n",
    "                    col_break = True\n",
    "                else:\n",
    "                    image_pixel_y = col_idx*self.step_size\n",
    "                    col_slice = slice(col_idx*self.step_size,\n",
    "                                      col_idx*self.step_size+self.tile_size)\n",
    "                    col_break = False\n",
    "\n",
    "                self.idx2slice[row_idx, col_idx] = (row_slice, col_slice)\n",
    "\n",
    "                if col_break:\n",
    "                    break\n",
    "\n",
    "            if row_break:\n",
    "                break\n",
    "                \n",
    "                \n",
    "                \n",
    "    def collate_image(self, idx_dict, image = None, mask = None):\n",
    "        x, y = zip(*[(image[:, row_slice, col_slice], mask[row_slice, col_slice]) for ((row_idx, col_idx, row_slice, col_slice)) in idx_dict])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff1fb22-8b00-4ec2-a664-a1386d55c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(prop, h_idx, z_idx, z_ref):\n",
    "\n",
    "    hid = h_idx + 1\n",
    "    hid_mask = prop.h_ds[\"hid\"] == hid\n",
    "\n",
    "    # Filter particles based on h_idx\n",
    "    x_part = prop.h_ds[\"x\"].values[hid_mask]\n",
    "    y_part = prop.h_ds[\"y\"].values[hid_mask]\n",
    "    z_part = prop.h_ds[\"z\"].values[hid_mask]\n",
    "    d_part = prop.h_ds[\"d\"].values[hid_mask]\n",
    "\n",
    "    z_indices = np.digitize(z_part, prop.z_bins) - 1\n",
    "    # Initialize the UNET mask\n",
    "    unet_mask = np.zeros((prop.x_arr.shape[0], prop.y_arr.shape[0]))\n",
    "    z_mask = np.zeros((prop.x_arr.shape[0], prop.y_arr.shape[0]))\n",
    "    num_particles = 0 \n",
    "    \n",
    "    if z_idx in z_indices:\n",
    "        cond = np.where(z_idx == z_indices)\n",
    "        x_part = x_part[cond]\n",
    "        y_part = y_part[cond]\n",
    "        z_part = z_part[cond]\n",
    "        d_part = d_part[cond]\n",
    "        \n",
    "        #print(x_part, y_part, z_part, d_part)\n",
    "        \n",
    "        # Build the UNET mask using vectorized operations\n",
    "        for part_idx in range(len(cond[0])):\n",
    "            y_diff = (prop.y_arr[None, :] * 1e6 - y_part[part_idx])\n",
    "            x_diff = (prop.x_arr[:, None] * 1e6 - x_part[part_idx])\n",
    "            d_squared = (d_part[part_idx] / 2)**2\n",
    "            unet_mask += ((y_diff**2 + x_diff**2) < d_squared).astype(float)\n",
    "            z_diff = (z_part - z_ref)\n",
    "            for particle in z_diff:\n",
    "                z_mask += ((y_diff**2 + x_diff**2) < d_squared).astype(float) * particle\n",
    "                num_particles += 1\n",
    "\n",
    "    return torch.from_numpy(unet_mask).unsqueeze(0), num_particles, torch.from_numpy(z_mask).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6738f6a7-9c81-490e-8368-a733aaebc758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadHolograms(Dataset):\n",
    "    \n",
    "    def __init__(self, file_path, n_bins = 1000, shuffle = False, device = \"cpu\", transform = False, lookahead =0, step_size = 32, tile_size = 32):\n",
    "        \n",
    "        # num of waveprop windows\n",
    "        self.n_bins = n_bins\n",
    "        # device used\n",
    "        self.device = device\n",
    "        # shuffle frames\n",
    "        self.shuffle = shuffle\n",
    "        # num of frames to look ahead\n",
    "        self.lookahead = lookahead\n",
    "        # wavepropagator object on device\n",
    "        self.propagator = WavePropagator(file_path, n_bins = n_bins, device = device, step_size = step_size, tile_size = tile_size)\n",
    "        self.transform = transform\n",
    "        self.indices =  [(x,y) for x in self.propagator.h_ds.hologram_number for y in range(self.n_bins - self.lookahead)]\n",
    "        \n",
    "        self.tile_size = tile_size\n",
    "        self.idx2slice = self.propagator.idx2slice\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) * len(self.idx2slice)\n",
    "\n",
    "    # idx = tile index\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.shuffle:\n",
    "            idx = random.choice(range(self.__len__()))\n",
    "            \n",
    "        #hologram_idx = idx // self.n_bins \n",
    "        #plane_idx = idx // len(self.propagator.h_ds.hologram_number)\n",
    "        hologram_idx, plane_idx = self.indices[(idx) // len(self.idx2slice)]\n",
    "        z_props = self.propagator.z_centers[plane_idx: plane_idx + self.lookahead + 1]\n",
    "        #z_props -= (z_props[1] - z_props[0]) / 2\n",
    "        plane_indices = np.arange(plane_idx, plane_idx + self.lookahead + 1)\n",
    "        # select hologram\n",
    "        image = self.propagator.h_ds[\"image\"].isel(hologram_number=hologram_idx).values\n",
    "        \n",
    "        im = {\n",
    "            \"image\": np.expand_dims(image, 0),\n",
    "            \"horizontal_flip\": False,\n",
    "            \"vertical_flip\": False\n",
    "        }\n",
    "\n",
    "        # add transformations here\n",
    "        if self.transform:\n",
    "            for image_transform in self.transform:\n",
    "                im = image_transform(im)\n",
    "        image = im[\"image\"]\n",
    "        \n",
    "        # Update the mask if we flipped the original image\n",
    "        \n",
    "        \n",
    "        # prop\n",
    "        \n",
    "        # make tensors of size lookahead + 1, and then add tensors\n",
    "        prop_synths = []\n",
    "        prop_phases = []\n",
    "        masks = []\n",
    "        z_masks = []\n",
    "        particles_in_frames = []\n",
    "        \n",
    "        #num_frames = len(plane_indices)\n",
    "        #idx_ran = random.choice(range(num_frames))\n",
    "        #z_prop = z_props[idx_ran]\n",
    "        #z_ind = plane_indices[idx_ran]\n",
    "        \n",
    "        for k, (z_prop, z_ind) in enumerate(zip(z_props, plane_indices)):\n",
    "            image_prop = self.propagator.torch_holo_set(\n",
    "                image.to(self.device),\n",
    "                torch.FloatTensor([z_prop*1e-6]).to(self.device)\n",
    "            )\n",
    "            # ABS (x-input)\n",
    "            prop_synth = torch.abs(image_prop)\n",
    "            prop_synths.append(prop_synth)\n",
    "            # Phase (x-input)\n",
    "            prop_phase = torch.angle(image_prop)\n",
    "            prop_phases.append(prop_phase)  \n",
    "            # Mask (y-label)\n",
    "            if k == 0:\n",
    "                mask, num_particles, z_mask = create_mask(self.propagator, hologram_idx, z_ind, z_prop)\n",
    "                if im[\"horizontal_flip\"]:\n",
    "                    mask = torch.flip(mask, dims=(1,))\n",
    "                    z_mask = torch.flip(z_mask, dims= (1,))\n",
    "                if im[\"vertical_flip\"]:\n",
    "                    mask = torch.flip(mask, dims=(2,))\n",
    "                    z_mask = torch.flip(z_mask, dims= (2,))\n",
    "                masks.append(mask)\n",
    "                z_masks.append(z_mask)\n",
    "\n",
    "        \n",
    "        \n",
    "        # cat target frames with lookahead context frames, convert to ndarrays\n",
    "        synth_window = torch.cat(prop_synths, dim = 0)\n",
    "        phases_window = torch.cat(prop_phases, dim = 0)\n",
    "        masks_window = torch.cat(masks, dim = 0)\n",
    "        z_masks_window = torch.cat(z_masks, dim = 0)\n",
    "        z_masks_window /= (z_props[-1] - z_props[0])\n",
    "        \n",
    "        # cat images and masks in color dim (0 since batch not added yet)\n",
    "        image_stack = torch.cat([synth_window, phases_window], dim = 0)\n",
    "        \"\"\"\n",
    "        masks_stack = torch.cat([masks_window, z_masks_window], dim = 0)\n",
    "        \"\"\"\n",
    "        masks_stack = torch.cat([masks_window], dim = 0)\n",
    "        \n",
    "        #get tiles, slicing along coords in idx2slice array that maps coord position to slice range\n",
    "        slice_coords = self.idx2slice[list(self.idx2slice)[idx % len(self.idx2slice)]]\n",
    "        image_stack = image_stack[:, slice_coords[0], slice_coords[1]]\n",
    "        masks_stack = masks_stack[:, slice_coords[0], slice_coords[1]]\n",
    "        \n",
    "        return (image_stack, masks_stack)\n",
    "    \n",
    "    def get_full_plane(self, h_idx, z_idx_list, device = \"cpu\"):\n",
    "        if self.shuffle:\n",
    "            idx = random.choice(range(self.__len__()))\n",
    "            \n",
    "        hologram_idx= h_idx\n",
    "        \n",
    "        image = self.propagator.h_ds[\"image\"].isel(hologram_number=hologram_idx).values\n",
    "        \n",
    "        im = {\n",
    "                \"image\": np.expand_dims(image, 0),\n",
    "                \"horizontal_flip\": False,\n",
    "                \"vertical_flip\": False\n",
    "            }\n",
    "\n",
    "        # add transformations here\n",
    "        if self.transform:\n",
    "            for image_transform in self.transform:\n",
    "                im = image_transform(im)\n",
    "        image = im[\"image\"]\n",
    "            \n",
    "            \n",
    "        for plane_idx in z_idx_list:\n",
    "            \n",
    "            z_props = self.propagator.z_centers[plane_idx: plane_idx + self.lookahead + 1]\n",
    "            #z_props -= (z_props[1] - z_props[0]) / 2\n",
    "            plane_indices = np.arange(plane_idx, plane_idx + self.lookahead + 1)\n",
    "            # select hologram\n",
    "\n",
    "           \n",
    "\n",
    "            # Update the mask if we flipped the original image\n",
    "\n",
    "\n",
    "            # prop\n",
    "\n",
    "            # make tensors of size lookahead + 1, and then add tensors\n",
    "            prop_synths = []\n",
    "            prop_phases = []\n",
    "            masks = []\n",
    "            z_masks = []\n",
    "            particles_in_frames = []\n",
    "\n",
    "            #num_frames = len(plane_indices)\n",
    "            #idx_ran = random.choice(range(num_frames))\n",
    "            #z_prop = z_props[idx_ran]\n",
    "            #z_ind = plane_indices[idx_ran]\n",
    "\n",
    "            for k, (z_prop, z_ind) in enumerate(zip(z_props, plane_indices)):\n",
    "                image_prop = self.propagator.torch_holo_set(\n",
    "                    image.to(device),\n",
    "                    torch.FloatTensor([z_prop*1e-6]).to(device)\n",
    "                )\n",
    "                # ABS (x-input)\n",
    "                prop_synth = torch.abs(image_prop)\n",
    "                prop_synths.append(prop_synth)\n",
    "                # Phase (x-input)\n",
    "                prop_phase = torch.angle(image_prop)\n",
    "                prop_phases.append(prop_phase)  \n",
    "                # Mask (y-label)\n",
    "                if k == 0:\n",
    "                    mask, num_particles, z_mask = create_mask(self.propagator, hologram_idx, z_ind, z_prop)\n",
    "                    if im[\"horizontal_flip\"]:\n",
    "                        mask = torch.flip(mask, dims=(1,))\n",
    "                        z_mask = torch.flip(z_mask, dims= (1,))\n",
    "                    if im[\"vertical_flip\"]:\n",
    "                        mask = torch.flip(mask, dims=(2,))\n",
    "                        z_mask = torch.flip(z_mask, dims= (2,))\n",
    "                    masks.append(mask)\n",
    "                    z_masks.append(z_mask)\n",
    "\n",
    "\n",
    "\n",
    "            # cat target frames with lookahead context frames, convert to ndarrays\n",
    "            synth_window = torch.cat(prop_synths, dim = 0)\n",
    "            phases_window = torch.cat(prop_phases, dim = 0)\n",
    "            masks_window = torch.cat(masks, dim = 0)\n",
    "            z_masks_window = torch.cat(z_masks, dim = 0)\n",
    "            z_masks_window /= (z_props[-1] - z_props[0])\n",
    "\n",
    "            # cat images and masks in color dim (0 since batch not added yet)\n",
    "            image_stack = torch.cat([synth_window, phases_window], dim = 0)\n",
    "            \"\"\"\n",
    "            masks_stack = torch.cat([masks_window, z_masks_window], dim = 0)\n",
    "            \"\"\"\n",
    "            masks_stack = torch.cat([masks_window], dim = 0)\n",
    "\n",
    "            yield (image_stack, masks_stack)\n",
    "        \n",
    "        \n",
    "        # given a full image, slice coordinates defined in slice.idx2slice, return dict of tiles {(x,y): tensor}\n",
    "    def sequential_tile(self, full_plane):\n",
    "        tiles_dict = defaultdict()\n",
    "        for slice_coords in self.idx2slice:\n",
    "            tiles_dict[slice_coords] = full_plane[:,self.idx2slice[slice_coords][0], self.idx2slice[slice_coords][1]]\n",
    "        return tiles_dict\n",
    "    \n",
    "        # given dict of tiles {(x,y): tensor tile} (as returned from sequential_tile()), reconstruct full image\n",
    "        # stride overlap is sum of both tiles\n",
    "    def tile_reconstruct(self, tile_dict):\n",
    "        largex, largey = self.idx2slice[list(self.idx2slice.keys())[-1]][0].stop, self.idx2slice[list(self.idx2slice.keys())[-1]][1].stop\n",
    "        template = torch.zeros(1,1,largex, largey)\n",
    "        counter = torch.zeros(largex, largey)\n",
    "        #template = torch.zeros(1,tile_dict[list(tile_dict.keys())[0]].shape[1],largex, largey)\n",
    "        for coords in tile_dict:\n",
    "            tile = tile_dict[coords]\n",
    "            slice_coords = self.idx2slice[coords]\n",
    "            template[:, :, slice_coords[0], slice_coords[1]] += tile\n",
    "            counter[slice_coords[0], slice_coords[1]] += 1\n",
    "        return template, counter\n",
    "            \n",
    "        # given image index, model, loss function, device, get full images at idx, split in to tiles, and get tile-wise prediction from model\n",
    "        # attach back together, and then evaluate loss between full prediction image and fullm ask image\n",
    "    def full_inference(self, h_idx, z_idx_list, model, loss = \"dice\", device = \"cpu\"):\n",
    "        plane_generator = self.get_full_plane(h_idx, z_idx_list, device = device)\n",
    "        frame_list = []\n",
    "        mask_list = []\n",
    "        counter_list = []\n",
    "        for (full_image, full_mask) in plane_generator:\n",
    "            image_tiles = self.sequential_tile(full_image)\n",
    "            mask_tiles = self.sequential_tile(full_mask)\n",
    "            with torch.no_grad():\n",
    "                for coords in image_tiles:\n",
    "                    image_tiles[coords] = model(image_tiles[coords].unsqueeze(0))[:,0:1,:,:]\n",
    "            full_inference_frame = self.tile_reconstruct(image_tiles)[0].squeeze(0)[0:1,:,:].float()\n",
    "            full_inference_mask, full_mask_counter = self.tile_reconstruct(mask_tiles)\n",
    "            counter_list += full_mask_counter.unsqueeze(0).unsqueeze(0)\n",
    "            frame_list += full_inference_frame.unsqueeze(0).unsqueeze(0)\n",
    "            mask_list += full_mask_counter.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        inference_frames = torch.cat(frame_list, dim = 0)  \n",
    "        mask_frames = torch.cat(mask_list, dim = 0)\n",
    "        counter_frames = torch.cat(mask_list, dim = 0)\n",
    "        test_criterion = load_loss(loss, split = \"validation\")\n",
    "        val_loss = test_criterion(inference_frames, mask_frames)\n",
    "        return(val_loss, mask_frames, counter_frames)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c094bb-e09f-49c6-ab0d-3fbfeaa69183",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb4aeb13-7109-4a35-9a54-a31286ca0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# load in from config file\n",
    "with open(conf_file_path) as cf:\n",
    "    conf = yaml.load(cf, Loader=yaml.FullLoader)\n",
    "\n",
    "        \n",
    "# edit color channels to be compatible with lookahead\n",
    "conf[\"model\"][\"in_channels\"] = 2 * (conf[\"data\"][\"lookahead\"] + 1)\n",
    "\n",
    "# load transformations from config\n",
    "if \"Normalize\" in conf[\"transforms\"][\"training\"]:\n",
    "    conf[\"transforms\"][\"validation\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\n",
    "        \"training\"\n",
    "    ][\"Normalize\"][\"mode\"]\n",
    "    conf[\"transforms\"][\"inference\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\n",
    "        \"training\"\n",
    "    ][\"Normalize\"][\"mode\"]\n",
    "\n",
    "train_transforms = LoadTransformations(conf[\"transforms\"][\"training\"])\n",
    "valid_transforms = LoadTransformations(conf[\"transforms\"][\"validation\"])\n",
    "\n",
    "# load lookahead depth from config\n",
    "lookahead = int(conf[\"data\"][\"lookahead\"])\n",
    "\n",
    "# Set up CUDA/CPU devices\n",
    "is_cuda = torch.cuda.is_available()\n",
    "data_device = (\n",
    "    torch.device(\"cpu\") if \"device\" not in conf[\"data\"] else conf[\"data\"][\"device\"]\n",
    ")\n",
    "\n",
    "if torch.cuda.device_count() >= 2 and \"cuda\" in data_device:\n",
    "    data_device = \"cuda:0\"\n",
    "    device = \"cuda:1\"\n",
    "    device_ids = list(range(1, torch.cuda.device_count()))\n",
    "else:\n",
    "    data_device = torch.device(\"cpu\")\n",
    "    device = (\n",
    "        torch.device(torch.cuda.current_device())\n",
    "        if is_cuda\n",
    "        else torch.device(\"cpu\")\n",
    "    )\n",
    "    device_ids = list(range(torch.cuda.device_count()))\n",
    "logging.info(f\"There are {torch.cuda.device_count()} GPUs available\")\n",
    "logging.info(\n",
    "    f\"Using device {data_device} to perform wave propagation, and {device_ids} for training the model\"\n",
    ")\n",
    "\n",
    "\n",
    "# load tiling size\n",
    "step_size = int(conf[\"data\"][\"step_size\"])\n",
    "z_weight = int(conf[\"trainer\"][\"z_weight\"])\n",
    "\n",
    "# hard code shuffle, n_bins\n",
    "shuffle =False\n",
    "n_bins = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a13665-82a8-4055-a1a1-77f07584df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "\n",
    "train_dataset = LoadHolograms(\"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_training.nc\", shuffle = False, device = data_device, n_bins = n_bins, transform = train_transforms, lookahead = 1, tile_size = 1024, step_size = 1024)\n",
    "\n",
    "test_dataset = LoadHolograms(\"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_validation.nc\", shuffle = False, device = data_device, n_bins = n_bins, transform = valid_transforms, lookahead = 1, tile_size = 1024, step_size = 1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c4173-582c-4b89-8693-b567e6e370d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb8cbc2-7c60-4968-a31e-3417671deca4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(conf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m model_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../results/batch7/best.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(model_dict)\n\u001b[1;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;241m200\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/holodec/lib/python3.8/site-packages/torch/serialization.py:607\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[1;32m    606\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 607\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/.conda/envs/holodec/lib/python3.8/site-packages/torch/serialization.py:882\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m    881\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m--> 882\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/holodec/lib/python3.8/site-packages/torch/serialization.py:857\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    855\u001b[0m data_type, key, location, size \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[0;32m--> 857\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    858\u001b[0m storage \u001b[38;5;241m=\u001b[39m loaded_storages[key]\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m storage\n",
      "File \u001b[0;32m~/.conda/envs/holodec/lib/python3.8/site-packages/torch/serialization.py:846\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    843\u001b[0m dtype \u001b[38;5;241m=\u001b[39m data_type(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    845\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, size, dtype)\u001b[38;5;241m.\u001b[39mstorage()\n\u001b[0;32m--> 846\u001b[0m loaded_storages[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/holodec/lib/python3.8/site-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 175\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/holodec/lib/python3.8/site-packages/torch/serialization.py:151\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 151\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    153\u001b[0m             storage_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda, \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/holodec/lib/python3.8/site-packages/torch/serialization.py:135\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    132\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    136\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    140\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "model = load_model(conf[\"model\"])\n",
    "model_dict = torch.load(\"../results/batch7/best.pt\")[\"model_state_dict\"]\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "inputs = train_dataset.__getitem__(200)\n",
    "\n",
    "pred_masks = model(inputs[0].unsqueeze(dim = 0))\n",
    "pred_masks = torch.gt(pred_masks, 0.5)[0].detach().numpy()\n",
    "#pred_masks = pred_masks[0].detach().numpy()\n",
    "print(pred_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e6247-48c0-4054-a386-d799683804a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_idx = 1\n",
    "z_idx_list = [0,1,2,3]\n",
    "gener = train_dataset.get_full_plane(h_idx, z_idx_list, device = \"cpu\")\n",
    "for (image_stack, masks_stack) in gener:\n",
    "    print(image_stack.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51dd43-69c5-4612-9cd2-077154ac8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mask_frames, counter_frames = train_dataset.full_inference(5, [0,1,2,3], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63a313-5e42-472f-b9e1-5f2646148f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b9da06-e829-4c3d-baef-9156edcc4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check loading\n",
    "randint = 1040529\n",
    "rand_img_raw, rand_masks_raw = train_dataset.__getitem__(randint)\n",
    "\n",
    "while (int(torch.count_nonzero(rand_masks_raw[0])) < 30):\n",
    "    randint = random.randint(0,train_dataset.__len__())\n",
    "    rand_img_raw, rand_masks_raw = train_dataset.__getitem__(randint)\n",
    "print(randint, int(torch.count_nonzero(rand_masks_raw[0])))\n",
    "print(len(torch.nonzero(rand_masks_raw[0], as_tuple = False)))\n",
    "print()\n",
    "\n",
    "rand_img_raw, rand_masks_raw = train_dataset.__getitem__(randint)\n",
    "image = rand_img_raw\n",
    "print(len(image))\n",
    "\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 4, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow(image[0], origin ='lower')\n",
    "ax[1].imshow(image[1], origin = 'lower')\n",
    "ax[2].imshow(image[2], origin = 'lower')\n",
    "ax[3].imshow(image[3], origin = 'lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05764718-1579-4049-8777-8089b6777f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = counter_frames\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 4, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow(image[0], origin ='lower')\n",
    "ax[1].imshow(image[1], origin = 'lower')\n",
    "ax[2].imshow(image[2], origin = 'lower')\n",
    "ax[3].imshow(image[3], origin = 'lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd27ff-4332-4127-b4cd-0cddc20eae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = masks\n",
    "\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "\n",
    "ax.imshow(image[0], origin ='lower')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5d091-49d7-45f8-b649-71a16d5f420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "val_loss = train_dataset.full_inference(randint, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3a5f4-0c89-4a56-b5bd-69faa041d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_loss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384e995-d98c-4d0b-b51a-3e88e1cadc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = val_loss[1]\n",
    "\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "\n",
    "ax.imshow(image[0] > 0.2, origin ='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05532232-2120-498f-bed0-7c0c5a7b8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = val_loss[2]\n",
    "\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "\n",
    "ax.imshow(image, origin ='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da90733b-2fd8-4267-aa3c-856f3fe280b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9825cd9-6255-49b5-9ff1-1c9c7b6168f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tiles = train_dataset.sequential_tile(masks)\n",
    "print(mask_tiles[(0,0)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881588f1-ff13-475a-84ac-dc84edd71ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_reconstruct_raw, mask_reconstruct_counter = train_dataset.tile_reconstruct(mask_tiles)\n",
    "print(mask_reconstruct_counter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a707ef72-829b-4c55-9f45-ed061ba03418",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mask_reconstruct_raw.squeeze(0).squeeze()\n",
    "\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "\n",
    "ax.imshow(image, origin ='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ccdf3-f3f4-4b66-a30c-98ab2ce46f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.full_inference(randint, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holodec",
   "language": "python",
   "name": "holodec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
