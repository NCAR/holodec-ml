{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a575b36-2617-47bf-b025-1f523a5f6436",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28e4f0-d7a3-4878-b3bf-4e8e3190d9dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Libraries, Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8ff86707-cc39-4df1-a6b2-edef5cca34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import xarray as xr\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from holodecml.transforms import LoadTransformations\n",
    "from echo.src.base_objective import BaseObjective\n",
    "\n",
    "# from holodecml.seed import seed_everything\n",
    "from holodecml.data import XarrayReader\n",
    "from holodecml.models import load_model\n",
    "from holodecml.losses import load_loss\n",
    "\n",
    "from collections import defaultdict\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import torch.fft\n",
    "import logging\n",
    "import shutil\n",
    "import random\n",
    "import psutil\n",
    "import optuna\n",
    "import torch\n",
    "import time\n",
    "import tqdm\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import yaml\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e329c8d7-b121-4f59-88d2-2857deac148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d0677629-00c3-4278-b01f-0d5c83c0af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "print(is_cuda)\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")\n",
    "print(device)\n",
    "if is_cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    #torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00601ee-f398-4e16-b6f5-396c7a1b4d43",
   "metadata": {},
   "source": [
    "### Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "196a54d2-b374-4ac0-8e66-d8914c2145da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_training.nc\"\n",
    "test_dataset_path = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_validation.nc\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44639ef1-df3c-49b9-b91a-3a2528054548",
   "metadata": {},
   "source": [
    "### Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d621df-5574-41c2-9041-a0c1c31bc06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29c76903-9f83-4e98-9db5-fd320e2c0020",
   "metadata": {},
   "source": [
    "### Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67ca7777-4ea8-4eb4-93fb-81ea40d14ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavePropagator(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 n_bins=1000,\n",
    "                 step_size=128,\n",
    "                 tile_size = 128,\n",
    "                 marker_size=10,\n",
    "                 transform_mode=None,\n",
    "                 device=\"cpu\"):\n",
    "\n",
    "        self.h_ds = xr.open_dataset(data_path)\n",
    "\n",
    "\n",
    "        if 'zMin' in self.h_ds.attrs:\n",
    "            self.zMin = self.h_ds.attrs['zMin']  # minimum z in sample volume\n",
    "            self.zMax = self.h_ds.attrs['zMax']\n",
    "        else:  # some of the raw data does not have this parameter\n",
    "            # should warn the user here through the logger\n",
    "            self.zMin = 0.014\n",
    "            self.zMax = 0.158 #15.8 - 1.4 / (1000)\n",
    "\n",
    "        self.n_bins = n_bins\n",
    "        self.z_bins = np.linspace(\n",
    "            self.zMin, self.zMax, n_bins+1)*1e6  # histogram bin edges\n",
    "        self.z_centers = self.z_bins[:-1] + 0.5 * \\\n",
    "            np.diff(self.z_bins)  # histogram bin center\n",
    "        \n",
    "        self.tile_size = tile_size\n",
    "        self.step_size = step_size\n",
    "        \n",
    "        # UNET gaussian marker width (standard deviation) in um\n",
    "        self.marker_size = marker_size\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "        self.dx = self.h_ds.attrs['dx']      # horizontal resolution\n",
    "        self.dy = self.h_ds.attrs['dy']      # vertical resolution\n",
    "        self.Nx = int(self.h_ds.attrs['Nx'])  # number of horizontal pixels\n",
    "        self.Ny = int(self.h_ds.attrs['Ny'])  # number of vertical pixels\n",
    "        self.lam = self.h_ds.attrs['lambda']  # wavelength\n",
    "        self.image_norm = 255.0\n",
    "        self.transform_mode = transform_mode\n",
    "        self.x_arr = np.arange(-self.Nx//2, self.Nx//2)*self.dx\n",
    "        self.y_arr = np.arange(-self.Ny//2, self.Ny//2)*self.dy\n",
    "\n",
    "        self.tile_x_bins = np.arange(-self.Nx//2,\n",
    "                                     self.Nx//2, self.step_size)*self.dx*1e6\n",
    "        self.tile_y_bins = np.arange(-self.Ny//2,\n",
    "                                     self.Ny//2, self.step_size)*self.dy*1e6\n",
    "\n",
    "        self.fx = torch.fft.fftfreq(\n",
    "            self.Nx, self.dx, device=self.device).unsqueeze(0).unsqueeze(2)\n",
    "        self.fy = torch.fft.fftfreq(\n",
    "            self.Ny, self.dy, device=self.device).unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        \n",
    "        self.create_mapping()\n",
    "    def torch_holo_set(self,\n",
    "                       Ein: torch.tensor,\n",
    "                       z_tnsr: torch.tensor):\n",
    "        \"\"\"\n",
    "        Propagates an electric field a distance z\n",
    "        Ein complex torch.tensor\n",
    "        - input electric field\n",
    "\n",
    "        fx:real torch.tensor\n",
    "        - x frequency axis (3D, setup to broadcast)\n",
    "\n",
    "        fy: real torch.tensor\n",
    "        - y frequency axis (3D, setup to broadcast)\n",
    "\n",
    "        z_tnsr: torch.tensor\n",
    "        - tensor of distances to propagate the wave Ein\n",
    "            expected to have dims (Nz,1,1) where Nz is the number of z\n",
    "            dimensions\n",
    "\n",
    "        lam: float\n",
    "        - wavelength\n",
    "\n",
    "        returns: complex torch.tensor with dims (Nz,fy,fx)\n",
    "\n",
    "        Note the torch.fft library uses dtype=torch.complex64\n",
    "        This may be an issue for GPU implementation\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.transform_mode == \"standard\":\n",
    "            Ein = Ein.float()\n",
    "            Ein -= torch.mean(Ein)\n",
    "            Ein /= torch.std(Ein)\n",
    "\n",
    "        elif self.transform_mode == \"min-max\":\n",
    "            Ein = Ein.float()\n",
    "            Ein -= torch.min(Ein)\n",
    "            Ein /= torch.max(Ein)\n",
    "\n",
    "        Etfft = torch.fft.fft2(Ein)\n",
    "        Eofft = Etfft*torch.exp(1j*2*np.pi*z_tnsr/self.lam *\n",
    "                                torch.sqrt(1-self.lam**2*(self.fx**2+self.fy**2)))\n",
    "\n",
    "        # It might be helpful if we could omit this step.  It would save an inverse fft.\n",
    "        Eout = torch.fft.ifft2(Eofft)\n",
    "        return Eout\n",
    "    \n",
    "    \n",
    "    def create_mapping(self):\n",
    "        \"\"\"\n",
    "        Create map from tile coordinates (x,y) to indices to slice in image to extract that tile. \n",
    "        \"\"\"\n",
    "        self.idx2slice = {}\n",
    "        for row_idx in range(self.Nx//self.step_size):\n",
    "\n",
    "            if row_idx*self.step_size+self.tile_size > self.Nx:\n",
    "                image_pixel_x = self.Nx-self.tile_size\n",
    "                row_slice = slice(-self.tile_size, None)\n",
    "                row_break = True\n",
    "            else:\n",
    "                image_pixel_x = row_idx*self.step_size\n",
    "                row_slice = slice(row_idx*self.step_size,\n",
    "                                  row_idx*self.step_size+self.tile_size)\n",
    "                row_break = False\n",
    "\n",
    "            for col_idx in range(self.Ny//self.step_size):\n",
    "\n",
    "                if col_idx*self.step_size+self.tile_size > self.Ny:\n",
    "                    image_pixel_y = self.Ny-self.tile_size\n",
    "                    col_slice = slice(-self.tile_size, None)\n",
    "                    col_break = True\n",
    "                else:\n",
    "                    image_pixel_y = col_idx*self.step_size\n",
    "                    col_slice = slice(col_idx*self.step_size,\n",
    "                                      col_idx*self.step_size+self.tile_size)\n",
    "                    col_break = False\n",
    "\n",
    "                self.idx2slice[row_idx, col_idx] = (row_slice, col_slice)\n",
    "\n",
    "                if col_break:\n",
    "                    break\n",
    "\n",
    "            if row_break:\n",
    "                break\n",
    "                \n",
    "                \n",
    "                \n",
    "    def collate_image(self, idx_dict, image = None, mask = None):\n",
    "        x, y = zip(*[(image[:, row_slice, col_slice], mask[row_slice, col_slice]) for ((row_idx, col_idx, row_slice, col_slice)) in idx_dict])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ff1fb22-8b00-4ec2-a664-a1386d55c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(prop, h_idx, z_idx, z_ref):\n",
    "\n",
    "    hid = h_idx + 1\n",
    "    hid_mask = prop.h_ds[\"hid\"] == hid\n",
    "\n",
    "    # Filter particles based on h_idx\n",
    "    x_part = prop.h_ds[\"x\"].values[hid_mask]\n",
    "    y_part = prop.h_ds[\"y\"].values[hid_mask]\n",
    "    z_part = prop.h_ds[\"z\"].values[hid_mask]\n",
    "    d_part = prop.h_ds[\"d\"].values[hid_mask]\n",
    "\n",
    "    z_indices = np.digitize(z_part, prop.z_bins) - 1\n",
    "    # Initialize the UNET mask\n",
    "    unet_mask = np.zeros((prop.x_arr.shape[0], prop.y_arr.shape[0]))\n",
    "    z_mask = np.zeros((prop.x_arr.shape[0], prop.y_arr.shape[0]))\n",
    "    num_particles = 0 \n",
    "    \n",
    "    if z_idx in z_indices:\n",
    "        cond = np.where(z_idx == z_indices)\n",
    "        x_part = x_part[cond]\n",
    "        y_part = y_part[cond]\n",
    "        z_part = z_part[cond]\n",
    "        d_part = d_part[cond]\n",
    "        \n",
    "        #print(x_part, y_part, z_part, d_part)\n",
    "        \n",
    "        # Build the UNET mask using vectorized operations\n",
    "        for part_idx in range(len(cond[0])):\n",
    "            y_diff = (prop.y_arr[None, :] * 1e6 - y_part[part_idx])\n",
    "            x_diff = (prop.x_arr[:, None] * 1e6 - x_part[part_idx])\n",
    "            d_squared = (d_part[part_idx] / 2)**2\n",
    "            unet_mask += ((y_diff**2 + x_diff**2) < d_squared).astype(float)\n",
    "            z_diff = (z_part - z_ref)\n",
    "            for particle in z_diff:\n",
    "                z_mask += ((y_diff**2 + x_diff**2) < d_squared).astype(float) * particle\n",
    "                num_particles += 1\n",
    "\n",
    "    return torch.from_numpy(unet_mask).unsqueeze(0), num_particles, torch.from_numpy(z_mask).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6738f6a7-9c81-490e-8368-a733aaebc758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadHolograms(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_path,\n",
    "        n_bins=1000,\n",
    "        shuffle=False,\n",
    "        device=\"cpu\",\n",
    "        transform=False,\n",
    "        lookahead=0,\n",
    "        step_size=32,\n",
    "        tile_size=32,\n",
    "        balance=True,\n",
    "    ):\n",
    "\n",
    "        # num of waveprop windows\n",
    "        self.n_bins = n_bins\n",
    "        # device used\n",
    "        self.device = device\n",
    "        # shuffle frames\n",
    "        self.shuffle = shuffle\n",
    "        # num of frames to look ahead\n",
    "        self.lookahead = lookahead\n",
    "        # wavepropagator object on device\n",
    "        self.propagator = WavePropagator(\n",
    "            file_path,\n",
    "            n_bins=n_bins,\n",
    "            device=device,\n",
    "            step_size=step_size,\n",
    "            tile_size=tile_size,\n",
    "        )\n",
    "        self.transform = transform\n",
    "        self.indices = [\n",
    "            (x, y)\n",
    "            for x in self.propagator.h_ds.hologram_number\n",
    "            for y in range(self.n_bins - self.lookahead)\n",
    "        ]\n",
    "\n",
    "        self.tile_size = tile_size\n",
    "        self.idx2slice = self.propagator.idx2slice\n",
    "        self.balance = balance\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.balance:\n",
    "            return len(self.propagator.h_ds.hologram_number) * len(self.indices)\n",
    "        return len(self.indices) * len(self.idx2slice)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.balance:\n",
    "            image_lst = []\n",
    "            while len(image_lst) == 0:\n",
    "                # flip coin\n",
    "                infocus, outfocus = random.choice([[0, 1], [1, 0]])\n",
    "                image_lst, particle_unet_labels_lst, particle_in_focus_lst = self.get_reconstructed_sub_images(\n",
    "                    idx, part_per_holo=infocus, empt_per_holo=outfocus\n",
    "                )\n",
    "            return image_lst[0], particle_unet_labels_lst[0].squeeze(0), particle_in_focus_lst\n",
    "\n",
    "        else:\n",
    "            return self.random_batcher(idx)\n",
    "\n",
    "    def random_batcher(self, idx):\n",
    "\n",
    "        if self.shuffle:\n",
    "            idx = random.choice(range(self.__len__()))\n",
    "\n",
    "        # hologram_idx = idx // self.n_bins\n",
    "        # plane_idx = idx // len(self.propagator.h_ds.hologram_number)\n",
    "        hologram_idx, plane_idx = self.indices[(idx) // len(self.idx2slice)]\n",
    "        z_props = self.propagator.z_centers[plane_idx : plane_idx + self.lookahead + 1]\n",
    "        # z_props -= (z_props[1] - z_props[0]) / 2\n",
    "        plane_indices = np.arange(plane_idx, plane_idx + self.lookahead + 1)\n",
    "        # select hologram\n",
    "        image = (\n",
    "            self.propagator.h_ds[\"image\"]\n",
    "            .isel(hologram_number=hologram_idx)\n",
    "            .values.astype(float)\n",
    "        )\n",
    "\n",
    "        im = {\n",
    "            \"image\": np.expand_dims(image, 0),\n",
    "            \"horizontal_flip\": False,\n",
    "            \"vertical_flip\": False,\n",
    "        }\n",
    "\n",
    "        # add transformations here\n",
    "        if self.transform:\n",
    "            for image_transform in self.transform:\n",
    "                im = image_transform(im)\n",
    "        image = im[\"image\"]\n",
    "\n",
    "        # make tensors of size lookahead + 1, and then add tensors\n",
    "        prop_synths = torch.empty((len(z_props), image.shape[-2], image.shape[-1]))\n",
    "        prop_phases = torch.empty((len(z_props), image.shape[-2], image.shape[-1]))\n",
    "        masks = torch.empty((1, image.shape[-2], image.shape[-1]))\n",
    "        z_masks = torch.empty((1, image.shape[-2], image.shape[-1]))\n",
    "\n",
    "        for k, (z_prop, z_ind) in enumerate(zip(z_props, plane_indices)):\n",
    "            image_prop = self.propagator.torch_holo_set(\n",
    "                image.to(self.device),\n",
    "                torch.FloatTensor([z_prop * 1e-6]).to(self.device),\n",
    "            )\n",
    "            # ABS (x-input)\n",
    "            prop_synth = torch.abs(image_prop).squeeze(0)\n",
    "            prop_synths[k] = prop_synth\n",
    "            # Phase (x-input)\n",
    "            prop_phase = torch.angle(image_prop).squeeze(0)\n",
    "            prop_phases[k] = prop_phase\n",
    "            # Mask (y-label)\n",
    "            if k == 0:\n",
    "                mask, num_particles, z_mask = create_mask(\n",
    "                    self.propagator, hologram_idx, z_ind, z_prop\n",
    "                )\n",
    "                if im[\"horizontal_flip\"]:\n",
    "                    mask = torch.flip(mask, [1])\n",
    "                    z_mask = torch.flip(z_mask, [1])\n",
    "                if im[\"vertical_flip\"]:\n",
    "                    mask = torch.flip(mask, [2])\n",
    "                    z_mask = torch.flip(z_mask, [2])\n",
    "                masks[k] = mask\n",
    "                z_masks[k] = z_mask\n",
    "\n",
    "        # z_masks_window /= (z_props[-1] - z_props[0])\n",
    "\n",
    "        # cat images and masks in color dim (0 since batch not added yet)\n",
    "        image_stack = torch.cat([prop_synths, prop_phases], dim=0)\n",
    "\n",
    "        # get tiles, slicing along coords in idx2slice array that maps coord position to slice range\n",
    "        slice_coords = self.idx2slice[list(self.idx2slice)[idx % len(self.idx2slice)]]\n",
    "        image_stack = image_stack[:, slice_coords[0], slice_coords[1]]\n",
    "        masks = masks[slice_coords[0], slice_coords[1]]\n",
    "\n",
    "        return (image_stack, masks)\n",
    "\n",
    "    def get_full_plane(self, h_idx, z_idx_list, device = \"cpu\"):\n",
    "        image = self.propagator.h_ds['image'].isel(hologram_number=h_idx+1).values\n",
    "        # select hologram\n",
    "        im = {\n",
    "            \"image\": np.expand_dims(image, 0),\n",
    "            \"horizontal_flip\": False,\n",
    "            \"vertical_flip\": False\n",
    "        }\n",
    "\n",
    "        # add transformations here\n",
    "        if self.transform:\n",
    "            for image_transform in self.transform:\n",
    "                im = image_transform(im)\n",
    "        image = im[\"image\"]\n",
    "        \n",
    "        for z_idx in z_idx_list:\n",
    "            z_props = self.propagator.z_centers[z_idx: z_idx + self.lookahead + 1]\n",
    "            # select planes for lookahead\n",
    "            plane_indices = np.arange(z_idx, z_idx + self.lookahead + 1)\n",
    "\n",
    "            # Make tensors of size lookahead + 1, and then add tensors\n",
    "            prop_synths = np.zeros((lookahead + 1, *image.shape))\n",
    "            prop_phases = np.zeros((lookahead + 1, *image.shape))\n",
    "            masks = np.zeros((1, *image.shape[-2:]))\n",
    "            particles_in_frames = []\n",
    "\n",
    "            for k, (z_prop, z_ind) in enumerate(zip(z_props, plane_indices)):\n",
    "                image_prop = self.propagator.torch_holo_set(\n",
    "                    image.to(device),\n",
    "                    torch.FloatTensor([z_prop*1e-6]).to(device)\n",
    "                )\n",
    "                # ABS (x-input)\n",
    "                prop_synth = torch.abs(image_prop)\n",
    "                prop_synths[k] = prop_synth\n",
    "                # Phase (x-input)\n",
    "                prop_phase = torch.angle(image_prop)\n",
    "                prop_phases[k] = prop_phase  \n",
    "                # Mask (y-label)\n",
    "                if k == 0:\n",
    "                    mask, num_particles, _ = create_mask(self.propagator, h_idx, z_ind, z_prop)\n",
    "                    if im[\"horizontal_flip\"]:\n",
    "                        mask = torch.flip(mask, dims=(1,))\n",
    "                    if im[\"vertical_flip\"]:\n",
    "                        mask = torch.flip(mask, dims=(2,))\n",
    "                    masks[k] = mask\n",
    "                    particles_in_frames.append(num_particles)\n",
    "\n",
    "            # cat target frames with lookahead context frames, convert to ndarrays\n",
    "            synth_window = np.concatenate(prop_synths, axis=0)\n",
    "            phases_window = np.concatenate(prop_phases, axis=0)\n",
    "            masks_window = np.concatenate(masks, axis=0)\n",
    "            \n",
    "            # cat images and masks in color dim (0 since batch not added yet)\n",
    "            image_stack = np.concatenate([synth_window, phases_window], axis=0)\n",
    "            masks_stack = np.concatenate([masks_window], axis=0)\n",
    "\n",
    "            yield (torch.from_numpy(image_stack).float(), torch.from_numpy(masks_stack).int())\n",
    "        \n",
    "        \n",
    "        # given a full image, slice coordinates defined in slice.idx2slice, return dict of tiles {(x,y): tensor}\n",
    "    def sequential_tile(self, full_plane):\n",
    "        tiles_dict = defaultdict()\n",
    "        for slice_coords in self.idx2slice:\n",
    "            tiles_dict[slice_coords] = full_plane[:,self.idx2slice[slice_coords][0], self.idx2slice[slice_coords][1]]\n",
    "        return tiles_dict\n",
    "    \n",
    "        # given dict of tiles {(x,y): tensor tile} (as returned from sequential_tile()), reconstruct full image\n",
    "        # stride overlap is sum of both tiles\n",
    "    def tile_reconstruct(self, tile_dict, largex, largey):\n",
    "        template = torch.zeros(1, 1, largex, largey)\n",
    "        counter = torch.zeros(largex, largey)\n",
    "        #template = torch.zeros(1,tile_dict[list(tile_dict.keys())[0]].shape[1],largex, largey)\n",
    "        for coords in tile_dict:\n",
    "            tile = tile_dict[coords]\n",
    "            slice_coords = self.idx2slice[coords]\n",
    "            template[:, :, slice_coords[0], slice_coords[1]] += tile\n",
    "            counter[slice_coords[0], slice_coords[1]] += 1\n",
    "        return template, counter\n",
    "            \n",
    "        # given image index, model, loss function, device, get full images at idx, split in to tiles, and get tile-wise prediction from model\n",
    "        # attach back together, and then evaluate loss between full prediction image and fullm ask image\n",
    "        \n",
    "        \n",
    "    def get_full_plane(self, h_idx, z_idx_list, device = \"cpu\"):\n",
    "        image = self.propagator.h_ds['image'].isel(hologram_number=h_idx+1).values\n",
    "        # select hologram\n",
    "        im = {\n",
    "            \"image\": np.expand_dims(image, 0),\n",
    "            \"horizontal_flip\": False,\n",
    "            \"vertical_flip\": False\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            for image_transform in self.transform:\n",
    "                im = image_transform(im)\n",
    "        image = im[\"image\"]\n",
    "        \n",
    "        for z_idx in z_idx_list:\n",
    "            z_props = self.propagator.z_centers[z_idx: z_idx + self.lookahead + 1]\n",
    "            # select planes for lookahead\n",
    "            plane_indices = np.arange(z_idx, z_idx + self.lookahead + 1)\n",
    "\n",
    "            # Make tensors of size lookahead + 1, and then add tensors\n",
    "            prop_synths = np.zeros((self.lookahead + 1, *image.shape))\n",
    "            prop_phases = np.zeros((self.lookahead + 1, *image.shape))\n",
    "            masks = np.zeros((1, *image.shape[-2:]))\n",
    "            particles_in_frames = []\n",
    "\n",
    "            for k, (z_prop, z_ind) in enumerate(zip(z_props, plane_indices)):\n",
    "                image_prop = self.propagator.torch_holo_set(\n",
    "                    image.to(device),\n",
    "                    torch.FloatTensor([z_prop*1e-6]).to(device)\n",
    "                )\n",
    "                # ABS (x-input)\n",
    "                prop_synth = torch.abs(image_prop)\n",
    "                prop_synths[k] = prop_synth\n",
    "                # Phase (x-input)\n",
    "                prop_phase = torch.angle(image_prop)\n",
    "                prop_phases[k] = prop_phase  \n",
    "                # Mask (y-label)\n",
    "                if k == 0:\n",
    "                    mask, num_particles, _ = create_mask(self.propagator, h_idx, z_ind, z_prop)\n",
    "                    if im[\"horizontal_flip\"]:\n",
    "                        mask = torch.flip(mask, dims=(1,))\n",
    "                    if im[\"vertical_flip\"]:\n",
    "                        mask = torch.flip(mask, dims=(2,))\n",
    "                    masks[k] = mask\n",
    "                    particles_in_frames.append(num_particles)\n",
    "\n",
    "            # cat target frames with lookahead context frames, convert to ndarrays\n",
    "            synth_window = np.concatenate(prop_synths, axis=0)\n",
    "            phases_window = np.concatenate(prop_phases, axis=0)\n",
    "            masks_window = np.concatenate(masks, axis=0)\n",
    "            \n",
    "            # cat images and masks in color dim (0 since batch not added yet)\n",
    "            image_stack = np.concatenate([synth_window, phases_window], axis=0)\n",
    "            masks_stack = np.concatenate([masks_window], axis=0)\n",
    "\n",
    "            yield (torch.from_numpy(image_stack).float(), torch.from_numpy(masks_stack).int())\n",
    "        \n",
    "        \n",
    "    def full_inference(self, idx, model, loss = \"dice\", device = \"cpu\"):\n",
    "        full_image, full_mask = self.get_full_plane(idx, device = device)\n",
    "        image_tiles = self.sequential_tile(full_image)\n",
    "        mask_tiles = self.sequential_tile(full_mask)\n",
    "        with torch.no_grad():\n",
    "            for coords in image_tiles:\n",
    "                image_tiles[coords] = model(image_tiles[coords].unsqueeze(0))[:,0:1,:,:]\n",
    "        full_inference_frame = self.tile_reconstruct(image_tiles)[0].squeeze(0)[0:1,:,:].float()\n",
    "        full_inference_mask, full_mask_counter = self.tile_reconstruct(mask_tiles)\n",
    "        test_criterion = load_loss(loss, split = \"validation\")\n",
    "        val_loss = test_criterion(full_inference_frame, full_inference_mask)\n",
    "        return(val_loss, full_inference_frame, full_mask_counter)\n",
    "            \n",
    "    def get_reconstructed_sub_images(\n",
    "        self, h_idx, part_per_holo=None, empt_per_holo=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Reconstruct a hologram at specific planes to provide training data\n",
    "        with a specified number of sub images containing and not containing\n",
    "        particles\n",
    "        \"\"\"\n",
    "        h_idx = h_idx // len(self.indices)\n",
    "        self.step_size = self.propagator.step_size\n",
    "        self.tile_size = self.propagator.tile_size\n",
    "        step_size = self.step_size\n",
    "        tile_size = self.tile_size\n",
    "\n",
    "        #### roughly half of the empty cases should be near in focus ####\n",
    "        empt_near_cnt = empt_per_holo // 2\n",
    "        ####\n",
    "\n",
    "        # locate particle information corresponding to this hologram\n",
    "        self.h_ds = self.propagator.h_ds\n",
    "        particle_idx = np.where(self.h_ds[\"hid\"].values == h_idx + 1)\n",
    "\n",
    "        x_part = self.h_ds[\"x\"].values[particle_idx]\n",
    "        y_part = self.h_ds[\"y\"].values[particle_idx]\n",
    "        z_part = self.h_ds[\"z\"].values[particle_idx]\n",
    "        # not used but here it is\n",
    "        d_part = self.h_ds[\"d\"].values[particle_idx]\n",
    "\n",
    "        # create a 3D histogram\n",
    "        in_data = np.stack((x_part, y_part, z_part)).T\n",
    "        h_part = np.histogramdd(\n",
    "            in_data,\n",
    "            bins=[\n",
    "                self.propagator.tile_x_bins,\n",
    "                self.propagator.tile_y_bins,\n",
    "                self.propagator.z_bins,\n",
    "            ],\n",
    "        )[0]\n",
    "        # specify the z bin locations of the particles\n",
    "        z_part_bin_idx = np.digitize(z_part, self.propagator.z_bins) - 1\n",
    "\n",
    "        # smoothing kernel accounts for overlapping subimages when the\n",
    "        # subimage is larger than the stride\n",
    "        ratio = self.tile_size // self.step_size\n",
    "        if self.step_size < self.tile_size:\n",
    "            overlap_kernel = np.ones((ratio, ratio))\n",
    "            for z_idx in range(h_part.shape[-1]):\n",
    "                h_part[:, :, z_idx] = convolve2d(h_part[:, :, z_idx], overlap_kernel)[\n",
    "                    ratio - 1 : h_part.shape[0] + ratio - 1,\n",
    "                    ratio - 1 : h_part.shape[1] + ratio - 1,\n",
    "                ]\n",
    "\n",
    "        # locate all the cases where particles are and are not present\n",
    "        # to sample from those cases\n",
    "        if self.step_size < self.tile_size:\n",
    "            # note that the last bin is ommitted from each to avoid edge cases where\n",
    "            # the image is not complete\n",
    "\n",
    "            edge_idx = ratio - 1\n",
    "\n",
    "            # find the locations where particles are in focus\n",
    "            loc_idx = np.where(h_part[:-edge_idx, :-edge_idx, :] > 0)\n",
    "            # find locations where particles are not in focus\n",
    "            empt_idx = np.where(h_part[:-edge_idx, :-edge_idx, :] == 0)\n",
    "            #### find locations where particles are nearly in focus  ####\n",
    "            zdiff = np.diff(h_part[:-edge_idx, :-edge_idx, :], axis=2)\n",
    "            zero_pad = np.zeros(h_part[:-edge_idx, :-edge_idx, :].shape[0:2] + (1,))\n",
    "            near_empt_idx = np.where(\n",
    "                (h_part[:-edge_idx, :-edge_idx, :] == 0)\n",
    "                & (\n",
    "                    (np.concatenate([zdiff, zero_pad], axis=2) == 1)\n",
    "                    | (np.concatenate([zero_pad, zdiff], axis=2) == -1)\n",
    "                )\n",
    "            )\n",
    "            ####\n",
    "        else:\n",
    "            # find the locations where particles are in focus\n",
    "            loc_idx = np.where(h_part > 0)\n",
    "            # find locations where particles are not in focus\n",
    "            empt_idx = np.where(h_part == 0)\n",
    "            #### find locations where particles are nearly in focus ####\n",
    "            zdiff = np.diff(h_part, axis=2)\n",
    "            zero_pad = np.zeros(h_part.shape[0:2] + (1,))\n",
    "            near_empt_idx = np.where(\n",
    "                (h_part == 0)\n",
    "                & (\n",
    "                    (np.concatenate([zdiff, zero_pad], axis=2) == 1)\n",
    "                    | (np.concatenate([zero_pad, zdiff], axis=2) == -1)\n",
    "                )\n",
    "            )\n",
    "            ####\n",
    "            \n",
    "        loc_x_idx = loc_idx[0]\n",
    "        loc_y_idx = loc_idx[1]\n",
    "        loc_z_idx = loc_idx[2]\n",
    "\n",
    "        # select sub images with particles in them\n",
    "        if part_per_holo > loc_idx[0].size:\n",
    "            pass\n",
    "            # pick the entire set\n",
    "            \n",
    "        else:\n",
    "            # randomly select particles from the set\n",
    "            sel_part_idx = np.random.choice(\n",
    "                np.arange(loc_x_idx.size, dtype=int), size=part_per_holo, replace=False\n",
    "            )\n",
    "            loc_x_idx = loc_x_idx[sel_part_idx]\n",
    "            loc_y_idx = loc_y_idx[sel_part_idx]\n",
    "            loc_z_idx = loc_z_idx[sel_part_idx]\n",
    "\n",
    "        # randomly select empties from the empty set\n",
    "        #### Add nearly in focus cases to the training data ####\n",
    "        sel_empt_idx = np.random.choice(\n",
    "            np.arange(near_empt_idx[0].size, dtype=int),\n",
    "            size=empt_near_cnt,\n",
    "            replace=False,\n",
    "        )  # select nearly in focus cases\n",
    "        \n",
    "        ####\n",
    "        sel_empt_idx = np.concatenate(\n",
    "            [\n",
    "                np.random.choice(\n",
    "                    np.arange(empt_idx[0].size, dtype=int),\n",
    "                    size=(empt_per_holo - empt_near_cnt),\n",
    "                    replace=False,\n",
    "                ),\n",
    "                sel_empt_idx,\n",
    "            ]\n",
    "        )  # select random out of focus cases\n",
    "        empt_x_idx = empt_idx[0][sel_empt_idx]\n",
    "        empt_y_idx = empt_idx[1][sel_empt_idx]\n",
    "        empt_z_idx = empt_idx[2][sel_empt_idx]\n",
    "\n",
    "        # full set of plane indices to reconstruct (empty and with particles)\n",
    "        z_full_idx = np.unique(np.concatenate((loc_z_idx, empt_z_idx)))\n",
    "        _z_full_idx = []\n",
    "        for zp in z_full_idx:\n",
    "            if zp >= (self.n_bins-self.lookahead):\n",
    "                _z_full_idx.append(zp - self.lookahead - 1)\n",
    "            else:\n",
    "                _z_full_idx.append(zp)\n",
    "        z_full_idx = np.array(_z_full_idx)\n",
    "\n",
    "        # build the torch tensor for reconstruction\n",
    "        z_plane = (\n",
    "            torch.tensor(\n",
    "                self.propagator.z_centers[z_full_idx] * 1e-6, device=self.device\n",
    "            )\n",
    "            .unsqueeze(-1)\n",
    "            .unsqueeze(-1)\n",
    "        )\n",
    "\n",
    "        # grab the sub images corresponding to the selected data points\n",
    "        particle_in_focus_lst = []  # training labels for if particle is in focus\n",
    "        particle_unet_labels_lst = []  # training labels for if particle is in focus\n",
    "        image_lst = []  # sliced reconstructed image\n",
    "        image_index_lst = []  # indices used to identify the image slice\n",
    "        image_corner_coords = []  # coordinates of the corner of the image slice\n",
    "\n",
    "        for sub_idx, z_idx in enumerate(z_full_idx):\n",
    "            z_props = self.propagator.z_centers[z_idx : z_idx + self.lookahead + 1]\n",
    "            plane_indices = np.arange(z_idx, z_idx + self.lookahead + 1)\n",
    "            # select hologram\n",
    "            image = (\n",
    "                self.propagator.h_ds[\"image\"]\n",
    "                .isel(hologram_number=h_idx)\n",
    "                .values.astype(float)\n",
    "            )\n",
    "\n",
    "            im = {\n",
    "                \"image\": np.expand_dims(image, 0),\n",
    "                \"horizontal_flip\": False,\n",
    "                \"vertical_flip\": False,\n",
    "            }\n",
    "\n",
    "            # add transformations here\n",
    "            if self.transform:\n",
    "                for image_transform in self.transform:\n",
    "                    im = image_transform(im)\n",
    "            image = im[\"image\"]\n",
    "\n",
    "            # make tensors of size lookahead + 1, and then add tensors\n",
    "            prop_synths = torch.empty((len(z_props), image.shape[-2], image.shape[-1]))\n",
    "            prop_phases = torch.empty((len(z_props), image.shape[-2], image.shape[-1]))\n",
    "            masks = torch.empty((1, image.shape[-2], image.shape[-1]))\n",
    "            z_masks = torch.empty((1, image.shape[-2], image.shape[-1]))\n",
    "\n",
    "            for k, (z_prop, z_ind) in enumerate(zip(z_props, plane_indices)):\n",
    "                image_prop = self.propagator.torch_holo_set(\n",
    "                    image.to(self.device),\n",
    "                    torch.FloatTensor([z_prop * 1e-6]).to(self.device),\n",
    "                )\n",
    "                # ABS (x-input)\n",
    "                prop_synth = torch.abs(image_prop).squeeze(0)\n",
    "                prop_synths[k] = prop_synth\n",
    "                # Phase (x-input)\n",
    "                prop_phase = torch.angle(image_prop).squeeze(0)\n",
    "                prop_phases[k] = prop_phase\n",
    "                # Mask (y-label)\n",
    "                if k == 0:\n",
    "                    mask, num_particles, z_mask = create_mask(\n",
    "                        self.propagator, h_idx, z_ind, z_prop\n",
    "                    )\n",
    "                    if im[\"horizontal_flip\"]:\n",
    "                        mask = torch.flip(mask, [1])\n",
    "                        z_mask = torch.flip(z_mask, [1])\n",
    "                    if im[\"vertical_flip\"]:\n",
    "                        mask = torch.flip(mask, [2])\n",
    "                        z_mask = torch.flip(z_mask, [2])\n",
    "                    masks[k] = mask\n",
    "                    z_masks[k] = z_mask\n",
    "            # z_masks_window /= (z_props[-1] - z_props[0])\n",
    "\n",
    "            # cat images and masks in color dim (0 since batch not added yet)\n",
    "            image_stack = torch.cat([prop_synths, prop_phases], dim=0)\n",
    "\n",
    "            # Build the mask and pick out\n",
    "            part_set_idx = np.where(loc_z_idx == z_idx)[0]\n",
    "            empt_set_idx = np.where(empt_z_idx == z_idx)[0]\n",
    "\n",
    "            # initialize the UNET mask\n",
    "            # locate all particles in this plane\n",
    "            part_in_plane_idx = np.where(z_part_bin_idx == z_idx)[0] \n",
    "\n",
    "            for part_idx in part_set_idx:\n",
    "                x_idx = loc_x_idx[part_idx]\n",
    "                y_idx = loc_y_idx[part_idx]\n",
    "                image_lst.append(\n",
    "                    image_stack[\n",
    "                        :,\n",
    "                        x_idx * step_size : (x_idx * step_size + tile_size),\n",
    "                        y_idx * step_size : (y_idx * step_size + tile_size),\n",
    "                    ]\n",
    "                )\n",
    "                image_index_lst.append([x_idx, y_idx, z_idx])\n",
    "                image_corner_coords.append(\n",
    "                    [\n",
    "                        self.propagator.x_arr[x_idx * step_size],\n",
    "                        self.propagator.y_arr[y_idx * step_size],\n",
    "                    ]\n",
    "                )\n",
    "                particle_in_focus_lst.append(1)\n",
    "                particle_unet_labels_lst.append(\n",
    "                    masks[\n",
    "                        :,\n",
    "                        x_idx * step_size : (x_idx * step_size + tile_size),\n",
    "                        y_idx * step_size : (y_idx * step_size + tile_size),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            for empt_idx in empt_set_idx:\n",
    "                x_idx = empt_x_idx[empt_idx]\n",
    "                y_idx = empt_y_idx[empt_idx]\n",
    "                image_lst.append(\n",
    "                    image_stack[\n",
    "                        :,\n",
    "                        x_idx * step_size : (x_idx * step_size + tile_size),\n",
    "                        y_idx * step_size : (y_idx * step_size + tile_size),\n",
    "                    ]\n",
    "                )\n",
    "                image_index_lst.append([x_idx, y_idx, z_idx])\n",
    "                image_corner_coords.append(\n",
    "                    [\n",
    "                        self.propagator.x_arr[x_idx * step_size],\n",
    "                        self.propagator.y_arr[y_idx * step_size],\n",
    "                    ]\n",
    "                )\n",
    "                particle_in_focus_lst.append(0)\n",
    "                particle_unet_labels_lst.append(\n",
    "                    masks[\n",
    "                        :,\n",
    "                        x_idx * step_size : (x_idx * step_size + tile_size),\n",
    "                        y_idx * step_size : (y_idx * step_size + tile_size),\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "        #print(\"Returning\", len(image_lst))\n",
    "            \n",
    "        return image_lst, particle_unet_labels_lst, particle_in_focus_lst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c094bb-e09f-49c6-ab0d-3fbfeaa69183",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb4aeb13-7109-4a35-9a54-a31286ca0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "conf_file_path = \"../results/batch1/model.yml\"\n",
    "#conf_file_path = \"/glade/work/schreck/repos/HOLO/style/holodec-ml/results/manopt/model.yml\"\n",
    "# load in from config file\n",
    "with open(conf_file_path) as cf:\n",
    "    conf = yaml.load(cf, Loader=yaml.FullLoader)\n",
    "\n",
    "        \n",
    "# edit color channels to be compatible with lookahead\n",
    "#conf[\"model\"][\"in_channels\"] = 2 * (conf[\"data\"][\"lookahead\"] + 1)\n",
    "conf[\"model\"][\"in_channels\"] = 1\n",
    "# load transformations from config\n",
    "if \"Normalize\" in conf[\"transforms\"][\"training\"]:\n",
    "    conf[\"transforms\"][\"validation\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\n",
    "        \"training\"\n",
    "    ][\"Normalize\"][\"mode\"]\n",
    "    conf[\"transforms\"][\"inference\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\n",
    "        \"training\"\n",
    "    ][\"Normalize\"][\"mode\"]\n",
    "\n",
    "train_transforms = LoadTransformations(conf[\"transforms\"][\"training\"])\n",
    "valid_transforms = LoadTransformations(conf[\"transforms\"][\"validation\"])\n",
    "\n",
    "# load lookahead depth from config\n",
    "lookahead = int(conf[\"data\"][\"lookahead\"])\n",
    "tile_size = int(conf[\"data\"][\"tile_size\"])\n",
    "step_size = int(conf[\"data\"][\"step_size\"])\n",
    "# Set up CUDA/CPU devices\n",
    "is_cuda = torch.cuda.is_available()\n",
    "data_device = (\n",
    "    torch.device(\"cpu\") if \"device\" not in conf[\"data\"] else conf[\"data\"][\"device\"]\n",
    ")\n",
    "\n",
    "if torch.cuda.device_count() >= 2 and \"cuda\" in data_device:\n",
    "    data_device = \"cuda:0\"\n",
    "    device = \"cuda:1\"\n",
    "    device_ids = list(range(1, torch.cuda.device_count()))\n",
    "else:\n",
    "    data_device = torch.device(\"cpu\")\n",
    "    device = (\n",
    "        torch.device(torch.cuda.current_device())\n",
    "        if is_cuda\n",
    "        else torch.device(\"cpu\")\n",
    "    )\n",
    "    device_ids = list(range(torch.cuda.device_count()))\n",
    "logging.info(f\"There are {torch.cuda.device_count()} GPUs available\")\n",
    "logging.info(\n",
    "    f\"Using device {data_device} to perform wave propagation, and {device_ids} for training the model\"\n",
    ")\n",
    "\n",
    "\n",
    "# load tiling size\n",
    "step_size = int(conf[\"data\"][\"step_size\"])\n",
    "\n",
    "\n",
    "# hard code shuffle, n_bins\n",
    "shuffle =False\n",
    "n_bins = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15a13665-82a8-4055-a1a1-77f07584df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "\n",
    "train_dataset = LoadHolograms(\"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_training.nc\", shuffle = False, device = data_device, \n",
    "                              n_bins = n_bins, transform = train_transforms, lookahead = lookahead, tile_size = tile_size, step_size = step_size, balance = True)\n",
    "\n",
    "test_dataset = LoadHolograms(\"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_validation.nc\", shuffle = False, device = data_device, \n",
    "                             n_bins = n_bins, transform = valid_transforms, lookahead = lookahead, tile_size = tile_size, step_size = step_size, balance = True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "465c5057-acec-4504-bf77-5910b5c57265",
   "metadata": {},
   "source": [
    "old_file_path = \"/glade/work/schreck/repos/HOLO/style/holodec-ml/results/manopt/best.pt\"\n",
    "\n",
    "model = load_model(conf[\"model\"])\n",
    "model_dict = torch.load(\"../results/batch1/best.pt\")[\"model_state_dict\"]\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ce73b12-4b95-4d89-8ef0-98eaef15c6e4",
   "metadata": {},
   "source": [
    "conf_file_path = \"../results/batch1/model.yml\"\n",
    "\n",
    "\n",
    "model = load_model(conf[\"model\"])\n",
    "model_dict = torch.load(\"../results/batch1/best.pt\")[\"model_state_dict\"]\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "inputs = train_dataset.__getitem__(200)\n",
    "\n",
    "pred_masks = model(inputs[0].unsqueeze(dim = 0))\n",
    "pred_masks = torch.gt(pred_masks, 0.5)[0].detach().numpy()\n",
    "#pred_masks = pred_masks[0].detach().numpy()\n",
    "print(pred_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "94a93b0d-34bb-4d3b-84dc-d38642b4bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train_dataset.__getitem__(200)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbfb5e3e-0c1e-4be5-b084-51aef5c3b3a9",
   "metadata": {},
   "source": [
    "inputs = train_dataset.__getitem__(200)\n",
    "\n",
    "pred_masks = model(inputs[0].unsqueeze(dim = 0))\n",
    "pred_masks = torch.gt(pred_masks, 0.5)[0].detach().numpy()\n",
    "#pred_masks = pred_masks[0].detach().numpy()\n",
    "print(pred_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fffd137-f080-4790-a79c-5f23a4ba7403",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e6247-48c0-4054-a386-d799683804a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_idx = 1\n",
    "z_idx_list = [0,1,2,3]\n",
    "gener = train_dataset.get_full_plane(h_idx, z_idx_list, device = \"cpu\")\n",
    "for (image_stack, masks_stack) in gener:\n",
    "    print(image_stack.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51dd43-69c5-4612-9cd2-077154ac8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mask_frames, counter_frames = train_dataset.full_inference(5, [0,1,2,3], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63a313-5e42-472f-b9e1-5f2646148f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b9da06-e829-4c3d-baef-9156edcc4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check loading\n",
    "randint = 1040529\n",
    "rand_img_raw, rand_masks_raw = train_dataset.__getitem__(randint)\n",
    "\n",
    "while (int(torch.count_nonzero(rand_masks_raw[0])) < 30):\n",
    "    randint = random.randint(0,train_dataset.__len__())\n",
    "    rand_img_raw, rand_masks_raw = train_dataset.__getitem__(randint)\n",
    "print(randint, int(torch.count_nonzero(rand_masks_raw[0])))\n",
    "print(len(torch.nonzero(rand_masks_raw[0], as_tuple = False)))\n",
    "print()\n",
    "\n",
    "rand_img_raw, rand_masks_raw = train_dataset.__getitem__(randint)\n",
    "image = rand_img_raw\n",
    "print(len(image))\n",
    "\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 4, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow(image[0], origin ='lower')\n",
    "ax[1].imshow(image[1], origin = 'lower')\n",
    "ax[2].imshow(image[2], origin = 'lower')\n",
    "ax[3].imshow(image[3], origin = 'lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05764718-1579-4049-8777-8089b6777f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = counter_frames\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 4, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow(image[0], origin ='lower')\n",
    "ax[1].imshow(image[1], origin = 'lower')\n",
    "ax[2].imshow(image[2], origin = 'lower')\n",
    "ax[3].imshow(image[3], origin = 'lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd27ff-4332-4127-b4cd-0cddc20eae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = masks\n",
    "\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "\n",
    "ax.imshow(image[0], origin ='lower')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5d091-49d7-45f8-b649-71a16d5f420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "val_loss = train_dataset.full_inference(randint, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3a5f4-0c89-4a56-b5bd-69faa041d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_loss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384e995-d98c-4d0b-b51a-3e88e1cadc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = val_loss[1]\n",
    "\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "\n",
    "ax.imshow(image[0] > 0.2, origin ='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05532232-2120-498f-bed0-7c0c5a7b8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = val_loss[2]\n",
    "\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "\n",
    "ax.imshow(image, origin ='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da90733b-2fd8-4267-aa3c-856f3fe280b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9825cd9-6255-49b5-9ff1-1c9c7b6168f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tiles = train_dataset.sequential_tile(masks)\n",
    "print(mask_tiles[(0,0)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881588f1-ff13-475a-84ac-dc84edd71ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_reconstruct_raw, mask_reconstruct_counter = train_dataset.tile_reconstruct(mask_tiles)\n",
    "print(mask_reconstruct_counter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a707ef72-829b-4c55-9f45-ed061ba03418",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mask_reconstruct_raw.squeeze(0).squeeze()\n",
    "\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "\n",
    "ax.imshow(image, origin ='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd32b582-e805-4a4c-8e5a-dd413ccaa784",
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5a1dc-b4c0-4b7e-9f8f-1b15a2c42068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63b49e-13ca-41ff-baad-4a81dd2becf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holodec",
   "language": "python",
   "name": "holodec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
