{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a575b36-2617-47bf-b025-1f523a5f6436",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28e4f0-d7a3-4878-b3bf-4e8e3190d9dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Libraries, Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff86707-cc39-4df1-a6b2-edef5cca34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import xarray as xr\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from holodecml.propagation import InferencePropagator\n",
    "from holodecml.transforms import LoadTransformations\n",
    "from echo.src.base_objective import BaseObjective\n",
    "\n",
    "# from holodecml.seed import seed_everything\n",
    "from holodecml.data import XarrayReader\n",
    "from holodecml.models import load_model\n",
    "from holodecml.losses import load_loss\n",
    "\n",
    "from collections import defaultdict\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import torch.fft\n",
    "import logging\n",
    "import shutil\n",
    "import random\n",
    "import psutil\n",
    "import optuna\n",
    "import torch\n",
    "import time\n",
    "import tqdm\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import yaml\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e329c8d7-b121-4f59-88d2-2857deac148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0677629-00c3-4278-b01f-0d5c83c0af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "print(is_cuda)\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")\n",
    "print(device)\n",
    "if is_cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    #torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00601ee-f398-4e16-b6f5-396c7a1b4d43",
   "metadata": {},
   "source": [
    "### Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196a54d2-b374-4ac0-8e66-d8914c2145da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_training.nc\"\n",
    "test_dataset_path = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_validation.nc\"\n",
    "\n",
    "conf_file_path = \"../config/frame_matching_model_segmentation.yml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44639ef1-df3c-49b9-b91a-3a2528054548",
   "metadata": {},
   "source": [
    "### Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d621df-5574-41c2-9041-a0c1c31bc06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29c76903-9f83-4e98-9db5-fd320e2c0020",
   "metadata": {},
   "source": [
    "### Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ca7777-4ea8-4eb4-93fb-81ea40d14ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavePropagator(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 n_bins=1000,\n",
    "                 step_size=128,\n",
    "                 tile_size = 128,\n",
    "                 marker_size=10,\n",
    "                 transform_mode=None,\n",
    "                 device=\"cpu\"):\n",
    "\n",
    "        self.h_ds = xr.open_dataset(data_path)\n",
    "\n",
    "\n",
    "        if 'zMin' in self.h_ds.attrs:\n",
    "            self.zMin = self.h_ds.attrs['zMin']  # minimum z in sample volume\n",
    "            self.zMax = self.h_ds.attrs['zMax']\n",
    "        else:  # some of the raw data does not have this parameter\n",
    "            # should warn the user here through the logger\n",
    "            self.zMin = 0.014\n",
    "            self.zMax = 0.158 #15.8 - 1.4 / (1000)\n",
    "\n",
    "        self.n_bins = n_bins\n",
    "        self.z_bins = np.linspace(\n",
    "            self.zMin, self.zMax, n_bins+1)*1e6  # histogram bin edges\n",
    "        self.z_centers = self.z_bins[:-1] + 0.5 * \\\n",
    "            np.diff(self.z_bins)  # histogram bin center\n",
    "        \n",
    "        self.tile_size = step_size\n",
    "        self.step_size = tile_size\n",
    "        \n",
    "        # UNET gaussian marker width (standard deviation) in um\n",
    "        self.marker_size = marker_size\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "        self.dx = self.h_ds.attrs['dx']      # horizontal resolution\n",
    "        self.dy = self.h_ds.attrs['dy']      # vertical resolution\n",
    "        self.Nx = int(self.h_ds.attrs['Nx'])  # number of horizontal pixels\n",
    "        self.Ny = int(self.h_ds.attrs['Ny'])  # number of vertical pixels\n",
    "        self.lam = self.h_ds.attrs['lambda']  # wavelength\n",
    "        self.image_norm = 255.0\n",
    "        self.transform_mode = transform_mode\n",
    "        self.x_arr = np.arange(-self.Nx//2, self.Nx//2)*self.dx\n",
    "        self.y_arr = np.arange(-self.Ny//2, self.Ny//2)*self.dy\n",
    "\n",
    "        self.tile_x_bins = np.arange(-self.Nx//2,\n",
    "                                     self.Nx//2, self.step_size)*self.dx*1e6\n",
    "        self.tile_y_bins = np.arange(-self.Ny//2,\n",
    "                                     self.Ny//2, self.step_size)*self.dy*1e6\n",
    "\n",
    "        self.fx = torch.fft.fftfreq(\n",
    "            self.Nx, self.dx, device=self.device).unsqueeze(0).unsqueeze(2)\n",
    "        self.fy = torch.fft.fftfreq(\n",
    "            self.Ny, self.dy, device=self.device).unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        \n",
    "        self.create_mapping()\n",
    "    def torch_holo_set(self,\n",
    "                       Ein: torch.tensor,\n",
    "                       z_tnsr: torch.tensor):\n",
    "        \"\"\"\n",
    "        Propagates an electric field a distance z\n",
    "        Ein complex torch.tensor\n",
    "        - input electric field\n",
    "\n",
    "        fx:real torch.tensor\n",
    "        - x frequency axis (3D, setup to broadcast)\n",
    "\n",
    "        fy: real torch.tensor\n",
    "        - y frequency axis (3D, setup to broadcast)\n",
    "\n",
    "        z_tnsr: torch.tensor\n",
    "        - tensor of distances to propagate the wave Ein\n",
    "            expected to have dims (Nz,1,1) where Nz is the number of z\n",
    "            dimensions\n",
    "\n",
    "        lam: float\n",
    "        - wavelength\n",
    "\n",
    "        returns: complex torch.tensor with dims (Nz,fy,fx)\n",
    "\n",
    "        Note the torch.fft library uses dtype=torch.complex64\n",
    "        This may be an issue for GPU implementation\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.transform_mode == \"standard\":\n",
    "            Ein = Ein.float()\n",
    "            Ein -= torch.mean(Ein)\n",
    "            Ein /= torch.std(Ein)\n",
    "\n",
    "        elif self.transform_mode == \"min-max\":\n",
    "            Ein = Ein.float()\n",
    "            Ein -= torch.min(Ein)\n",
    "            Ein /= torch.max(Ein)\n",
    "\n",
    "        Etfft = torch.fft.fft2(Ein)\n",
    "        Eofft = Etfft*torch.exp(1j*2*np.pi*z_tnsr/self.lam *\n",
    "                                torch.sqrt(1-self.lam**2*(self.fx**2+self.fy**2)))\n",
    "\n",
    "        # It might be helpful if we could omit this step.  It would save an inverse fft.\n",
    "        Eout = torch.fft.ifft2(Eofft)\n",
    "        return Eout\n",
    "    \n",
    "    \n",
    "    def create_mapping(self):\n",
    "        \"\"\"\n",
    "        Create map from tile coordinates (x,y) to indices to slice in image to extract that tile. \n",
    "        \"\"\"\n",
    "        self.idx2slice = {}\n",
    "        for row_idx in range(self.Nx//self.step_size):\n",
    "\n",
    "            if row_idx*self.step_size+self.tile_size > self.Nx:\n",
    "                image_pixel_x = self.Nx-self.tile_size\n",
    "                row_slice = slice(-self.tile_size, None)\n",
    "                row_break = True\n",
    "            else:\n",
    "                image_pixel_x = row_idx*self.step_size\n",
    "                row_slice = slice(row_idx*self.step_size,\n",
    "                                  row_idx*self.step_size+self.tile_size)\n",
    "                row_break = False\n",
    "\n",
    "            for col_idx in range(self.Ny//self.step_size):\n",
    "\n",
    "                if col_idx*self.step_size+self.tile_size > self.Ny:\n",
    "                    image_pixel_y = self.Ny-self.tile_size\n",
    "                    col_slice = slice(-self.tile_size, None)\n",
    "                    col_break = True\n",
    "                else:\n",
    "                    image_pixel_y = col_idx*self.step_size\n",
    "                    col_slice = slice(col_idx*self.step_size,\n",
    "                                      col_idx*self.step_size+self.tile_size)\n",
    "                    col_break = False\n",
    "\n",
    "                self.idx2slice[row_idx, col_idx] = (row_slice, col_slice)\n",
    "\n",
    "                if col_break:\n",
    "                    break\n",
    "\n",
    "            if row_break:\n",
    "                break\n",
    "                \n",
    "                \n",
    "                \n",
    "    def collate_image(self, idx_dict, image = None, mask = None):\n",
    "        x, y = zip(*[(image[:, row_slice, col_slice], mask[row_slice, col_slice]) for ((row_idx, col_idx, row_slice, col_slice)) in idx_dict])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff1fb22-8b00-4ec2-a664-a1386d55c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(prop, h_idx, z_idx, z_ref):\n",
    "    hid = h_idx + 1\n",
    "    hid_mask = prop.h_ds[\"hid\"] == hid\n",
    "\n",
    "    # Filter particles based on h_idx\n",
    "    x_part = prop.h_ds[\"x\"].values[hid_mask]\n",
    "    y_part = prop.h_ds[\"y\"].values[hid_mask]\n",
    "    z_part = prop.h_ds[\"z\"].values[hid_mask]\n",
    "    d_part = prop.h_ds[\"d\"].values[hid_mask]\n",
    "\n",
    "    z_indices = np.digitize(z_part, prop.z_bins) - 1\n",
    "    # Initialize the UNET mask\n",
    "    unet_mask = np.zeros((prop.x_arr.shape[0], prop.y_arr.shape[0]))\n",
    "    z_mask = np.zeros((prop.x_arr.shape[0], prop.y_arr.shape[0]))\n",
    "    num_particles = 0 \n",
    "    \n",
    "    if z_idx in z_indices:\n",
    "        cond = np.where(z_idx == z_indices)\n",
    "        x_part = x_part[cond]\n",
    "        y_part = y_part[cond]\n",
    "        z_part = z_part[cond]\n",
    "        d_part = d_part[cond]\n",
    "        \n",
    "        #print(x_part, y_part, z_part, d_part)\n",
    "        \n",
    "        # Build the UNET mask using vectorized operations\n",
    "        for part_idx in range(len(cond[0])):\n",
    "            y_diff = (prop.y_arr[None, :] * 1e6 - y_part[part_idx])\n",
    "            x_diff = (prop.x_arr[:, None] * 1e6 - x_part[part_idx])\n",
    "            d_squared = (d_part[part_idx] / 2)**2\n",
    "            unet_mask += ((y_diff**2 + x_diff**2) < d_squared).astype(float)\n",
    "            z_diff = (z_part - z_ref)\n",
    "            for particle in z_diff:\n",
    "                z_mask += ((y_diff**2 + x_diff**2) < d_squared).astype(float) * particle\n",
    "                num_particles += 1\n",
    "\n",
    "    return torch.from_numpy(unet_mask).unsqueeze(0), num_particles, torch.from_numpy(z_mask).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6738f6a7-9c81-490e-8368-a733aaebc758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadHolograms(Dataset):\n",
    "    \n",
    "    def __init__(self, file_path, n_bins = 1000, shuffle = False, device = \"cpu\", transform = False, lookahead =0, step_size = 32, tile_size = 32):\n",
    "        \n",
    "        # num of waveprop windows\n",
    "        self.n_bins = n_bins\n",
    "        # device used\n",
    "        self.device = device\n",
    "        # shuffle frames\n",
    "        self.shuffle = shuffle\n",
    "        # num of frames to look ahead\n",
    "        self.lookahead = lookahead\n",
    "        # wavepropagator object on device\n",
    "        self.propagator = WavePropagator(file_path, n_bins = n_bins, device = device, step_size = step_size, tile_size = tile_size)\n",
    "        self.transform = transform\n",
    "        self.indices =  [(x,y) for x in self.propagator.h_ds.hologram_number for y in range(self.n_bins - self.lookahead)]\n",
    "        \n",
    "        self.tile_size = tile_size\n",
    "        self.idx2slice = self.propagator.idx2slice\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) * len(self.idx2slice)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.shuffle:\n",
    "            idx = random.choice(range(self.__len__()))\n",
    "            \n",
    "        #hologram_idx = idx // self.n_bins \n",
    "        #plane_idx = idx // len(self.propagator.h_ds.hologram_number)\n",
    "        hologram_idx, plane_idx = self.indices[(idx) // len(self.idx2slice)]\n",
    "        z_props = self.propagator.z_centers[plane_idx: plane_idx + self.lookahead + 1]\n",
    "        z_props -= (z_props[1] - z_props[0]) / 2\n",
    "        plane_indices = np.arange(plane_idx, plane_idx + self.lookahead + 1)\n",
    "        # select hologram\n",
    "        image = self.propagator.h_ds[\"image\"].isel(hologram_number=hologram_idx).values\n",
    "        \n",
    "        im = {\n",
    "            \"image\": np.expand_dims(image, 0),\n",
    "            \"horizontal_flip\": False,\n",
    "            \"vertical_flip\": False\n",
    "        }\n",
    "\n",
    "        # add transformations here\n",
    "        if self.transform:\n",
    "            for image_transform in self.transform:\n",
    "                im = image_transform(im)\n",
    "        image = im[\"image\"]\n",
    "        \n",
    "        # Update the mask if we flipped the original image\n",
    "        \n",
    "        \n",
    "        # prop\n",
    "        \n",
    "        # make tensors of size lookahead + 1, and then add tensors\n",
    "        prop_synths = []\n",
    "        prop_phases = []\n",
    "        masks = []\n",
    "        z_masks = []\n",
    "        particles_in_frames = []\n",
    "        \n",
    "        #num_frames = len(plane_indices)\n",
    "        #idx_ran = random.choice(range(num_frames))\n",
    "        #z_prop = z_props[idx_ran]\n",
    "        #z_ind = plane_indices[idx_ran]\n",
    "        \n",
    "        for k, (z_prop, z_ind) in enumerate(zip(z_props, plane_indices)):\n",
    "            image_prop = self.propagator.torch_holo_set(\n",
    "                image.to(self.device),\n",
    "                torch.FloatTensor([z_prop*1e-6]).to(self.device)\n",
    "            )\n",
    "            # ABS (x-input)\n",
    "            prop_synth = torch.abs(image_prop)\n",
    "            prop_synths.append(prop_synth)\n",
    "            # Phase (x-input)\n",
    "            prop_phase = torch.angle(image_prop)\n",
    "            prop_phases.append(prop_phase)  \n",
    "            # Mask (y-label)\n",
    "            if k == 0:\n",
    "                mask, num_particles, z_mask = create_mask(self.propagator, hologram_idx, z_ind, z_props[0])\n",
    "                if im[\"horizontal_flip\"]:\n",
    "                    mask = torch.flip(mask, dims=(1,))\n",
    "                    z_mask = torch.flip(z_mask, dims= (1,))\n",
    "                if im[\"vertical_flip\"]:\n",
    "                    mask = torch.flip(mask, dims=(2,))\n",
    "                    z_mask = torch.flip(z_mask, dims= (2,))\n",
    "                masks.append(mask)\n",
    "                z_masks.append(z_mask)\n",
    "\n",
    "        \n",
    "        \n",
    "        # cat target frames with lookahead context frames, convert to ndarrays\n",
    "        synth_window = torch.cat(prop_synths, dim = 0)\n",
    "        phases_window = torch.cat(prop_phases, dim = 0)\n",
    "        masks_window = torch.cat(masks, dim = 0)\n",
    "        z_masks_window = torch.cat(z_masks, dim = 0)\n",
    "        z_masks_window /= (z_props[1] - z_props[0])\n",
    "        \n",
    "        # cat images and masks in color dim (0 since batch not added yet)\n",
    "        image_stack = torch.cat([synth_window, phases_window], dim = 0)\n",
    "        masks_stack = torch.cat([masks_window, z_masks_window], dim = 0)\n",
    "        \n",
    "        #get tiles, slicing along coords in idx2slice array that maps coord position to slice range\n",
    "        slice_coords = self.idx2slice[list(self.idx2slice)[idx % len(self.idx2slice)]]\n",
    "        image_stack = image_stack[:, slice_coords[0], slice_coords[1]]\n",
    "        masks_stack = masks_stack[:, slice_coords[0], slice_coords[1]]\n",
    "        \n",
    "        return (image_stack, masks_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d924c-7c3d-4808-bf74-75c63acc6573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8c094bb-e09f-49c6-ab0d-3fbfeaa69183",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb4aeb13-7109-4a35-9a54-a31286ca0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# load in from config file\n",
    "with open(conf_file_path) as cf:\n",
    "    conf = yaml.load(cf, Loader=yaml.FullLoader)\n",
    "\n",
    "        \n",
    "# edit color channels to be compatible with lookahead\n",
    "conf[\"model\"][\"in_channels\"] = 2 * (conf[\"data\"][\"lookahead\"] + 1)\n",
    "\n",
    "# load transformations from config\n",
    "if \"Normalize\" in conf[\"transforms\"][\"training\"]:\n",
    "    conf[\"transforms\"][\"validation\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\n",
    "        \"training\"\n",
    "    ][\"Normalize\"][\"mode\"]\n",
    "    conf[\"transforms\"][\"inference\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\n",
    "        \"training\"\n",
    "    ][\"Normalize\"][\"mode\"]\n",
    "\n",
    "train_transforms = LoadTransformations(conf[\"transforms\"][\"training\"])\n",
    "valid_transforms = LoadTransformations(conf[\"transforms\"][\"validation\"])\n",
    "\n",
    "# load lookahead depth from config\n",
    "lookahead = int(conf[\"data\"][\"lookahead\"])\n",
    "\n",
    "# Set up CUDA/CPU devices\n",
    "is_cuda = torch.cuda.is_available()\n",
    "data_device = (\n",
    "    torch.device(\"cpu\") if \"device\" not in conf[\"data\"] else conf[\"data\"][\"device\"]\n",
    ")\n",
    "\n",
    "if torch.cuda.device_count() >= 2 and \"cuda\" in data_device:\n",
    "    data_device = \"cuda:0\"\n",
    "    device = \"cuda:1\"\n",
    "    device_ids = list(range(1, torch.cuda.device_count()))\n",
    "else:\n",
    "    data_device = torch.device(\"cpu\")\n",
    "    device = (\n",
    "        torch.device(torch.cuda.current_device())\n",
    "        if is_cuda\n",
    "        else torch.device(\"cpu\")\n",
    "    )\n",
    "    device_ids = list(range(torch.cuda.device_count()))\n",
    "logging.info(f\"There are {torch.cuda.device_count()} GPUs available\")\n",
    "logging.info(\n",
    "    f\"Using device {data_device} to perform wave propagation, and {device_ids} for training the model\"\n",
    ")\n",
    "\n",
    "\n",
    "# load tiling size\n",
    "step_size = int(conf[\"data\"][\"step_size\"])\n",
    "\n",
    "\n",
    "# hard code shuffle, n_bins\n",
    "shuffle =False\n",
    "n_bins = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daf0d523-bbfc-4ae4-8b9f-f5dcd59f66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "\n",
    "train_dataset = LoadHolograms(\"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_training.nc\", shuffle = shuffle, device = data_device, n_bins = n_bins, transform = train_transforms, lookahead = 1, tile_size = 256, step_size = 128)\n",
    "\n",
    "test_dataset = LoadHolograms(\"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_validation.nc\", shuffle = False, device = data_device, n_bins = n_bins, transform = valid_transforms, lookahead = 1, tile_size = 156, step_size = 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb891c4b-e4aa-4087-995f-3220e513f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_particle_rate(dataloader, niter):\n",
    "    nparticles = 0\n",
    "    generator = tqdm.tqdm(range(niter))\n",
    "    for i in generator:\n",
    "        r = random.randrange(dataloader.__len__())\n",
    "        holo, label = dataloader.__getitem__(r)\n",
    "        if (int(torch.count_nonzero(label)) != 0):\n",
    "            nparticles += 1\n",
    "        generator.set_description(str(nparticles/niter))\n",
    "        generator.update()\n",
    "    return(nparticles/niter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b382af6-d5cb-4d8e-a2e7-574fc7e9a7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0033333333333333335: 100%|██████████| 300/300 [23:38<00:00,  4.73s/it]\n"
     ]
    }
   ],
   "source": [
    "ratio = present_particle_rate(train_dataset, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db91d4d-95a3-40b1-aa79-1a5f524ba796",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d3640-56ed-4b0a-9102-1ead36dca008",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.__getitem__(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e060d-331c-4c1d-a55e-c203ac346eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check loading\n",
    "rand_img_raw, rand_masks_raw = test_dataset.__getitem__(2540)\n",
    "image = rand_img_raw\n",
    "print(len(image))\n",
    "\n",
    "fontsize = 10\n",
    "single_column_width = 10\n",
    "plt.figure(figsize = (single_column_width/30, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(2, 4, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow(image[0], origin ='lower')\n",
    "ax[1].imshow(image[1], origin = 'lower')\n",
    "ax[2].imshow(image[2], origin = 'lower')\n",
    "ax[3].imshow(image[3], origin = 'lower')\n",
    "ax[4].imshow(image[4], origin = 'lower')\n",
    "ax[5].imshow(image[5], origin = 'lower')\n",
    "ax[6].imshow(image[6], origin = 'lower')\n",
    "ax[7].imshow(image[7], origin = 'lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5622087e-e73a-43bd-8310-2205702931fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check masks\n",
    "image = rand_masks_raw\n",
    "print(image.shape)\n",
    "print(len(image))\n",
    "\n",
    "\n",
    "fontsize = 10\n",
    "single_column_width = 7\n",
    "plt.figure(figsize = (single_column_width, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(single_column_width, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow(image[0], origin ='lower')\n",
    "ax[1].imshow(image[1], origin = 'lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabd3e5-387c-4d4c-8ba9-15e804fe216a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946e9c3-6d08-4369-89fc-dfd2dba746e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "panic_y = torch.load('../results/zlossinv/yclone_train.pt').cpu()\n",
    "panic_x = torch.load('../results/zlossinv/xclone_train.pt').cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd4655-ffa3-48f6-a62c-5e7b9716c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(panic_y.shape)\n",
    "print(panic_x.shape)\n",
    "\n",
    "#assert not torch.isnan(panic_y).any()\n",
    "#assert not torch.isnan(panic_x).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc8f25-7c3e-4cc6-9e19-fca2625fdb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_indices = torch.nonzero(torch.isnan(panic_y), as_tuple=True)\n",
    "print(nan_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3319a-a4e7-4e0c-9e49-20dc36b56e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nan_indices[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492a8d1-9fd3-4475-9a1c-799522d43c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e656cb-26fb-4517-80eb-f3b6702ad91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "panic_y0 = panic_y[:,0:1,:,:].squeeze(dim = 1)\n",
    "panic_y1 = panic_y[:,:1:2,:,:].squeeze(dim = 1)\n",
    "print(panic_y0.shape)\n",
    "print(panic_y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8df0ece-3b9d-4d69-a0a8-01ce0657a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 10\n",
    "single_column_width = 40\n",
    "plt.figure(figsize = (20, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(8, 1, figsize=(20, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow(panic_y0[0], origin ='lower')\n",
    "ax[1].imshow(panic_y0[1], origin ='lower')\n",
    "ax[2].imshow(panic_y0[2], origin ='lower')\n",
    "ax[3].imshow(panic_y0[3], origin ='lower')\n",
    "ax[4].imshow(panic_y0[4], origin ='lower')\n",
    "ax[5].imshow(panic_y0[5], origin ='lower')\n",
    "ax[6].imshow(panic_y0[6], origin ='lower')\n",
    "ax[7].imshow(panic_y0[7], origin ='lower')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b11017-2bca-47bb-b44f-22f3e226c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 10\n",
    "single_column_width = 40\n",
    "plt.figure(figsize = (20, single_column_width / 1.61803398875))\n",
    "fig, ax = plt.subplots(8, 1, figsize=(20, single_column_width * 1.61803398875), \n",
    "                         gridspec_kw={'hspace': 0.0, 'wspace': 0.2})\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow(panic_y1[0], origin ='lower')\n",
    "ax[1].imshow(panic_y1[1], origin ='lower')\n",
    "ax[2].imshow(panic_y1[2], origin ='lower')\n",
    "ax[3].imshow(panic_y1[3], origin ='lower')\n",
    "ax[4].imshow(panic_y1[4], origin ='lower')\n",
    "ax[5].imshow(panic_y1[5], origin ='lower')\n",
    "ax[6].imshow(panic_y1[6], origin ='lower')\n",
    "ax[7].imshow(panic_y1[7], origin ='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9be1f7-a707-43a4-85a7-ebbd1382c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not torch.isnan(panic_y1[5]).any()\n",
    "panic_y1[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088629e-42be-49cd-bc28-a3303d860dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not torch.isnan(panic_y1[7]).any()\n",
    "\n",
    "panic_y1[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4a828-7739-49a7-8a48-6e8214fc00f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holodec",
   "language": "python",
   "name": "holodec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
