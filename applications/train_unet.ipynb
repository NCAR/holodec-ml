{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"/glade/work/schreck/repos/HOLO/clean/holodec-ml\")\n",
    "from holodecml.data import *\n",
    "from holodecml.losses import *\n",
    "from holodecml.models import *\n",
    "from holodecml.metrics import *\n",
    "from holodecml.transforms import *\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import time\n",
    "import yaml\n",
    "import torch\n",
    "import shutil\n",
    "import pickle\n",
    "import joblib\n",
    "import random\n",
    "import sklearn\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "import torch.fft\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from collections import defaultdict\n",
    "from scipy.signal import convolve2d\n",
    "from torch.optim.lr_scheduler import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from typing import List, Dict, Callable, Union, Any, TypeVar, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up logger to print stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(levelname)s:%(name)s:%(message)s')\n",
    "\n",
    "# Stream output to stdout\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(formatter)\n",
    "root.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the GPU device id, or CPU if no GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the configuration and get the relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = \"/glade/work/schreck/repos/HOLO/clean/holodec-ml/results/unet_const_noisy/model.yml\"\n",
    "config = \"../config/unet_propagation.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config) as cf:\n",
    "    conf = yaml.load(cf, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = conf[\"data\"][\"tile_size\"]\n",
    "step_size = conf[\"data\"][\"step_size\"]\n",
    "data_path = conf[\"data\"][\"output_path\"]\n",
    "\n",
    "fn_train = f\"{data_path}/training_{tile_size}_{step_size}.pkl\"\n",
    "fn_valid = f\"{data_path}/validation_{tile_size}_{step_size}.pkl\"\n",
    "\n",
    "epochs = conf[\"trainer\"][\"epochs\"]\n",
    "train_batch_size = conf[\"trainer\"][\"train_batch_size\"]\n",
    "valid_batch_size = conf[\"trainer\"][\"valid_batch_size\"]\n",
    "batches_per_epoch = conf[\"trainer\"][\"batches_per_epoch\"]\n",
    "stopping_patience = conf[\"trainer\"][\"stopping_patience\"]\n",
    "model_loc = conf[\"trainer\"][\"output_path\"]\n",
    "\n",
    "model_name = conf[\"model\"][\"name\"]\n",
    "color_dim = conf[\"model\"][\"color_dim\"]\n",
    "inference_mode = conf[\"model\"][\"mode\"]\n",
    "\n",
    "learning_rate = conf[\"optimizer\"][\"learning_rate\"]\n",
    "weight_decay = conf[\"optimizer\"][\"weight_decay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/glade/work/schreck/repos/HOLO/clean/holodec-ml/results/baseline/model.yml'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(model_loc, exist_ok = True)\n",
    "shutil.copy(config, os.path.join(model_loc, \"model.yml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the preprocessing transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.transforms:Loaded RandomVerticalFlip transformation with probability 0.5\n",
      "INFO:holodecml.transforms:Loaded RandomHorizontalFlip transformation with probability 0.5\n",
      "INFO:holodecml.transforms:Loaded Normalize transformation that normalizes data color channel by dividing by 255.0 and phase pi\n",
      "INFO:holodecml.transforms:Loaded ToTensor transformation\n",
      "INFO:holodecml.transforms:Loaded Normalize transformation that normalizes data color channel by dividing by 255.0 and phase pi\n",
      "INFO:holodecml.transforms:Loaded ToTensor transformation\n"
     ]
    }
   ],
   "source": [
    "train_transforms = LoadTransformations(conf[\"transforms\"][\"training\"])\n",
    "valid_transforms = LoadTransformations(conf[\"transforms\"][\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data class for reading and preparing the data as needed to train the u-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = PickleReader(\n",
    "#     fn_train, \n",
    "#     transform = train_transforms,\n",
    "#     max_images = int(0.8 * conf[\"data\"][\"total_training\"]), \n",
    "#     max_buffer_size = int(0.1 * conf[\"data\"][\"total_training\"]), \n",
    "#     color_dim = color_dim,\n",
    "#     shuffle = True\n",
    "# )\n",
    "\n",
    "train_dataset = UpsamplingReader(\n",
    "    conf,\n",
    "    transform = train_transforms,\n",
    "    max_size = 1000\n",
    ")\n",
    "\n",
    "test_dataset = PickleReader(\n",
    "    fn_valid,\n",
    "    transform = valid_transforms,\n",
    "    max_images = int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "    max_buffer_size = int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "    color_dim = color_dim,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y = train_dataset.__getitem__(8)\n",
    "#plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the iterators for batching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size, \n",
    "    num_workers=16, # can increase to number of CPUs you asked for in launch script; usually 8\n",
    "    pin_memory=True,\n",
    "    shuffle=True) # let the reader do the shuffling\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=valid_batch_size,\n",
    "    #num_workers=8,\n",
    "    pin_memory=True,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a u-net model (resnet based on https://www.kaggle.com/bigironsphere/loss-function-library-keras-pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = ResNetUNet(n_class = 1, color_dim = color_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in unet.parameters())\n",
    "trainable_params = sum(p.numel() for p in unet.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18310121"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    unet.parameters(), \n",
    "    lr=learning_rate, \n",
    "    weight_decay=weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the training and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_criterion = DiceBCELoss()\n",
    "test_criterion = DiceLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    patience = 1, \n",
    "    min_lr = 1.0e-13,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a U-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 train_loss: 1.6053 lr: 0.000100000000: 100%|██████████| 500/500 [03:23<00:00,  2.46it/s]\n",
      "Epoch 0 test_loss: 0.9982: : 157it [01:35,  1.65it/s]\n",
      "Epoch 1 train_loss: 1.3663 lr: 0.000100000000: 100%|██████████| 500/500 [03:26<00:00,  2.43it/s]\n",
      "Epoch 1 test_loss: 0.9963: : 157it [01:26,  1.82it/s]\n",
      "Epoch 2 train_loss: 1.1680 lr: 0.000100000000: 100%|██████████| 500/500 [03:26<00:00,  2.42it/s]\n",
      "Epoch 2 test_loss: 0.9925: : 157it [01:26,  1.81it/s]\n",
      "Epoch 3 train_loss: 1.0694 lr: 0.000100000000: 100%|██████████| 500/500 [03:26<00:00,  2.42it/s]\n",
      "Epoch 3 test_loss: 0.9844: : 157it [01:28,  1.78it/s]\n",
      "Epoch 4 train_loss: 1.0161 lr: 0.000100000000: 100%|██████████| 500/500 [03:26<00:00,  2.42it/s]\n",
      "Epoch 4 test_loss: 0.9651: : 157it [01:27,  1.80it/s]\n",
      "Epoch 5 train_loss: 0.9579 lr: 0.000100000000: 100%|██████████| 500/500 [03:26<00:00,  2.42it/s]\n",
      "Epoch 5 test_loss: 0.8399: : 157it [01:26,  1.81it/s]\n",
      "Epoch 6 train_loss: 0.5760 lr: 0.000100000000: 100%|██████████| 500/500 [03:26<00:00,  2.42it/s]\n",
      "Epoch 6 test_loss: 0.1917: : 157it [01:26,  1.81it/s]\n",
      "Epoch 7 train_loss: 0.1486 lr: 0.000100000000: 100%|██████████| 500/500 [03:26<00:00,  2.42it/s]\n",
      "Epoch 7 test_loss: 0.0649: : 157it [01:26,  1.82it/s]\n",
      "Epoch 8 train_loss: 0.0917 lr: 0.000100000000: 100%|██████████| 500/500 [03:26<00:00,  2.42it/s]\n",
      "Epoch 8 test_loss: 0.0536: : 157it [01:25,  1.83it/s]\n",
      "Epoch 9 train_loss: 0.0703 lr: 0.000100000000: 100%|██████████| 500/500 [03:26<00:00,  2.42it/s]\n",
      "Epoch 9 test_loss: 0.0465: : 157it [01:25,  1.84it/s]\n",
      "Epoch 10 train_loss: 0.0805 lr: 0.000100000000: 100%|██████████| 500/500 [03:26<00:00,  2.42it/s]\n",
      "Epoch 10 test_loss: 0.0460: : 157it [01:26,  1.82it/s]\n",
      "Epoch 11 train_loss: 0.0571 lr: 0.000100000000: 100%|██████████| 500/500 [03:26<00:00,  2.43it/s]\n",
      "Epoch 11 test_loss: 0.0431: : 157it [01:29,  1.76it/s]\n",
      "Epoch 12 train_loss: 0.0591 lr: 0.000100000000: : 524it [03:22,  2.46it/s]                       "
     ]
    }
   ],
   "source": [
    "epoch_test_losses = []\n",
    "results_dict = defaultdict(list)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    ### Train the model \n",
    "    unet.train()\n",
    "\n",
    "    batch_loss = []\n",
    "        \n",
    "    # set up a custom tqdm\n",
    "    batch_group_generator = tqdm.tqdm(\n",
    "        enumerate(train_loader), \n",
    "        total=batches_per_epoch,\n",
    "        leave=True\n",
    "    )\n",
    " \n",
    "    for k, (inputs, y) in batch_group_generator:\n",
    "        \n",
    "        # Move data to the GPU, if not there already\n",
    "        inputs = inputs.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        \n",
    "        # Clear gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output from the model, given the inputs\n",
    "        pred_mask = unet(inputs)\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        loss = train_criterion(pred_mask, y)\n",
    "                \n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # update tqdm\n",
    "        to_print = \"Epoch {} train_loss: {:.4f}\".format(epoch, np.mean(batch_loss))\n",
    "        to_print += \" lr: {:.12f}\".format(optimizer.param_groups[0]['lr'])\n",
    "        batch_group_generator.set_description(to_print)\n",
    "        batch_group_generator.update()\n",
    "                     \n",
    "        # stop the training epoch when train_batches_per_epoch have been used to update \n",
    "        # the weights to the model\n",
    "        if k >= batches_per_epoch and k > 0:\n",
    "            break\n",
    "            \n",
    "        #lr_scheduler.step(epoch + k / batches_per_epoch)\n",
    "        \n",
    "    # Shutdown the progbar\n",
    "    batch_group_generator.close()\n",
    "        \n",
    "    # Compuate final performance metrics before doing validation\n",
    "    train_loss = np.mean(batch_loss)\n",
    "        \n",
    "    # clear the cached memory from the gpu\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ### Test the model \n",
    "    unet.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        batch_loss = []\n",
    "        \n",
    "        # set up a custom tqdm\n",
    "        batch_group_generator = tqdm.tqdm(\n",
    "            enumerate(test_loader),\n",
    "            leave=True\n",
    "        )\n",
    "\n",
    "        for k, (inputs, y) in batch_group_generator:\n",
    "            # Move data to the GPU, if not there already\n",
    "            inputs = inputs.to(device).float()\n",
    "            y = y.to(device).float()\n",
    "            # get output from the model, given the inputs\n",
    "            pred_mask = unet(inputs)\n",
    "            # get loss for the predicted output\n",
    "            loss = test_criterion(pred_mask, y)\n",
    "            batch_loss.append(loss.item())\n",
    "            # update tqdm\n",
    "            to_print = \"Epoch {} test_loss: {:.4f}\".format(epoch, np.mean(batch_loss))\n",
    "            batch_group_generator.set_description(to_print)\n",
    "            batch_group_generator.update()\n",
    "            \n",
    "        # Shutdown the progbar\n",
    "        batch_group_generator.close()\n",
    "\n",
    "    # Use the accuracy as the performance metric to toggle learning rate and early stopping\n",
    "    test_loss = np.mean(batch_loss)\n",
    "    epoch_test_losses.append(test_loss)\n",
    "    \n",
    "    # Lower the learning rate if we are not improving\n",
    "    lr_scheduler.step(test_loss)\n",
    "\n",
    "    # Save the model if its the best so far.\n",
    "    if test_loss == min(epoch_test_losses):\n",
    "        state_dict = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': unet.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': test_loss\n",
    "        }\n",
    "        #TODO: add directory\n",
    "        torch.save(state_dict, f\"{model_loc}/best.pt\")\n",
    "        \n",
    "    # Get the last learning rate\n",
    "    learning_rate = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "    # Put things into a results dictionary -> dataframe\n",
    "    results_dict['epoch'].append(epoch)\n",
    "    results_dict['train_loss'].append(train_loss)\n",
    "    results_dict['valid_loss'].append(np.mean(batch_loss))\n",
    "    results_dict[\"learning_rate\"].append(learning_rate)\n",
    "    df = pd.DataFrame.from_dict(results_dict).reset_index()\n",
    "\n",
    "    # Save the dataframe to disk\n",
    "    df.to_csv(f\"{model_loc}/training_log.csv\", index = False)\n",
    "        \n",
    "    # Stop training if we have not improved after X epochs (stopping patience)\n",
    "    best_epoch = [i for i,j in enumerate(epoch_test_losses) if j == min(epoch_test_losses)][0]\n",
    "    offset = epoch - best_epoch\n",
    "    if offset >= stopping_patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
