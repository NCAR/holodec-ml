{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, os, torch, numpy as np\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "#seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "import torch.fft\n",
    "import subprocess\n",
    "import logging\n",
    "#import random\n",
    "import shutil\n",
    "import psutil\n",
    "import sklearn\n",
    "import scipy\n",
    "#import torch\n",
    "import copy\n",
    "import yaml\n",
    "import time\n",
    "import tqdm\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import torch\n",
    "\n",
    "from holodecml.data import PickleReader, UpsamplingReader, XarrayReader, XarrayReaderLabels\n",
    "from holodecml.propagation import InferencePropagator\n",
    "from holodecml.transforms import LoadTransformations\n",
    "from holodecml.models import load_model\n",
    "from holodecml.losses import load_loss\n",
    "\n",
    "#import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn, sklearn.metrics\n",
    "\n",
    "def man_metrics(results):\n",
    "    result = {}\n",
    "    for metric in [\"f1\", \"auc\", 'pod', \"far\", \"csi\"]: #\"man_prec\", \"man_recall\",\n",
    "        if metric == 'f1':\n",
    "            score = sklearn.metrics.f1_score(results[\"true\"], results[\"pred\"], average = \"weighted\")\n",
    "        elif metric == 'prec':\n",
    "            score = sklearn.metrics.precision_score(results[\"true\"], results[\"pred\"], average = \"weighted\")\n",
    "        elif metric == 'recall':\n",
    "            score = sklearn.metrics.recall_score(results[\"true\"], results[\"pred\"], average = \"weighted\")\n",
    "        elif metric == 'auc':\n",
    "            try:\n",
    "                score = sklearn.metrics.roc_auc_score(results[\"true\"], results[\"pred\"], average = \"weighted\")\n",
    "            except:\n",
    "                score = 1.0\n",
    "        elif metric ==  \"csi\":\n",
    "            try:\n",
    "                TN, FP, FN, TP = sklearn.metrics.confusion_matrix(results[\"true\"], results[\"pred\"]).ravel()\n",
    "                score = TP / (TP + FN + FP)\n",
    "            except:\n",
    "                score = 1\n",
    "        elif metric == 'far':\n",
    "            try:\n",
    "                TN, FP, FN, TP = sklearn.metrics.confusion_matrix(results[\"true\"], results[\"pred\"]).ravel()\n",
    "                score = FP / (TP + FP)\n",
    "            except:\n",
    "                score = 1\n",
    "        elif metric == 'pod':\n",
    "            try:\n",
    "                TN, FP, FN, TP = sklearn.metrics.confusion_matrix(results[\"true\"], results[\"pred\"]).ravel()\n",
    "                score = TP / (TP + FN)\n",
    "            except: \n",
    "                score = 1\n",
    "        result[metric] = score\n",
    "        #print(metric, round(score, 3))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transforms(transforms, image):\n",
    "    im = {\"image\": image}\n",
    "    for image_transform in transforms:\n",
    "        im = image_transform(im)\n",
    "    image = im[\"image\"]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "available_ncpus = len(psutil.Process().cpu_affinity())\n",
    "\n",
    "# Set up the GPU\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\") if not is_cuda else torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Set seeds for reproducibility\n",
    "# def seed_everything(seed=1234):\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.manual_seed(seed)\n",
    "#         torch.backends.cudnn.benchmark = True\n",
    "#         torch.backends.cudnn.deterministic = True\n",
    "        \n",
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"../results/random_test/model.yml\" #\"../config/gan.yml\"\n",
    "with open(config) as cf:\n",
    "    conf = yaml.load(cf, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "seed = 1000 if \"seed\" not in conf else conf[\"seed\"]\n",
    "seed_everything(seed)\n",
    "\n",
    "save_loc = conf[\"save_loc\"]\n",
    "os.makedirs(save_loc, exist_ok = True)\n",
    "os.makedirs(os.path.join(save_loc, \"images\"), exist_ok = True)\n",
    "if not os.path.isfile(os.path.join(save_loc, \"model.yml\")):\n",
    "    shutil.copyfile(config, os.path.join(save_loc, \"model.yml\"))\n",
    "\n",
    "tile_size = int(conf[\"data\"][\"tile_size\"])\n",
    "step_size = int(conf[\"data\"][\"step_size\"])\n",
    "data_path = conf[\"data\"][\"output_path\"]\n",
    "data_path_raw = conf[\"data\"][\"output_path_raw\"]\n",
    "\n",
    "total_positive = int(conf[\"data\"][\"total_positive\"])\n",
    "total_negative = int(conf[\"data\"][\"total_negative\"])\n",
    "total_examples = int(conf[\"data\"][\"total_training\"])\n",
    "\n",
    "transform_mode = \"None\" if \"transform_mode\" not in conf[\"data\"] else conf[\"data\"][\"transform_mode\"]\n",
    "config_ncpus = int(conf[\"data\"][\"cores\"])\n",
    "use_cached = False if \"use_cached\" not in conf[\"data\"] else conf[\"data\"][\"use_cached\"]\n",
    "\n",
    "name_tag = f\"{tile_size}_{step_size}_{total_positive}_{total_negative}_{total_examples}_{transform_mode}\"\n",
    "fn_train = f\"{data_path}/training_{name_tag}.nc\"\n",
    "fn_valid = f\"{data_path}/validation_{name_tag}.nc\"\n",
    "fn_train_raw = data_path_raw\n",
    "#fn_train_raw = f\"{data_path_raw}/training_{name_tag}.nc\"\n",
    "#fn_valid_raw = f\"{data_path_raw}/validation_{name_tag}.nc\"\n",
    "\n",
    "# Trainer params\n",
    "train_batch_size = conf[\"trainer\"][\"train_batch_size\"]\n",
    "valid_batch_size = conf[\"trainer\"][\"valid_batch_size\"]\n",
    "\n",
    "epochs = conf[\"trainer\"][\"epochs\"]\n",
    "batches_per_epoch = conf[\"trainer\"][\"batches_per_epoch\"]\n",
    "Tensor = torch.cuda.FloatTensor if is_cuda else torch.FloatTensor\n",
    "adv_loss = conf[\"trainer\"][\"adv_loss\"]\n",
    "lambda_gp = conf[\"trainer\"][\"lambda_gp\"]\n",
    "mask_penalty = conf[\"trainer\"][\"mask_penalty\"]\n",
    "regression_penalty = conf[\"trainer\"][\"regression_penalty\"]\n",
    "train_gen_every = conf[\"trainer\"][\"train_gen_every\"]\n",
    "train_disc_every = conf[\"trainer\"][\"train_disc_every\"]\n",
    "threshold = conf[\"trainer\"][\"threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessing transforms\n",
    "if \"Normalize\" in conf[\"transforms\"][\"training\"]:\n",
    "    conf[\"transforms\"][\"validation\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\"training\"][\"Normalize\"][\"mode\"]\n",
    "    conf[\"transforms\"][\"inference\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\"training\"][\"Normalize\"][\"mode\"]\n",
    "\n",
    "train_transforms = LoadTransformations(conf[\"transforms\"][\"training\"])\n",
    "valid_transforms = LoadTransformations(conf[\"transforms\"][\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_synthetic_dataset = XarrayReader(fn_train, train_transforms)\n",
    "test_synthetic_dataset = XarrayReader(fn_valid, valid_transforms)\n",
    "\n",
    "# train_synthetic_dataset = PickleReader(\n",
    "#     fn_train,\n",
    "#     transform=train_transforms,\n",
    "#     max_images=int(0.8 * conf[\"data\"][\"total_training\"]),\n",
    "#     max_buffer_size=int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "#     color_dim=conf[\"discriminator\"][\"in_channels\"],\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "# test_synthetic_dataset = PickleReader(\n",
    "#     fn_valid,\n",
    "#     transform=valid_transforms,\n",
    "#     max_images=int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "#     max_buffer_size=int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "#     color_dim=conf[\"discriminator\"][\"in_channels\"],\n",
    "#     shuffle=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_synthetic_loader = torch.utils.data.DataLoader(\n",
    "    train_synthetic_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    num_workers=available_ncpus//2,\n",
    "    pin_memory=True,\n",
    "    shuffle=True)\n",
    "\n",
    "# test_synthetic_loader = torch.utils.data.DataLoader(\n",
    "#     test_synthetic_dataset,\n",
    "#     batch_size=valid_batch_size,\n",
    "#     num_workers=0,  # 0 = One worker with the main process\n",
    "#     pin_memory=True,\n",
    "#     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_holodec_dataset = XarrayReaderLabels(fn_train_raw, train_transforms)\n",
    "#test_holodec_dataset = XarrayReader(fn_valid_raw, valid_transforms)\n",
    "\n",
    "# train_holodec_dataset = PickleReader(\n",
    "#     fn_train_raw,\n",
    "#     transform=train_transforms,\n",
    "#     max_images=int(0.8 * conf[\"data\"][\"total_training\"]),\n",
    "#     max_buffer_size=int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "#     color_dim=conf[\"discriminator\"][\"in_channels\"],\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "# test_holodec_dataset = PickleReader(\n",
    "#     fn_valid_raw,\n",
    "#     transform=valid_transforms,\n",
    "#     max_images=int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "#     max_buffer_size=int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "#     color_dim=conf[\"discriminator\"][\"in_channels\"],\n",
    "#     shuffle=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_holodec_loader = torch.utils.data.DataLoader(\n",
    "    train_holodec_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    num_workers=available_ncpus//2,\n",
    "    pin_memory=True,\n",
    "    shuffle=True)\n",
    "\n",
    "# test_holodec_loader = torch.utils.data.DataLoader(\n",
    "#     test_holodec_dataset,\n",
    "#     batch_size=valid_batch_size,\n",
    "#     num_workers=0,  # 0 = One worker with the main process\n",
    "#     pin_memory=True,\n",
    "#     shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = load_model(conf[\"generator\"]).to(device) \n",
    "discriminator = load_model(conf[\"discriminator\"]).to(device)\n",
    "model = load_model(conf[\"model\"]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /glade/work/schreck/py37/lib/python3.7/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "adv_loss = conf[\"trainer\"][\"adv_loss\"]\n",
    "if adv_loss == \"bce\":\n",
    "    adversarial_loss = torch.nn.BCELoss().to(device)\n",
    "    \n",
    "perceptual_alex = lpips.LPIPS(net='alex').cuda()\n",
    "\n",
    "Mask_Loss = load_loss(\"focal-tyversky\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, generator.parameters()),\n",
    "    lr = conf[\"optimizer_G\"][\"learning_rate\"],\n",
    "    betas = (conf[\"optimizer_G\"][\"b0\"], conf[\"optimizer_G\"][\"b1\"]))\n",
    "\n",
    "optimizer_D = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, discriminator.parameters()), \n",
    "    lr = conf[\"optimizer_D\"][\"learning_rate\"], \n",
    "    betas = (conf[\"optimizer_D\"][\"b0\"], conf[\"optimizer_D\"][\"b1\"]))\n",
    "\n",
    "optimizer_M = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), \n",
    "    lr =  conf[\"optimizer_M\"][\"learning_rate\"], \n",
    "    betas = (conf[\"optimizer_M\"][\"b0\"], conf[\"optimizer_M\"][\"b1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(discriminator, real_imgs, gen_imgs):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    alpha = torch.rand(real_imgs.size(0), 1, 1, 1).cuda().expand_as(real_imgs)\n",
    "    interpolated = Variable(alpha * real_imgs.data + (1 - alpha) * gen_imgs.data, requires_grad=True)\n",
    "    out = discriminator(interpolated)[1]\n",
    "    grad = torch.autograd.grad(outputs=out,\n",
    "                               inputs=interpolated,\n",
    "                               grad_outputs=torch.ones(out.size()).cuda(),\n",
    "                               retain_graph=True,\n",
    "                               create_graph=True,\n",
    "                               only_inputs=True)[0]\n",
    "    grad = grad.view(grad.size(0), -1)\n",
    "    grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))\n",
    "    d_loss_gp = torch.mean((grad_l2norm - 1) ** 2)\n",
    "    return d_loss_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_G_decay = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=10, gamma=0.2)\n",
    "lr_D_decay = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=10, gamma=0.2)\n",
    "lr_M_decay = torch.optim.lr_scheduler.StepLR(optimizer_M, step_size=10, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 D_loss 1.574306 G_loss 35.002747 G_reg 0.078397 mask_loss 0.927094 h_acc 0.6875 f_acc 0.6875 s_acc 0.4375 p_syn 0.6728 p_real 0.9966: 100%|██████████| 250/250 [06:04<00:00,  1.46s/it]\n",
      "Epoch 0 F1: 0.668 POD: 0.939 FAR: 0.238 CSI: 0.725906: 100%|██████████| 1154/1154 [00:27<00:00, 41.88it/s]\n",
      "Epoch 1 D_loss 0.266075 G_loss 39.314060 G_reg 0.068820 mask_loss 0.995426 h_acc 1.0000 f_acc 0.9875 s_acc 0.0250 p_syn 0.7815 p_real 1.0689:  38%|███▊      | 95/250 [02:19<03:45,  1.46s/it]"
     ]
    }
   ],
   "source": [
    "results = defaultdict(list)\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    ### Train\n",
    "    real_images = iter(train_holodec_loader)\n",
    "    synthethic_images = iter(train_synthetic_loader)\n",
    "    dual_iter = tqdm.tqdm(\n",
    "        enumerate(zip(real_images, synthethic_images)),\n",
    "        total = batches_per_epoch, \n",
    "        leave = True)\n",
    "    \n",
    "    train_results = defaultdict(list)\n",
    "    for i, ((holo_img, holo_label), (synth_img, synth_label)) in dual_iter:\n",
    "            \n",
    "        if holo_img.shape[0] != synth_img.shape[0]:\n",
    "            continue\n",
    "                            \n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(holo_img.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(holo_img.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(holo_img.type(Tensor))\n",
    "        synthethic_imgs = Variable(synth_img.type(Tensor))\n",
    "                \n",
    "        # Sample noise as generator input\n",
    "        #z = Variable(Tensor(np.random.normal(0, 1.0, (holo_img.shape[0], 512))))\n",
    "        z = Variable(Tensor(np.random.normal(0, 1.0, synthethic_imgs.shape)))\n",
    "        # C-GAN-like input using the synthethic image as conditional input\n",
    "        gen_input = torch.cat([synthethic_imgs, z], 1)\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(gen_input)\n",
    "        # Discriminate the fake images\n",
    "        pred_masks, verdict = discriminator(gen_imgs)\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train mask model\n",
    "        # -----------------\n",
    "        \n",
    "        optimizer_M.zero_grad()\n",
    "        requires_grad(model, True)\n",
    "        pred_masks = model(gen_imgs.detach())\n",
    "        mask_loss = Mask_Loss(pred_masks, synth_label.to(device))\n",
    "        train_results[\"mask_loss\"].append(mask_loss.item())\n",
    "        mask_loss.backward()\n",
    "        optimizer_M.step()\n",
    "        requires_grad(model, False)\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "            \n",
    "        if (i + 1) % train_gen_every == 0:\n",
    "            \n",
    "            optimizer_G.zero_grad()\n",
    "            requires_grad(generator, True)\n",
    "            requires_grad(discriminator, False)\n",
    "            \n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            if adv_loss == 'wgan-gp':\n",
    "                g_loss = -verdict.mean()\n",
    "            elif adv_loss == 'hinge':\n",
    "                g_loss = -verdict.mean()\n",
    "            elif adv_loss == 'bce':\n",
    "                g_loss = adversarial_loss(verdict, valid)\n",
    "                \n",
    "            # compute L1/L2 reg term\n",
    "#             mask = synth_label.to(device).bool()\n",
    "#             reg_loss = torch.nn.MSELoss()(\n",
    "#                 torch.masked_select(gen_imgs, mask),\n",
    "#                 torch.masked_select(synthethic_imgs, mask)\n",
    "#             )\n",
    "\n",
    "            mask = synth_label.to(device)\n",
    "            reg_loss = torch.nn.MSELoss()(gen_imgs, synthethic_imgs)\n",
    "\n",
    "            train_results[\"g_reg\"].append(reg_loss.item())\n",
    "            g_loss += regression_penalty * reg_loss\n",
    "            \n",
    "            # compute mask loss reg term\n",
    "            pred_masks = model(gen_imgs)\n",
    "            mask_loss = Mask_Loss(pred_masks, synth_label.to(device))\n",
    "            train_results[\"fake_mask_loss\"].append(mask_loss.item())\n",
    "            g_loss += mask_penalty * mask_loss\n",
    "            train_results[\"g_loss\"].append(g_loss.item())\n",
    "                \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # compute perception scores\n",
    "            p_score_syn = perceptual_alex(gen_imgs, synthethic_imgs).mean()\n",
    "            p_score_real = perceptual_alex(gen_imgs, real_imgs).mean()\n",
    "            train_results[\"p_syn\"].append(p_score_syn.item())\n",
    "            train_results[\"p_real\"].append(p_score_real.item())\n",
    "            \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        \n",
    "        if (i + 1) % train_disc_every == 0:\n",
    "        \n",
    "            optimizer_D.zero_grad()\n",
    "            requires_grad(generator, False)\n",
    "            requires_grad(discriminator, True)\n",
    "\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "            _, disc_real = discriminator(real_imgs)\n",
    "            _, disc_synth = discriminator(gen_imgs.detach())\n",
    "            _, disc_synth_true = discriminator(synthethic_imgs)\n",
    "            \n",
    "            train_results[\"real_acc\"].append(((disc_real > threshold) == valid).float().mean().item())\n",
    "            train_results[\"syn_acc\"].append(((disc_synth > threshold) == fake).float().mean().item())\n",
    "            train_results[\"syn_true_acc\"].append(((disc_synth_true > threshold) == valid).float().mean().item())\n",
    "            \n",
    "            if adv_loss == 'wgan-gp':\n",
    "                real_loss = -torch.mean(disc_real) \n",
    "                fake_loss = disc_synth.mean() \n",
    "            elif adv_loss == 'hinge':\n",
    "                real_loss = torch.nn.ReLU()(1.0 - disc_real).mean() \n",
    "                fake_loss = torch.nn.ReLU()(1.0 + disc_synth).mean()             \n",
    "            elif adv_loss == 'bce':\n",
    "                real_loss = adversarial_loss(disc_real, valid) \n",
    "                fake_loss = adversarial_loss(disc_synth, fake) \n",
    "                \n",
    "            d_loss = real_loss + fake_loss \n",
    "            train_results[\"d_loss\"].append(d_loss.item())\n",
    "            \n",
    "            if adv_loss == 'wgan-gp':\n",
    "                # Compute gradient penalty\n",
    "                alpha = torch.rand(real_imgs.size(0), 1, 1, 1).cuda().expand_as(real_imgs)\n",
    "                interpolated = Variable(alpha * real_imgs.data + (1 - alpha) * gen_imgs.data, requires_grad=True)\n",
    "                out = discriminator(interpolated)[1]\n",
    "\n",
    "                grad = torch.autograd.grad(outputs=out,\n",
    "                                           inputs=interpolated,\n",
    "                                           grad_outputs=torch.ones(out.size()).cuda(),\n",
    "                                           retain_graph=True,\n",
    "                                           create_graph=True,\n",
    "                                           only_inputs=True)[0]\n",
    "\n",
    "                grad = grad.view(grad.size(0), -1)\n",
    "                grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))\n",
    "                d_loss_gp = torch.mean((grad_l2norm - 1) ** 2)\n",
    "                d_loss_reg = lambda_gp * d_loss_gp\n",
    "                d_loss += d_loss_reg\n",
    "                train_results[\"d_reg\"].append(d_loss_reg.item())\n",
    "            \n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "        print_str =  f'Epoch {epoch}'\n",
    "        print_str += f' D_loss {np.mean(train_results[\"d_loss\"]):.6f}'\n",
    "        if adv_loss == 'wgan-gp':\n",
    "            print_str += f' D_reg {np.mean(train_results[\"d_reg\"]):.6f}'\n",
    "        print_str += f' G_loss {np.mean(train_results[\"g_loss\"]):6f}'\n",
    "        print_str += f' G_reg {np.mean(train_results[\"g_reg\"]):6f}'\n",
    "        print_str += f' mask_loss {np.mean(train_results[\"mask_loss\"]):6f}'\n",
    "        #print_str += f' fake_mask_loss {np.mean(train_results[\"fake_mask_loss\"]):6f}'\n",
    "        print_str += f' h_acc {np.mean(train_results[\"real_acc\"]):.4f}'\n",
    "        print_str += f' f_acc {np.mean(train_results[\"syn_acc\"]):.4f}'\n",
    "        print_str += f' s_acc {np.mean(train_results[\"syn_true_acc\"]):.4f}'\n",
    "        print_str += f' p_syn {np.mean(train_results[\"p_syn\"]):.4f}'\n",
    "        print_str += f' p_real {np.mean(train_results[\"p_real\"]):.4f}'\n",
    "        dual_iter.set_description(print_str)\n",
    "        dual_iter.refresh()\n",
    "        \n",
    "        if i == batches_per_epoch and i > 0:\n",
    "            break\n",
    "        \n",
    "    # Validate \n",
    "    requires_grad(model, False)\n",
    "    inputs = torch.from_numpy(np.load(os.path.join(\n",
    "        data_path, f'manual_images_{transform_mode}_test.npy'))).float()\n",
    "    labels = torch.from_numpy(np.load(os.path.join(\n",
    "        data_path, f'manual_labels_{transform_mode}_test.npy'))).float()\n",
    "    inputs = torch.from_numpy(np.expand_dims(\n",
    "        np.vstack([apply_transforms(valid_transforms, x) for x in inputs.numpy()]), 1))\n",
    "    \n",
    "    results_dict_set1 = defaultdict(list)\n",
    "    my_iter = tqdm.tqdm(enumerate(zip(inputs, labels)), total = inputs.shape[0], leave = True)\n",
    "    for k, (x, y) in my_iter:\n",
    "        pred_label = model(x.unsqueeze(0).to(device))\n",
    "        arr, n = scipy.ndimage.label(pred_label.cpu() > 0.5)\n",
    "        centroid = scipy.ndimage.find_objects(arr)\n",
    "        pred_label = len(centroid)\n",
    "        if pred_label > 0:\n",
    "            pred_label = 1\n",
    "        else:\n",
    "            pred_label = 0\n",
    "        results_dict_set1[\"pred\"].append(pred_label)\n",
    "        results_dict_set1[\"true\"].append(y[0].item())\n",
    "        mets = man_metrics(results_dict_set1)\n",
    "        f1, pod, far, csi = mets[\"f1\"], mets[\"pod\"], mets[\"far\"], mets[\"csi\"]\n",
    "        my_iter.set_description(f\"Epoch {epoch} F1: {f1:.3f} POD: {pod:.3f} FAR: {far:.3f} CSI: {csi:3f}\")\n",
    "        my_iter.refresh()\n",
    "    \n",
    "        \n",
    "    # Epoch is over. Save some stuff.\n",
    "    save_image(synthethic_imgs.data[:16], f'{conf[\"save_loc\"]}/images/synth_{epoch}.png', nrow=4, normalize=True)\n",
    "    save_image(real_imgs.data[:16], f'{conf[\"save_loc\"]}/images/real_{epoch}.png', nrow=4, normalize=True)\n",
    "    save_image(gen_imgs.data[:16], f'{conf[\"save_loc\"]}/images/pred_{epoch}.png', nrow=4, normalize=True)\n",
    "\n",
    "    # Save the dataframe to disk\n",
    "    results[\"epoch\"].append(epoch)\n",
    "    results[\"d_loss\"].append(np.mean(train_results[\"d_loss\"]))\n",
    "    if adv_loss == 'wgan-gp':\n",
    "        results[\"d_loss_reg\"].append(np.mean(train_results[\"d_reg\"]))\n",
    "    results[\"g_loss\"].append(np.mean(train_results[\"g_loss\"]))\n",
    "    results[\"g_reg\"].append(np.mean(train_results[\"g_reg\"]))\n",
    "    results[\"mask_loss\"].append(np.mean(train_results[\"mask_loss\"]))\n",
    "    #results[\"fake_mask_loss\"].append(np.mean(train_results[\"fake_mask_loss\"]))\n",
    "    results[\"holo_acc\"].append(np.mean(train_results[\"real_acc\"]))\n",
    "    results[\"fake_acc\"].append(np.mean(train_results[\"syn_acc\"]))\n",
    "    results[\"synth_acc\"].append(np.mean(train_results[\"syn_true_acc\"]))\n",
    "    results[\"perception_syn\"].append(np.mean(train_results[\"p_syn\"]))\n",
    "    results[\"perception_holo\"].append(np.mean(train_results[\"p_real\"]))\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(results).reset_index()\n",
    "    df.to_csv(f'{conf[\"save_loc\"]}/training_log.csv', index=False)\n",
    "\n",
    "    # Save the model\n",
    "    state_dict = {\n",
    "        'epoch': epoch,\n",
    "        'discriminator_state_dict': discriminator.state_dict(),\n",
    "        'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "        'generator_state_dict': generator.state_dict(),\n",
    "        'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_optimizer_state_dict': optimizer_M.state_dict()\n",
    "    }\n",
    "    torch.save(state_dict, f'{conf[\"save_loc\"]}/best.pt')\n",
    "    \n",
    "    # Anneal learning rates \n",
    "    lr_G_decay.step(epoch)\n",
    "    lr_D_decay.step(epoch)\n",
    "    lr_M_decay.step(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Validate on the manual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn, sklearn.metrics\n",
    "\n",
    "def man_metrics(results):\n",
    "    result = {}\n",
    "    for metric in [\"f1\", \"auc\", 'pod', \"far\", \"csi\"]: #\"man_prec\", \"man_recall\",\n",
    "        if metric == 'f1':\n",
    "            score = sklearn.metrics.f1_score(results[\"true\"], results[\"pred\"], average = \"weighted\")\n",
    "        elif metric == 'prec':\n",
    "            score = sklearn.metrics.precision_score(results[\"true\"], results[\"pred\"], average = \"weighted\")\n",
    "        elif metric == 'recall':\n",
    "            score = sklearn.metrics.recall_score(results[\"true\"], results[\"pred\"], average = \"weighted\")\n",
    "        elif metric == 'auc':\n",
    "            try:\n",
    "                score = sklearn.metrics.roc_auc_score(results[\"true\"], results[\"pred\"], average = \"weighted\")\n",
    "            except:\n",
    "                score = 1.0\n",
    "        elif metric ==  \"csi\":\n",
    "            try:\n",
    "                TN, FP, FN, TP = sklearn.metrics.confusion_matrix(results[\"true\"], results[\"pred\"]).ravel()\n",
    "                score = TP / (TP + FN + FP)\n",
    "            except:\n",
    "                score = 1\n",
    "        elif metric == 'far':\n",
    "            try:\n",
    "                TN, FP, FN, TP = sklearn.metrics.confusion_matrix(results[\"true\"], results[\"pred\"]).ravel()\n",
    "                score = FP / (TP + FP)\n",
    "            except:\n",
    "                score = 1\n",
    "        elif metric == 'pod':\n",
    "            try:\n",
    "                TN, FP, FN, TP = sklearn.metrics.confusion_matrix(results[\"true\"], results[\"pred\"]).ravel()\n",
    "                score = TP / (TP + FN)\n",
    "            except: \n",
    "                score = 1\n",
    "        result[metric] = score\n",
    "        #print(metric, round(score, 3))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transforms(transforms, image):\n",
    "    im = {\"image\": image}\n",
    "    for image_transform in transforms:\n",
    "        im = image_transform(im)\n",
    "    image = im[\"image\"]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(conf[\"model\"]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\n",
    "    f\"{save_loc}/best.pt\",\n",
    "    map_location=lambda storage, loc: storage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(np.load(os.path.join(\n",
    "    data_path, f'manual_images_{transform_mode}.npy'))).float()\n",
    "labels = torch.from_numpy(np.load(os.path.join(\n",
    "    data_path, f'manual_labels_{transform_mode}.npy'))).float()\n",
    "inputs = torch.from_numpy(np.expand_dims(\n",
    "    np.vstack([apply_transforms(valid_transforms, x) for x in inputs.numpy()]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_set1 = defaultdict(list)\n",
    "my_iter = tqdm.tqdm(enumerate(zip(inputs, labels)), total = inputs.shape[0], leave = True)\n",
    "for k, (x, y) in my_iter:\n",
    "    pred_label = model(x.unsqueeze(0).to(device))\n",
    "    arr, n = scipy.ndimage.label(pred_label.cpu() > 0.5)\n",
    "    centroid = scipy.ndimage.find_objects(arr)\n",
    "    pred_label = len(centroid)\n",
    "    if pred_label > 0:\n",
    "        pred_label = 1\n",
    "    else:\n",
    "        pred_label = 0\n",
    "    results_dict_set1[\"pred\"].append(pred_label)\n",
    "    results_dict_set1[\"true\"].append(y[0].item())\n",
    "    mets = man_metrics(results_dict_set1)\n",
    "    f1, pod, far, csi = mets[\"f1\"], mets[\"pod\"], mets[\"far\"], mets[\"csi\"]\n",
    "    my_iter.set_description(f\"F1: {f1:.3f} POD: {pod:.3f} FAR: {far:.3f} CSI: {csi:3f}\")\n",
    "    #my_iter.set_description(f\"Accuracy: {np.mean(results_dict_set1['accuracy'])}\")\n",
    "    my_iter.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1_metrics = man_metrics(results_dict_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in set1_metrics.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_2 = torch.from_numpy(np.load(os.path.join(\n",
    "    data_path, f'manual_images_{transform_mode}_test.npy'))).float()\n",
    "labels_2 = torch.from_numpy(np.load(os.path.join(\n",
    "    data_path, f'manual_labels_{transform_mode}_test.npy'))).float()\n",
    "confs_2 = torch.from_numpy(np.load(os.path.join(\n",
    "    data_path, f'manual_conf_{transform_mode}_test.npy'))).float()\n",
    "inputs_2 = torch.from_numpy(np.expand_dims(\n",
    "    np.vstack([apply_transforms(valid_transforms, x) for x in inputs_2.numpy()]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_set2 = defaultdict(list)\n",
    "my_iter = tqdm.tqdm(enumerate(zip(inputs_2, labels_2)), total = inputs_2.shape[0], leave = True)\n",
    "for k, (x, y) in my_iter:\n",
    "    pred_label = model(x.unsqueeze(0).to(device))\n",
    "    arr, n = scipy.ndimage.label(pred_label.cpu() > 0.5)\n",
    "    centroid = scipy.ndimage.find_objects(arr)\n",
    "    pred_label = len(centroid)\n",
    "    if pred_label > 0 and pred_label <= 10000:\n",
    "        pred_label = 1\n",
    "    else:\n",
    "        pred_label = 0\n",
    "    results_dict_set2[\"pred\"].append(pred_label)\n",
    "    results_dict_set2[\"true\"].append(y[0].item())\n",
    "    mets = man_metrics(results_dict_set2)\n",
    "    f1, pod, far, csi = mets[\"f1\"], mets[\"pod\"], mets[\"far\"], mets[\"csi\"]\n",
    "    my_iter.set_description(f\"F1: {f1:.3f} POD: {pod:.3f} FAR: {far:.3f} CSI: {csi:3f}\")\n",
    "    my_iter.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set2_metrics = man_metrics(results_dict_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in set2_metrics.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
