{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = smp.Unet(\n",
    "    encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset),\n",
    "    activation = \"tanh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_noise = generator(torch.ones([1, 1, 64, 64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for thing in generator.encoder(torch.ones([1, 1, 64, 64])):\n",
    "#     print(thing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_params=dict(\n",
    "    pooling='avg',             # one of 'avg', 'max'\n",
    "    dropout=0.2,               # dropout ratio, default is None\n",
    "    activation='sigmoid',      # activation function, default is None\n",
    "    classes=1,                 # define number of output labels\n",
    ")\n",
    "\n",
    "discriminator = smp.Unet('resnet18', in_channels=1, aux_params=aux_params)\n",
    "_, verdict = discriminator(torch.ones([32, 1, 64, 64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.where(verdict > 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.fft\n",
    "import subprocess\n",
    "import logging\n",
    "import random\n",
    "import shutil\n",
    "import psutil\n",
    "import scipy\n",
    "import torch\n",
    "import copy\n",
    "import yaml\n",
    "import time\n",
    "import tqdm\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from holodecml.data import PickleReader, UpsamplingReader\n",
    "from holodecml.propagation import InferencePropagator\n",
    "from holodecml.transforms import LoadTransformations\n",
    "from holodecml.models import load_model\n",
    "from holodecml.losses import load_loss\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_ncpus = len(psutil.Process().cpu_affinity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Set seeds for reproducibility\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"../results/gan/model.yml\"\n",
    "with open(config) as cf:\n",
    "    conf = yaml.load(cf, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "seed = 1000 if \"seed\" not in conf else conf[\"seed\"]\n",
    "seed_everything(seed)\n",
    "\n",
    "tile_size = int(conf[\"data\"][\"tile_size\"])\n",
    "step_size = int(conf[\"data\"][\"step_size\"])\n",
    "data_path = conf[\"data\"][\"output_path\"]\n",
    "data_path_raw = conf[\"data\"][\"output_path_raw\"]\n",
    "\n",
    "total_positive = int(conf[\"data\"][\"total_positive\"])\n",
    "total_negative = int(conf[\"data\"][\"total_negative\"])\n",
    "total_examples = int(conf[\"data\"][\"total_training\"])\n",
    "\n",
    "transform_mode = \"None\" if \"transform_mode\" not in conf[\"data\"] else conf[\"data\"][\"transform_mode\"]\n",
    "config_ncpus = int(conf[\"data\"][\"cores\"])\n",
    "use_cached = False if \"use_cached\" not in conf[\"data\"] else conf[\"data\"][\"use_cached\"]\n",
    "\n",
    "name_tag = f\"{tile_size}_{step_size}_{total_positive}_{total_negative}_{total_examples}_{transform_mode}\"\n",
    "fn_train = f\"{data_path}/training_{name_tag}.pkl\"\n",
    "fn_valid = f\"{data_path}/validation_{name_tag}.pkl\"\n",
    "fn_train_raw = f\"{data_path_raw}/training_{name_tag}.pkl\"\n",
    "fn_valid_raw = f\"{data_path_raw}/validation_{name_tag}.pkl\"\n",
    "\n",
    "output_path = conf[\"data\"][\"output_path\"]\n",
    "\n",
    "train_batch_size = 16\n",
    "valid_batch_size = 16\n",
    "\n",
    "latent_dim = 128\n",
    "img_shape = (1, tile_size, tile_size)\n",
    "\n",
    "d_learning_rate = 0.0004\n",
    "g_learning_rate = 0.0001\n",
    "\n",
    "b1 = 0.0\n",
    "b2 = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "data_device = torch.device(\"cpu\") if \"device\" not in conf[\"data\"] else conf[\"data\"][\"device\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessing transforms\n",
    "if \"Normalize\" in conf[\"transforms\"][\"training\"]:\n",
    "    conf[\"transforms\"][\"validation\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\"training\"][\"Normalize\"][\"mode\"]\n",
    "    conf[\"transforms\"][\"inference\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\"training\"][\"Normalize\"][\"mode\"]\n",
    "\n",
    "train_transforms = LoadTransformations(conf[\"transforms\"][\"training\"])\n",
    "valid_transforms = LoadTransformations(conf[\"transforms\"][\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_synthetic_dataset = UpsamplingReader(\n",
    "#     conf,\n",
    "#     transform=train_transforms,\n",
    "#     max_size=100,\n",
    "#     device=data_device\n",
    "# )\n",
    "\n",
    "train_synthetic_dataset = PickleReader(\n",
    "    fn_train,\n",
    "    transform=train_transforms,\n",
    "    max_images=int(0.8 * conf[\"data\"][\"total_training\"]),\n",
    "    max_buffer_size=int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "    color_dim=conf[\"model\"][\"in_channels\"],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_synthetic_dataset = PickleReader(\n",
    "    fn_valid,\n",
    "    transform=valid_transforms,\n",
    "    max_images=int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "    max_buffer_size=int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "    color_dim=conf[\"model\"][\"in_channels\"],\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_synthetic_loader = torch.utils.data.DataLoader(\n",
    "    train_synthetic_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    num_workers=0, #available_ncpus//2,\n",
    "    pin_memory=True,\n",
    "    shuffle=True)\n",
    "\n",
    "test_synthetic_loader = torch.utils.data.DataLoader(\n",
    "    test_synthetic_dataset,\n",
    "    batch_size=valid_batch_size,\n",
    "    num_workers=0,  # 0 = One worker with the main process\n",
    "    pin_memory=True,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holo_conf = copy.deepcopy(conf)\n",
    "# holo_conf[\"data\"][\"data_path\"] = holo_conf[\"data\"][\"raw_data\"]\n",
    "\n",
    "\n",
    "# train_holodec_dataset = UpsamplingReader(\n",
    "#     holo_conf,\n",
    "#     transform=train_transforms,\n",
    "#     max_size=1000,\n",
    "#     device=data_device\n",
    "# )\n",
    "\n",
    "\n",
    "# # test_holodec_inputs = torch.from_numpy(np.load(os.path.join(\n",
    "# #             output_path, f'manual_images_{transform_mode}.npy'))).float()\n",
    "# # test_holodec_labels = torch.from_numpy(np.load(os.path.join(\n",
    "# #             output_path, f'manual_labels_{transform_mode}.npy'))).float()\n",
    "\n",
    "# # test_holodec_dataset = torch.utils.data.TensorDataset(test_holodec_inputs, test_holodec_labels)\n",
    "\n",
    "\n",
    "# holo_conf = copy.deepcopy(conf)\n",
    "# holo_conf[\"data\"][\"raw_data\"] = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/real_holograms_CSET_RF07_20150719_203600-203700.nc\"\n",
    "# holo_conf[\"data\"][\"data_path\"] = holo_conf[\"data\"][\"raw_data\"]\n",
    "\n",
    "# test_holodec_dataset = UpsamplingReader(\n",
    "#     holo_conf,\n",
    "#     transform=valid_transforms,\n",
    "#     max_size=1000,\n",
    "#     device=data_device\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_holodec_dataset = PickleReader(\n",
    "    fn_train_raw,\n",
    "    transform=train_transforms,\n",
    "    max_images=int(0.8 * conf[\"data\"][\"total_training\"]),\n",
    "    max_buffer_size=int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "    color_dim=conf[\"model\"][\"in_channels\"],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_holodec_dataset = PickleReader(\n",
    "    fn_valid_raw,\n",
    "    transform=valid_transforms,\n",
    "    max_images=int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "    max_buffer_size=int(0.1 * conf[\"data\"][\"total_training\"]),\n",
    "    color_dim=conf[\"model\"][\"in_channels\"],\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_holodec_loader = torch.utils.data.DataLoader(\n",
    "    train_holodec_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    num_workers=available_ncpus,\n",
    "    pin_memory=True,\n",
    "    shuffle=True)\n",
    "\n",
    "test_holodec_loader = torch.utils.data.DataLoader(\n",
    "    test_holodec_dataset,\n",
    "    batch_size=valid_batch_size,\n",
    "    num_workers=available_ncpus,\n",
    "    pin_memory=True,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = smp.Unet(\n",
    "    encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset),\n",
    "#     activation = \"tanh\"\n",
    ")\n",
    "\n",
    "aux_params=dict(\n",
    "    pooling='avg',             # one of 'avg', 'max'\n",
    "    dropout=0.0,               # dropout ratio, default is None\n",
    "    activation='sigmoid',      # activation function, default is None\n",
    "    classes=1,                 # define number of output labels\n",
    ")\n",
    "\n",
    "discriminator = smp.Unet(\n",
    "#     encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "#     encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1, \n",
    "    aux_params=aux_params\n",
    ")\n",
    "\n",
    "#print(generator(torch.ones([1, 1, 64, 64])).shape)\n",
    "#print(discriminator(torch.ones([1, 1, 64, 64]))[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "if is_cuda:\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    \n",
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_D = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, discriminator.parameters()), \n",
    "    lr=d_learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = ReduceLROnPlateau(\n",
    "        optimizer_D,\n",
    "        patience=1,\n",
    "        min_lr=1.0e-13,\n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 train_loss 0.13253163713600521 train_acc 0.9517045454545454: 100%|██████████| 10/10 [01:08<00:00,  6.88s/it]\n",
      "Epoch 0 valid_loss 0.045717847129922384 valid_acc 0.9865196078431373: 100%|██████████| 50/50 [03:55<00:00,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train_loss 0.13253163713600521 valid_loss 0.045717847129922384 train_acc 0.9517045454545454 valid_acc 0.9865196078431373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 train_loss 0.01508790817266262 train_acc 0.9943181818181818: 100%|██████████| 10/10 [01:16<00:00,  7.65s/it] \n",
      "Epoch 1 valid_loss 0.0013701987045351416 valid_acc 1.0:   6%|▌         | 3/50 [00:51<10:43, 13.69s/it]"
     ]
    }
   ],
   "source": [
    "n_epochs = 5000\n",
    "batches_per_epoch = 10\n",
    "valid_batches_per_epoch = 50\n",
    "stopping_patience = 4\n",
    "threshold = 0.5\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if is_cuda else torch.FloatTensor\n",
    "\n",
    "results = defaultdict(list)\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    ### Train\n",
    "    real_images = iter(train_holodec_loader)\n",
    "    synthethic_images = iter(train_synthetic_loader)\n",
    "    dual_iter = tqdm.tqdm(\n",
    "        enumerate(zip(real_images, synthethic_images)),\n",
    "        total = batches_per_epoch, \n",
    "        leave = True)\n",
    "    \n",
    "    train_results = defaultdict(list)\n",
    "    for i, ((holo_img, holo_label), (synth_img, synth_label)) in dual_iter:\n",
    "                    \n",
    "        if holo_img.shape[0] != synth_img.shape[0]:\n",
    "            continue\n",
    "            \n",
    "        optimizer_D.zero_grad()\n",
    "        requires_grad(discriminator, True)\n",
    "                \n",
    "        # Adversarial ground truths\n",
    "        real = Variable(Tensor(holo_img.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        synth = Variable(Tensor(synth_img.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "        labels = torch.cat([real, synth], 0)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(holo_img.type(Tensor))\n",
    "        synthethic_imgs = Variable(synth_img.type(Tensor))\n",
    "        batched_imgs = torch.cat([real_imgs, synthethic_imgs], 0)\n",
    "        \n",
    "        _, verdict = discriminator(batched_imgs)\n",
    "        loss = adversarial_loss(verdict, labels)\n",
    "        \n",
    "        train_results[\"loss\"].append(loss.item())\n",
    "        train_results[\"accuracy\"].append(((verdict > threshold) == labels).float().mean().item())\n",
    "        \n",
    "        to_print = f'Epoch {epoch} train_loss {np.mean(train_results[\"loss\"])} train_acc {np.mean(train_results[\"accuracy\"])}'\n",
    "        dual_iter.set_description(to_print)\n",
    "        dual_iter.update()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_D.step()\n",
    "            \n",
    "        if i == batches_per_epoch and i > 0:\n",
    "            break\n",
    "    \n",
    "    ### Validation\n",
    "    requires_grad(discriminator, False)\n",
    "    \n",
    "    real_images = iter(test_holodec_loader)\n",
    "    synthethic_images = iter(test_synthetic_loader)\n",
    "    dual_iter = tqdm.tqdm(\n",
    "        enumerate(zip(real_images, synthethic_images)),\n",
    "        total = valid_batches_per_epoch, \n",
    "        leave = True)\n",
    "    \n",
    "    valid_results = defaultdict(list)\n",
    "    for i, ((holo_img, holo_label), (synth_img, synth_label)) in dual_iter:\n",
    "                    \n",
    "        if holo_img.shape[0] != synth_img.shape[0]:\n",
    "            continue\n",
    "               \n",
    "        # Adversarial ground truths\n",
    "        real = Variable(Tensor(holo_img.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        synth = Variable(Tensor(synth_img.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "        labels = torch.cat([real, synth], 0)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(holo_img.type(Tensor))\n",
    "        synthethic_imgs = Variable(synth_img.type(Tensor))\n",
    "        batched_imgs = torch.cat([real_imgs, synthethic_imgs], 0)\n",
    "        \n",
    "        _, verdict = discriminator(batched_imgs)\n",
    "        loss = adversarial_loss(verdict, labels)\n",
    "        \n",
    "        valid_results[\"loss\"].append(loss.item())\n",
    "        valid_results[\"accuracy\"].append(((verdict > threshold) == labels).float().mean().item())\n",
    "        \n",
    "        to_print = f'Epoch {epoch} valid_loss {np.mean(valid_results[\"loss\"])} valid_acc {np.mean(valid_results[\"accuracy\"])}'\n",
    "        dual_iter.set_description(to_print)\n",
    "        dual_iter.update()\n",
    "        \n",
    "        if i == valid_batches_per_epoch and i > 0:\n",
    "            break\n",
    "            \n",
    "    results[\"epoch\"].append(epoch)\n",
    "    results[\"train_loss\"].append(np.mean(train_results[\"loss\"]))\n",
    "    results[\"train_accuracy\"].append(np.mean(train_results[\"accuracy\"]))\n",
    "    results[\"valid_loss\"].append(np.mean(valid_results[\"loss\"]))\n",
    "    results[\"valid_accuracy\"].append(np.mean(valid_results[\"accuracy\"]))\n",
    "    \n",
    "    print_str = f\"Epoch {epoch}\"\n",
    "    print_str += f' train_loss {np.mean(train_results[\"loss\"])} valid_loss {np.mean(valid_results[\"loss\"])}'\n",
    "    print_str += f' train_acc {np.mean(train_results[\"accuracy\"])} valid_acc {np.mean(valid_results[\"accuracy\"])}'\n",
    "\n",
    "    print(print_str)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(results).reset_index()\n",
    "\n",
    "    # Save the dataframe to disk\n",
    "    df.to_csv(f'{conf[\"save_loc\"]}/training_log.csv', index=False)\n",
    "    \n",
    "    # If the best model, save to disk\n",
    "    # Save the model if its the best so far.\n",
    "    if results[\"valid_accuracy\"][-1] == max(results[\"valid_accuracy\"]):\n",
    "        state_dict = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': discriminator.state_dict(),\n",
    "            'optimizer_state_dict': optimizer_D.state_dict(),\n",
    "            'loss': results[\"valid_accuracy\"][-1]\n",
    "        }\n",
    "        torch.save(state_dict, f'{conf[\"save_loc\"]}/best.pt')\n",
    "    \n",
    "    # Lower the learning rate\n",
    "    lr_scheduler.step(1.0-np.mean(valid_results[\"accuracy\"]))\n",
    "    \n",
    "    # Early stopping\n",
    "    best_epoch = [i for i, j in enumerate(\n",
    "        results[\"valid_accuracy\"]) if j == max(results[\"valid_accuracy\"])][0]\n",
    "    offset = epoch - best_epoch\n",
    "    if offset >= stopping_patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
