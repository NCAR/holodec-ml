log:
  save_path: "/glade/work/schreck/repos/HOLO/030722/holodec-ml/results/echo/log.txt"

pbs:
  jobs: 10
  kernel: "ncar_pylib /glade/work/$USER/py37" # ncar_20200417
  bash: ["source ~/.bashrc"]
  batch:
    N: "h2h"
    l: ["select=1:ncpus=8:ngpus=1:mem=128GB", "walltime=24:00:00", "gpu_type=v100"]
    A: "NAML0001"
    q: "casper"
    o: "out" #"/dev/null"
    e: "out" #"/dev/null"
    
optuna:
  study_name: "gan"
  storage: "sqlite:////glade/work/schreck/repos/HOLO/030722/holodec-ml/results/echo/gan.db"
  reload: 1
  objective: "/glade/work/schreck/repos/HOLO/030722/holodec-ml/applications/gan.py"
  direction: "minimize"
  metric: "custom"
  n_trials: 999
  gpu: True
  save_path: '/glade/work/schreck/repos/HOLO/030722/holodec-ml/results/echo/'
  sampler:
    type: "TPESampler"
    n_startup_trials: 50
  parameters:
    optimizer_G:learning_rate:
      type: "loguniform"
      settings:
        name: "G_learning_rate"
        low: 1.0e-06
        high: 1.0e-02
    optimizer_D:learning_rate:
      type: "loguniform"
      settings:
        name: "D_learning_rate"
        low: 1.0e-06
        high: 1.0e-02
    trainer:adv_loss:
      type: "categorical"
      settings:
        name: "adv_loss"
        choices: ["bce", "hinge", "wgan-gp"]
    trainer:train_disc_every:
      type: "int"
      settings:
        name: "train_disc_every"
        low: 1
        high: 100
    trainer:mask_penalty:
      type: "float"
      settings:
        name: "mask_penalty"
        low: 0.0
        high: 50.0
    trainer:regression_penalty:
      type: "float"
      settings:
        name: "regression_penalty"
        low: 0.0
        high: 50.0