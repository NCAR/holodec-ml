{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from holodecml.models import load_model\n",
    "from functools import partial\n",
    "from argparse import ArgumentParser\n",
    "import torch.multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import traceback\n",
    "import random\n",
    "import logging\n",
    "import signal\n",
    "import joblib\n",
    "import scipy\n",
    "import sys\n",
    "import yaml\n",
    "import time\n",
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import xarray as xr\n",
    "\n",
    "import torch, yaml, os\n",
    "import torch.fft\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "from holodecml.metrics import DistributedROC\n",
    "from holodecml.transforms import LoadTransformations\n",
    "from holodecml.propagation import InferencePropagator\n",
    "from holodecml.data import save_sparse_csr\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPropagator(InferencePropagator):\n",
    "    \n",
    "    def get_sub_images_labeled(self,\n",
    "                               image_tnsr,\n",
    "                               z_sub_set,\n",
    "                               z_counter,\n",
    "                               xp, yp, zp, dp,\n",
    "                               infocus_mask,\n",
    "                               z_part_bin_idx,\n",
    "                               batch_size=32,\n",
    "                               return_arrays=False,\n",
    "                               return_metrics=False,\n",
    "                               thresholds=None,\n",
    "                               obs_threshold=None):\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # build the torch tensor for reconstruction\n",
    "            z_plane = torch.tensor(\n",
    "                z_sub_set*1e-6, device=self.device).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "            # reconstruct the selected planes\n",
    "            E_out = self.torch_holo_set(image_tnsr, z_plane)\n",
    "\n",
    "            if self.color_dim == 2:\n",
    "                stacked_image = torch.cat([\n",
    "                    torch.abs(E_out).unsqueeze(1), torch.angle(E_out).unsqueeze(1)], 1)\n",
    "            elif self.color_dim == 1:\n",
    "                stacked_image = torch.abs(E_out).unsqueeze(1)\n",
    "            else:\n",
    "                raise OSError(f\"Unrecognized color dimension {self.color_dim}\")\n",
    "            stacked_image = self.apply_transforms(\n",
    "                stacked_image.squeeze(0)).unsqueeze(0)\n",
    "\n",
    "            size = (E_out.shape[1], E_out.shape[2])\n",
    "            true_output = torch.zeros(size).to(self.device)\n",
    "            counter = torch.zeros(size).to(self.device)\n",
    "\n",
    "            chunked = np.array_split(\n",
    "                list(self.idx2slice.items()),\n",
    "                int(np.ceil(len(self.idx2slice) / batch_size))\n",
    "            )\n",
    "\n",
    "            inputs, masks, preds = [], [], []\n",
    "            for z_idx in range(E_out.shape[0]):\n",
    "\n",
    "                unet_mask = torch.zeros(E_out.shape[1:]).to(\n",
    "                    self.device)  # initialize the UNET mask\n",
    "                # locate all particles in this plane\n",
    "                part_in_plane_idx = np.where(\n",
    "                    z_part_bin_idx == z_idx+z_counter)[0]\n",
    "\n",
    "                # build the UNET mask for this z plane\n",
    "                for part_idx in part_in_plane_idx:\n",
    "                    unet_mask += torch.from_numpy(\n",
    "                        (self.y_arr[None, :]*1e6-yp[part_idx])**2 +\n",
    "                        (self.x_arr[:, None]*1e6-xp[part_idx]\n",
    "                         )**2 < (dp[part_idx]/2)**2\n",
    "                    ).float().to(self.device)\n",
    "\n",
    "                worker = partial(\n",
    "                    self.collate_masks,\n",
    "                    image=stacked_image[z_idx, :].float(),\n",
    "                    mask=unet_mask\n",
    "                )\n",
    "\n",
    "                for chunk in chunked:\n",
    "                    slices, x, true_mask_tile = worker(chunk)\n",
    "                    for k, ((row_idx, col_idx), (row_slice, col_slice)) in enumerate(slices):\n",
    "                        inputs.append(x[k].cpu().numpy()) \n",
    "                        masks.append(true_mask_tile[k].cpu().unsqueeze(0).numpy().sum())\n",
    "            \n",
    "            return_dict = {\"inputs\": np.vstack(inputs), \"masks\": np.array(masks)}\n",
    "                                \n",
    "        return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\") if not is_cuda else torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_name = \"../config/model_segmentation.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn_name) as cf:\n",
    "    conf = yaml.load(cf, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = conf[\"seed\"]\n",
    "n_bins = conf[\"data\"][\"n_bins\"]\n",
    "tile_size = conf[\"data\"][\"tile_size\"]\n",
    "step_size = conf[\"data\"][\"step_size\"]\n",
    "marker_size = conf[\"data\"][\"marker_size\"]\n",
    "total_positive = int(conf[\"data\"][\"total_positive\"])\n",
    "total_negative = int(conf[\"data\"][\"total_negative\"])\n",
    "total_examples = int(conf[\"data\"][\"total_training\"])\n",
    "\n",
    "# Do not load the image transformations\n",
    "transform_mode = \"None\"\n",
    "tile_transforms = None\n",
    "color_dim = conf[\"model\"][\"in_channels\"]\n",
    "batch_size = conf[\"inference\"][\"batch_size\"]\n",
    "inference_mode = conf[\"inference\"][\"mode\"]\n",
    "\n",
    "name_tag = f\"{tile_size}_{step_size}_{total_positive}_{total_negative}_{total_examples}_{transform_mode}\"\n",
    "\n",
    "# Load the model\n",
    "model = load_model(conf[\"model\"]).to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = conf[\"style\"][\"raw\"][\"path\"]\n",
    "#holograms_per_dataset = style_conf[\"data\"][\"raw\"][\"holograms_per_dataset\"]\n",
    "tiles_per_reconstruction = conf[\"style\"][\"raw\"][\"tiles_per_reconstruction\"]\n",
    "reconstruction_per_hologram = conf[\"style\"][\"raw\"][\"reconstruction_per_hologram\"]\n",
    "save_path = conf[\"style\"][\"raw\"][\"save_path\"]\n",
    "sampler = conf[\"style\"][\"raw\"][\"sampler\"]\n",
    "name_tag = f\"{sampler}_{name_tag}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = CustomPropagator(\n",
    "    data_set,\n",
    "    n_bins=n_bins,\n",
    "    color_dim=color_dim,\n",
    "    tile_size=tile_size,\n",
    "    step_size=step_size,\n",
    "    marker_size=marker_size,\n",
    "    transform_mode=transform_mode,\n",
    "    device=device,\n",
    "    model=model,\n",
    "    mode=inference_mode,\n",
    "    probability_threshold=0.5,\n",
    "    transforms=tile_transforms\n",
    ")\n",
    "\n",
    "# Create a list of z-values to propagate to\n",
    "z_list = prop.create_z_plane_lst(planes_per_call=1)\n",
    "random.shuffle(z_list)\n",
    "z_list = z_list[:reconstruction_per_hologram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_range = prop.h_ds.hologram_number.values\n",
    "h_range_prime = list(set(h_range) - set(range(10, 20)))\n",
    "\n",
    "# split into train/test/valid\n",
    "h_train, rest_data = train_test_split(h_range_prime, train_size=0.8)\n",
    "h_valid, h_test = train_test_split(rest_data, test_size=0.45)\n",
    "h_test += list(range(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439 60 60\n"
     ]
    }
   ],
   "source": [
    "print(len(h_train), len(h_valid), len(h_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "446it [44:31,  5.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (11175, 1, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55it [05:36,  6.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (1400, 1, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55it [05:34,  6.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test (1400, 1, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "h_splits = [h_train, h_valid, h_test]\n",
    "split_names = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "for split, h_split in zip(split_names, h_splits):\n",
    "\n",
    "    total = len(h_split) * tiles_per_reconstruction * reconstruction_per_hologram\n",
    "    X = np.zeros((total, 512, 512))\n",
    "    Y = np.zeros((total, 1))\n",
    "\n",
    "    c = 0\n",
    "    # Main loop to call the generator, predict with the model, and aggregate and save the results\n",
    "    for nc, h_idx in tqdm.tqdm(enumerate(h_split), total = len(h_split)):\n",
    "        planes_processed = n_bins\n",
    "        inference_generator = prop.get_next_z_planes_labeled(\n",
    "            h_idx,\n",
    "            z_list,\n",
    "            batch_size=batch_size,\n",
    "            thresholds=[0.5],\n",
    "            return_arrays=False,\n",
    "            return_metrics=False,\n",
    "            obs_threshold=0.5,\n",
    "            start_z_counter=planes_processed\n",
    "        )\n",
    "\n",
    "        t0 = time.time()\n",
    "        for z_idx, results_dict in enumerate(inference_generator):\n",
    "\n",
    "            if results_dict[\"masks\"].sum() > 0:\n",
    "                mins = np.array([p.min() for p in results_dict[\"inputs\"]])\n",
    "                idx = np.where(mins==min(mins))[0]\n",
    "                print(z_idx, idx, results_dict[\"masks\"].shape)\n",
    "                #raise\n",
    "\n",
    "            idx = random.sample(range(results_dict[\"inputs\"].shape[0]), k=tiles_per_reconstruction)\n",
    "            X[c:c+tiles_per_reconstruction] = results_dict[\"inputs\"][idx]\n",
    "            Y[c:c+tiles_per_reconstruction] = results_dict[\"masks\"][idx].reshape((tiles_per_reconstruction, 1))\n",
    "            c += tiles_per_reconstruction\n",
    "\n",
    "            if c >= X.shape[0]:\n",
    "                break\n",
    "\n",
    "        if c >= X.shape[0]:\n",
    "                break\n",
    "\n",
    "    if color_dim == 1:\n",
    "        X = np.expand_dims(X, axis = 1)\n",
    "        \n",
    "    print(split, X.shape)\n",
    "\n",
    "    df = xr.Dataset(data_vars=dict(var_x=(['n', 'd', 'x', 'y'], X[:c]), \n",
    "                                   var_y=(['n', 'z'], Y[:c])))\n",
    "\n",
    "    df.to_netcdf(f\"{save_path}/{split}_{name_tag}.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
