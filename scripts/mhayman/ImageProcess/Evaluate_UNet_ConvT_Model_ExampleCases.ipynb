{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Activation, MaxPool2D, SeparableConv2D, UpSampling2D, concatenate, Conv2DTranspose\n",
    "\n",
    "from tensorflow.keras.models import Model, save_model, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#from tensorflow import concat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "# set path to local libraries\n",
    "dirP_str = '../../../library'\n",
    "if dirP_str not in sys.path:\n",
    "    sys.path.append(dirP_str)\n",
    "\n",
    "import ml_utils as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path='/scr/sci/mhayman/holodec/holodec-ml-data/'\n",
    "\n",
    "# model_file = \"holodec_UNET_16Filt_5Conv_4Pool_mse_linear_random_image_multiplane_data_64x64_5000count300epochs_run1.h5\"\n",
    "# ds_file = 'image_data_256x256_50count.nc'\n",
    "# ds_file = 'image_data_256x256_5000count.nc'\n",
    "# ds_file = 'image_data_64x64_5000count.nc'\n",
    "# ds_file = 'random_image_data_64x64_5000count.nc'\n",
    "# ds_file = 'random_image_data_64x64_5000count_v02.nc' # 1 um PSF with 1 cm depth\n",
    "# ds_file = 'random_image_data_64x64_5000count_v03.nc' # 1 um PSF with 10 cm depth\n",
    "# ds_file = 'random_image_multiplane_data_64x64_5000count.nc' # 1 um PSF with 10 cm depth\n",
    "# ds_file = \"random_image_multiplane_data_64x64_5000count_1particles.nc\" # 1 um PSF with 1 cm depth with 1 particles\n",
    "# ds_file = \"random_image_multiplane_data_64x64_5000count_2particles.nc\" # 1 um PSF with 1 cm depth with 2 particles\n",
    "\n",
    "\n",
    "# model_file = \"holodec_UNET_16Filt_5Conv_4Pool_mse_linear_random_image_multiplane_data_256x256_5000count_1particles150epochs_run1.h5\"\n",
    "# ds_file = 'random_image_multiplane_data_256x256_5000count_1particles.nc'\n",
    "\n",
    "# model_file = \"holodec_UNET_16Filt_5Conv_4Pool_mse_linear_random_image_multiplane_data_256x256_5000count_1particles_v02150epochs_run1.h5\"\n",
    "# ds_file = 'random_image_multiplane_data_256x256_5000count_1particles_v02.nc'\n",
    "\n",
    "# model_file = \"holodec_UNET_16Filt_5Conv_4Pool_mse_linear_random_image_multiplane_data_256x256_5000count_1particles_v03_150epochs_run1.h5\"\n",
    "# ds_file = 'random_image_multiplane_data_256x256_5000count_1particles_v03.nc'\n",
    "\n",
    "# model_file = \"holodec_UNET_16Filt_5Conv_4Pool_mse_linear_random_image_multiplane_data_256x256_5000count_1particles_v04_150epochs_run1.h5\"\n",
    "# ds_file = 'random_image_multiplane_data_256x256_5000count_1particles_v04.nc'\n",
    "# ds_file = 'random_image_multiplane_data_256x256_5000count_3particles_v04.nc'\n",
    "\n",
    "model_file = \"holodec_UNET_16Filt_5Conv_4Pool_5Layers_mse_linear_random_image_multiplane_data_256x256_5000count_1particles_v04_150epochs_run1.h5\"\n",
    "ds_file = 'random_image_multiplane_data_256x256_5000count_1particles_v04.nc'\n",
    "# ds_file = 'random_image_multiplane_data_256x256_5000count_3particles_v04.nc'\n",
    "\n",
    "# model_file = \"holodec_UNET_16Filt_7Conv_4Pool_4Layers_mse_linear_random_image_multiplane_data_256x256_5000count_1particles_v04_150epochs_run1.h5\"\n",
    "# ds_file = 'random_image_multiplane_data_256x256_5000count_1particles_v04.nc'\n",
    "# ds_file = 'random_image_multiplane_data_256x256_5000count_3particles_v04.nc'\n",
    "\n",
    "# model_file =\"holodec_UNET_16Filt_9Conv_8Pool_3Layers_mse_linear_random_image_multiplane_data_256x256_5000count_1particles_v04_51epochs_run1.h5\"\n",
    "# ds_file = 'random_image_multiplane_data_256x256_5000count_1particles_v04.nc'\n",
    "\n",
    "# model_file = \"holodec_UNET_16Filt_3Conv_2Pool_8Layers_mse_linear_random_image_multiplane_data_256x256_5000count_1particles_v04_151epochs_run1.h5\"\n",
    "# ds_file = 'random_image_multiplane_data_256x256_5000count_1particles_v04.nc'\n",
    "\n",
    "# model_file =\"holodec_UNET_16Filt_5Conv_2Pool_6Layers_mse_linear_random_image_multiplane_data_256x256_5000count_1particles_v04_151epochs_run1.h5\"\n",
    "# ds_file = 'random_image_multiplane_data_256x256_5000count_1particles_v04.nc'\n",
    "# ds_file = 'random_image_multiplane_data_256x256_5000count_3particles_v04.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(ds_path+ds_file)\n",
    "num_epochs = 0\n",
    "run_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select holograms to evaluate\n",
    "index_list = [18,2854,1247,858,3143,832,4021,3921,222,2431,321]\n",
    "test_all = True  # if this flag is set run all the test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.attrs['zmax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = np.int(0.7*ds.sizes['hologram_number'])  # number of training+validation points\n",
    "valid_index = np.int(0.2*ds.sizes['hologram_number'])  # number of validation points\n",
    "all_labels = ds['labels'].sel(type=['amplitude','z'])\n",
    "\n",
    "train_labels = all_labels.isel(hologram_number=slice(valid_index,split_index))\n",
    "\n",
    "if test_all:\n",
    "    test_labels = all_labels.isel(hologram_number=slice(split_index,None))\n",
    "else:\n",
    "    test_labels = all_labels.isel(hologram_number=index_list)\n",
    "\n",
    "# val_labels = all_labels.isel(hologram_number=slice(None,valid_index))\n",
    "\n",
    "scaler = ml.MinMaxScalerX(train_labels,dim=('hologram_number','xsize','ysize'))\n",
    "# scaled_train_labels = scaler.fit_transform(train_labels)\n",
    "# scaled_val_labels = scaler.fit_transform(val_labels)\n",
    "scaled_test_labels = scaler.fit_transform(test_labels)\n",
    "# scaled_all_labels = scaler.fit_transform(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_all:\n",
    "    in_data = ds['image'].isel(hologram_number=slice(split_index,None))\n",
    "else:\n",
    "    in_data = ds['image'].isel(hologram_number=index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'channel' in in_data.dims:\n",
    "    in_data = in_data.expand_dims(\"channel\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_in_data = in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the CNN model\n",
    "mod = load_model(ds_path+\"/models/\"+model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_start = datetime.datetime.now()\n",
    "preds_out = mod.predict(scaled_in_data.values, batch_size=64)\n",
    "cnn_stop = datetime.datetime.now()\n",
    "print(f\"{scaled_in_data.values.shape[0]} samples in {(cnn_stop-cnn_start).total_seconds()} seconds\")\n",
    "print(f\"for {(cnn_stop-cnn_start).total_seconds()/scaled_in_data.values.shape[0]} seconds per hologram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_out_da = xr.DataArray(preds_out,dims=('hologram_number','xsize','ysize','type'),\n",
    "                            coords=all_labels.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_original = scaler.inverse_transform(preds_out_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate each predicted particle location by\n",
    "# the prediction with the least error\n",
    "# the prediction with the highest amplitude term\n",
    "z_min = []\n",
    "z_amp = []\n",
    "z_act = []\n",
    "a_min = []\n",
    "a_amp = []\n",
    "a_act = []\n",
    "for ih in test_labels.coords['hologram_number']:\n",
    "    preds0 = preds_original.sel(hologram_number=ih)\n",
    "    ampset = np.nonzero(test_labels.sel(hologram_number=ih,type='amplitude').values > 0.1)\n",
    "    zset = np.unique(test_labels.sel(hologram_number=ih,type='z').values[ampset])\n",
    "    for iz,z in enumerate(zset):\n",
    "        ipart = np.nonzero(test_labels.sel(hologram_number=ih,type='z').values==z)\n",
    "        zpred = preds0.sel(type='z').values[ipart]\n",
    "        apred = preds0.sel(type='amplitude').values[ipart]\n",
    "        iamp = np.argmax(apred)\n",
    "        imin = np.argmin(np.abs(zpred-z))\n",
    "        z_act += [z]\n",
    "        z_amp += [zpred[iamp]]\n",
    "        z_min += [zpred[imin]]\n",
    "        a_act += [np.max(apred)]\n",
    "        a_amp += [apred[iamp]]\n",
    "        a_min += [apred[imin]]\n",
    "z_act = np.array(z_act)\n",
    "z_amp = np.array(z_amp)\n",
    "z_min = np.array(z_min)\n",
    "a_act = np.array(a_act)\n",
    "a_amp = np.array(a_amp)\n",
    "a_min = np.array(a_min)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_min[0:5])\n",
    "print(z_act[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_one_to_one = [z_act.min()*1e3,z_act.max()*1e3]\n",
    "fig, ax = plt.subplots(1,1, figsize=(4, 4))\n",
    "ax.plot(z_one_to_one,z_one_to_one,'k--')\n",
    "ax.scatter(z_act*1e3,z_amp*1e3,s=5,alpha=0.5,label='max amplitude')\n",
    "ax.scatter(z_act*1e3,z_min*1e3,s=5,alpha=0.5,label='min error')\n",
    "ax.set_xlabel('z actual [mm]')\n",
    "ax.set_ylabel('z predicted [mm]')\n",
    "ax.grid(b=True)\n",
    "ax.legend()\n",
    "plt.savefig(\"results/\"+model_file.replace(\".h5\",\"\")+f\"_Zscatter\"+f\"_{num_epochs}epochs_run{run_num}_\"+ds_file.replace(\".nc\",\"\")+\".png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbins = np.linspace(-10,10,100)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax[0].hist(z_act*1e3-z_amp*1e3,bins=hbins)\n",
    "ax[0].set_xlabel('z error [mm]')\n",
    "ax[0].set_title('Max Amplitude')\n",
    "ax[0].minorticks_on()\n",
    "ax[0].grid(b=True)\n",
    "ax[0].text(0.02, 0.98, 'RMSE = %.02f mm'%np.sqrt(np.mean((z_act*1e3-z_amp*1e3)**2)), \n",
    "     horizontalalignment=\"left\",verticalalignment=\"top\", transform=ax[0].transAxes)\n",
    "\n",
    "ax[1].hist(z_act*1e3-z_min*1e3,bins=hbins)\n",
    "ax[1].set_xlabel('z error [mm]')\n",
    "ax[1].set_title('Min Error')\n",
    "ax[1].minorticks_on()\n",
    "ax[1].grid(b=True)\n",
    "ax[1].text(0.02, 0.98, 'RMSE = %.02f mm'%np.sqrt(np.mean((z_act*1e3-z_min*1e3)**2)), \n",
    "     horizontalalignment=\"left\",verticalalignment=\"top\", transform=ax[1].transAxes)\n",
    "plt.savefig(\"results/\"+model_file.replace(\".h5\",\"\")+f\"_Zhistogram\"+f\"_{num_epochs}epochs_run{run_num}_\"+ds_file.replace(\".nc\",\"\")+\".png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iscatter = np.nonzero(preds_original.sel(type='amplitude').values.flatten() > 0.2)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "for a, clabel in enumerate(all_labels.coords['type'].values):\n",
    "    ax=axes.ravel()[a]\n",
    "    ax.scatter(test_labels.sel(type=clabel).values.flatten()[iscatter], preds_original.sel(type=clabel).values.flatten()[iscatter], 1, 'k')\n",
    "    diag = np.linspace(test_labels.sel(type=clabel).min(), test_labels.sel(type=clabel).max(), 10)\n",
    "    ax.plot(diag, diag, 'b--' )\n",
    "    ax.set_title(clabel)\n",
    "# plt.savefig(\"results/\"+model_file.replace(\".h5\",\"\")+f\"_SampleScatterPlot\"+f\"_{num_epochs}epochs_run{run_num}_\"+ds_file.replace(\".nc\",\"\")+\".png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cmap = plt.get_cmap('seismic')\n",
    "diff_cmap.set_bad(color='gray')\n",
    "\n",
    "z_cmap = plt.get_cmap('viridis')\n",
    "z_cmap.set_bad(color='gray')\n",
    "\n",
    "diff_res = ds.attrs['zmax']*0.1\n",
    "\n",
    "for ind in range(len(index_list)):\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    ax = ax.ravel()\n",
    "    \n",
    "    inan_mask = np.nonzero((preds_original.sel(type='amplitude',hologram_number=ind).values < 0.1)* \\\n",
    "        (test_labels.sel(type='amplitude',hologram_number=ind).values < 0.1))\n",
    "    nan_mask = np.ones(preds_original.sel(type='amplitude',hologram_number=ind).values.shape)\n",
    "    nan_mask[inan_mask] = np.nan\n",
    "    \n",
    "    ax[0].imshow(preds_original.sel(type='amplitude',hologram_number=ind).values,vmin=0,vmax=1)\n",
    "    ax[1].imshow(test_labels.sel(type='amplitude',hologram_number=ind).values,vmin=0,vmax=1)\n",
    "    ax[2].imshow((preds_original.sel(type='amplitude',hologram_number=ind).values-test_labels.sel(type='amplitude',hologram_number=ind).values)*nan_mask,vmin=-1,vmax=1,cmap=diff_cmap)\n",
    "    # ax[2].imshow(scaled_in_data.values[ind,:,:,0])\n",
    "    ax[3].imshow(preds_original.sel(type='z',hologram_number=ind).values*nan_mask,vmin=0,vmax=ds.attrs['zmax'],cmap=z_cmap)\n",
    "    ax[4].imshow(test_labels.sel(type='z',hologram_number=ind).values*nan_mask,vmin=0,vmax=ds.attrs['zmax'],cmap=z_cmap)\n",
    "    ax[5].imshow((preds_original.sel(type='z',hologram_number=ind).values-test_labels.sel(type='z',hologram_number=ind).values)*nan_mask,vmin=-diff_res,vmax=diff_res,cmap=diff_cmap)\n",
    "    plt.savefig(\"results/\"+model_file.replace(\".h5\",\"\")+f\"_ExampleImage{index_list[ind]}\"+f\"_{num_epochs}epochs_run{run_num}_\"+ds_file.replace(\".nc\",\"\")+\".png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_number = in_data.sizes['channel']\n",
    "# index_list = [18]\n",
    "for ind in range(len(index_list)):\n",
    "    fig, ax = plt.subplots(2, channel_number//2, figsize=(channel_number*3, 8))\n",
    "    for ai in range(channel_number):\n",
    "        axind = ai//2+np.mod(ai,2)*channel_number//2\n",
    "        ax[np.mod(ai,2),ai//2].imshow(scaled_in_data.isel(channel=ai,hologram_number=ind),vmin=-0.25,vmax=0.25)\n",
    "    plt.savefig(\"results/\"+model_file.replace(\".h5\",\"\")+f\"_ExampleInput{index_list[ind]}\"+f\"_{num_epochs}epochs_run{run_num}_\"+ds_file.replace(\".nc\",\"\")+\".png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg,yg = np.meshgrid(preds_original['xsize'].values,preds_original['ysize'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,indact in enumerate(index_list):\n",
    "    ipart = np.nonzero(preds_original.sel(type='amplitude',hologram_number=ind).values > 0.2)\n",
    "    ipart_label = np.nonzero(test_labels.sel(type='amplitude',hologram_number=ind).values > 0.2)\n",
    "    amp_p = preds_original.sel(type='amplitude',hologram_number=ind).values[ipart]\n",
    "    z_p = preds_original.sel(type='z',hologram_number=ind).values[ipart]\n",
    "    x_p = xg[ipart]\n",
    "    y_p = yg[ipart]\n",
    "    \n",
    "    z_l = test_labels.sel(type='z',hologram_number=ind).values[ipart_label]\n",
    "    x_l = xg[ipart_label]\n",
    "    y_l = yg[ipart_label]\n",
    "\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(z_p,x_p,y_p,c=amp_p,vmin=0,vmax=1,s=1)\n",
    "    ax.scatter(z_l,x_l,y_l,c='k',s=1)\n",
    "    ax.set_xlim([ds.attrs['zmin'],ds.attrs['zmax']])\n",
    "    ax.set_ylim([preds_original['xsize'].values[0],preds_original['xsize'].values[-1]])\n",
    "    ax.set_zlim([preds_original['ysize'].values[0],preds_original['ysize'].values[-1]])\n",
    "    ax.set_xlabel('z')\n",
    "    ax.set_ylabel('x')\n",
    "    ax.set_zlabel('y')\n",
    "    plt.savefig(\"results/\"+model_file.replace(\".h5\",\"\")+f\"_Scatter3D{index_list[ind]}\"+f\"_{num_epochs}epochs_run{run_num}_\"+ds_file.replace(\".nc\",\"\")+\".png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_original['xsize'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
