{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Activation, MaxPool2D, SeparableConv2D, AveragePooling2D, concatenate,Reshape\n",
    "from tensorflow.keras.models import Model, save_model, load_model\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# set path to local libraries\n",
    "dirP_str = '../../../library'\n",
    "if dirP_str not in sys.path:\n",
    "    sys.path.append(dirP_str)\n",
    "\n",
    "import ml_utils as ml\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FourierOpticsLib as FO\n",
    "import MieLibrary as mie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"/scr/sci/mhayman/holodec/holodec-ml-data/\"\n",
    "\n",
    "# ds_file = \"synthethic_holograms_v0_svd_ac_amplitude_float.nc\"\n",
    "\n",
    "# ds_file = \"synthetic_holograms_v02_svd_multipartamplitude_d_float.nc\"\n",
    "ds_file = \"synthetic_holograms_v03_svd_multipartamplitude_d_float.nc\"\n",
    "channel_name = \"channels\"\n",
    "data_rescale = 2\n",
    "\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "\n",
    "\n",
    "ds = xr.open_dataset(ds_path+ds_file)  # file with mean (DC) value removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_num=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixwid = 3e-6  # size of pixels\n",
    "wavelength = 355e-9  # laser wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_index = 7000  # number of training+validation points\n",
    "# valid_index = 2000  # number of validation points\n",
    "# all_labels = ds[[\"d\"]].to_dataframe()\n",
    "# train_labels = all_labels.iloc[valid_index:split_index]\n",
    "# test_labels = all_labels.iloc[split_index:]\n",
    "# val_labels = all_labels.iloc[:valid_index]\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_train_labels = pd.DataFrame(scaler.fit_transform(train_labels), index=train_labels.index, columns=train_labels.columns)\n",
    "# scaled_val_labels = pd.DataFrame(scaler.fit_transform(val_labels), index=val_labels.index, columns=val_labels.columns)\n",
    "# scaled_test_labels = pd.DataFrame(scaler.transform(test_labels), index=test_labels.index, columns=test_labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = 7000  # number of training+validation points\n",
    "valid_index = 2000  # number of validation points\n",
    "all_labels = ds['particle_data'].transpose('hologram_number','particle_property','particle_number')\n",
    "\n",
    "train_labels = all_labels.isel(hologram_number=slice(valid_index,split_index))\n",
    "test_labels = all_labels.isel(hologram_number=slice(split_index,None))\n",
    "val_labels = all_labels.isel(hologram_number=slice(None,valid_index))\n",
    "\n",
    "scaler = ml.MinMaxScalerX(train_labels,dim=('hologram_number','particle_number'))\n",
    "scaled_train_labels = scaler.fit_transform(train_labels)\n",
    "scaled_val_labels = scaler.fit_transform(val_labels)\n",
    "scaled_test_labels = scaler.fit_transform(test_labels)\n",
    "scaled_all_labels = scaler.fit_transform(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['image_svd'].dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = ds['image_svd'].transpose('hologram_number','filter_number','channels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not \"channel\" in ds[\"image_ft\"].dims:\n",
    "#     in_data = ds[\"image_ft\"].transpose(\"hologram_number\", \"xsize\", 'ysize').expand_dims(\"channel\", 3)\n",
    "# else:\n",
    "#     in_data = ds[\"image_ft\"].transpose(\"hologram_number\", \"xsize\", 'ysize',\"channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['xsize'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid = FO.Coordinate_Grid(((ds['xsize'].size,ds['ysize'].size),(pixwid,pixwid)),inputType='ccd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the svd filters were created correctly\n",
    "ds['filter_set'].isel(filter_number=4).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data.sel(filter_number=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform PCA to prefilter input data\n",
    "# max_angle = np.sqrt(np.max(image_grid.fx**2+image_grid.fy**2))*wavelength\n",
    "# ang_grid = np.linspace(0,max_angle,500)\n",
    "\n",
    "# particle_range = np.linspace(5,100,100)*1e-6\n",
    "\n",
    "# scat_data = np.zeros((ang_grid.size,particle_range.size))\n",
    "# for ir,r in enumerate(particle_range):\n",
    "#     scat_data[:,ir] = np.abs(mie.Mie_PhaseMatrix(1.3,2*np.pi*r/wavelength,ang_grid)[0,:])\n",
    "#     scat_data[:,ir] = scat_data[:,ir]/np.sum(scat_data[:,ir])  # normalize the area under the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(ang_grid,scat_data)\n",
    "# plt.xlabel('scattering angle [radians]')\n",
    "# plt.ylabel('amplitude')\n",
    "# plt.grid(b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_data = scat_data.copy()\n",
    "# pca_mean = np.mean(pca_data,axis=0,keepdims=True)\n",
    "# pca_data = pca_data-pca_mean\n",
    "\n",
    "# u,s,v = np.linalg.svd(pca_data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(s)\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel('Principle Component')\n",
    "# plt.ylabel('Magnitude')\n",
    "# plt.grid(b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # based on the above plot, decide where to truncate the PCA basis set\n",
    "# itrunc = 20\n",
    "# vtrunc = v[:itrunc,:]\n",
    "# utrunc = u[:,:itrunc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(ang_grid,vtrunc.T)\n",
    "# plt.xlabel('scattering angle [radians]')\n",
    "# plt.grid(b=True)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(particle_range*1e6,utrunc)\n",
    "# plt.xlabel('particle radius [$\\mu m$]')\n",
    "# plt.grid(b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(filter_set[:,:,5].values.flatten(),'.',markersize=1)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(ang_grid,vtrunc[5,:])\n",
    "# plt.plot(grid_set.flatten(),filter_set.values[:,:,5].flatten(),'.')\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(filter_set[:,:,5])\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_data = xr.DataArray(np.zeros((in_data0.coords['hologram_number'].size,itrunc,\n",
    "#                                  in_data0.coords['channel'].size)),\n",
    "#                       dims=('hologram_number','filter_number','channel'))\n",
    "\n",
    "\n",
    "# # in_data = (in_data0*filter_set).sum(dim=('xsize','ysize',))\n",
    "# for ai in in_data0.coords['hologram_number'].values:\n",
    "#     for bi,ch in enumerate(in_data0.coords['channel'].values):\n",
    "#         in_data.values[ai,:,bi] = ((in_data0.isel(hologram_number=ai,channel=bi)*filter_set).sum(dim=('xsize','ysize',))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (in_data0.isel(hologram_number=60,channel=0)*filter_set).sum(dim=('xsize','ysize',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_data.sizes['hologram_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_data.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_data.coords['channel'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds[\"image_ft\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(); plt.plot(scaled_train_labels.values[10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_in_data = (in_data+160) / 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_descript = 'DenseNN256_SVD_RegularizedAll'\n",
    "\n",
    "filter_input = Input(shape=scaled_in_data.shape[1:])\n",
    "flat = Flatten()(filter_input)\n",
    "dense_1_ch1 = Dense(256, activation=\"relu\",kernel_regularizer=regularizers.l1(1e-3))(flat)\n",
    "dense_2_ch1 = Dense(128, activation=\"relu\",kernel_regularizer=regularizers.l1(1e-3))(dense_1_ch1)\n",
    "dense_3_ch1 = Dense(64, activation=\"relu\",kernel_regularizer=regularizers.l1(1e-3))(dense_2_ch1)\n",
    "flat_out = Dense(np.prod(all_labels.shape[1:]),activation='relu')(dense_3_ch1)  # number of outputs determined by the parameters we are training to\n",
    "out = Reshape(all_labels.shape[1:], input_shape=(np.prod(all_labels.shape[1:]),))(flat_out)\n",
    "mod = Model(filter_input, out)\n",
    "mod.compile(optimizer=\"adam\", loss=\"mae\",metrics=['acc'])\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(mod,show_shapes=True,to_file=\"results/holodec_\"+nn_descript+'_'+ds_file.replace(\".nc\",\"\")+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = mod.fit(scaled_in_data[valid_index:split_index].values, scaled_train_labels.values, \n",
    "                  batch_size=16, epochs=num_epochs, verbose=1,\n",
    "                  validation_data=(scaled_in_data[:valid_index].values,scaled_val_labels.values))\n",
    "run_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(len(history.history['acc']))+1\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "ax.plot(epochs,history.history['loss'],'bo-',alpha=0.5,label='Training')\n",
    "ax.plot(epochs,history.history['val_loss'],'rs-',alpha=0.5,label='Validation')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.grid(b=True)\n",
    "plt.legend()\n",
    "plt.savefig(\"results/LossHistory_\"+nn_descript+'_'+ds_file.replace(\".nc\",\"\")+f\"_{num_epochs}epochs_run{run_num}\"+\".png\", dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "fig, bx = plt.subplots(1, 1, figsize=(8, 4))\n",
    "bx.plot(epochs,history.history['acc'],'bo-',alpha=0.5,label='Training')\n",
    "bx.plot(epochs,history.history['val_acc'],'rs-',alpha=0.5,label='Validation')\n",
    "bx.set_xlabel('Epoch')\n",
    "bx.set_ylabel('Accuracy')\n",
    "bx.grid(b=True)\n",
    "plt.legend()\n",
    "plt.savefig(\"results/AccuracyHistory_\"+nn_descript+'_'+ds_file.replace(\".nc\",\"\")+f\"_{num_epochs}epochs_run{run_num}\"+\".png\", dpi=200, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can skip the training process and just load the CNN model\n",
    "#mod = load_model(\"holodec_ft_cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_start = datetime.datetime.now()\n",
    "preds_out = mod.predict(scaled_in_data.values, batch_size=64)\n",
    "cnn_stop = datetime.datetime.now()\n",
    "print(f\"{scaled_in_data.values.shape[0]} samples in {(cnn_stop-cnn_start).total_seconds()} seconds\")\n",
    "print(f\"for {(cnn_stop-cnn_start).total_seconds()/scaled_in_data.values.shape[0]} seconds per hologram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(mod, ds_path+\"/models/holodec_histogram_\"+nn_descript+'_'+ds_file.replace(\".nc\",\"\")+f\"{num_epochs}epochs_run{run_num}\"+\".h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_out_da = xr.DataArray(preds_out,dims=all_labels.dims,\n",
    "                            coords=all_labels.coords)\n",
    "preds_original = scaler.inverse_transform(preds_out_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = (preds_original[split_index:] - test_labels).mean(dim=('hologram_number','particle_number'))\n",
    "std_error = (preds_original[split_index:] - test_labels).std(dim=('hologram_number','particle_number'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = {}\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "for a, clabel in enumerate(all_labels.coords['particle_property'].values):\n",
    "    ax=axes.ravel()[a]\n",
    "    ax.scatter(test_labels.sel(particle_property=clabel), preds_original.sel(particle_property=clabel,hologram_number=slice(split_index,None)), 1, 'k')\n",
    "    diag = np.linspace(test_labels.sel(particle_property=clabel).min(), test_labels.sel(particle_property=clabel).max(), 10)\n",
    "    ax.plot(diag, diag, 'b--' )\n",
    "    ax.set_title(clabel)\n",
    "    plt.text(0.1,0.9,f\"${mean_error.sel(particle_property=clabel).values:.1f} \\pm {std_error.sel(particle_property=clabel).values:.1f} \\mu m$\",ha='left',va='top',transform=ax.transAxes)\n",
    "#     validation_data[test_labels.columns[a]] = test_labels.iloc[:, a]\n",
    "#     validation_data[test_labels.columns[a]+'_pred'] = preds_original[split_index:, a]\n",
    "plt.savefig(\"results/error_scatter_\"+nn_descript+'_'+ds_file.replace(\".nc\",\"\")+f\"{num_epochs}epochs_run{run_num}\"+\".png\", dpi=200, bbox_inches=\"tight\")\n",
    "# validation_data_df = pd.DataFrame(validation_data)\n",
    "# validation_data_df.to_csv('results/validation_data_denseNN_MultiIn_'+ds_file.replace(\".nc\",\"_\")+''.join(all_labels.columns)+'.txt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "for a, clabel in enumerate(all_labels.coords['particle_property'].values):\n",
    "    ax=axes.ravel()[a]\n",
    "    ax.hist( (preds_original.sel(particle_property=clabel,hologram_number=slice(split_index,None)).values - test_labels.sel(particle_property=clabel).values).flatten() / (test_labels.sel(particle_property=clabel).values.max() - test_labels.sel(particle_property=clabel).values.min()),\n",
    "           bins=20)\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"Error in \"+clabel)\n",
    "plt.savefig(\"results/relative_error_histogram\"+nn_descript+'_'+ds_file.replace(\".nc\",\"\")+f\"{num_epochs}epochs_run{run_num}\"+\".png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "for a, clabel in enumerate(all_labels.coords['particle_property'].values):\n",
    "    ax=axes.ravel()[a]\n",
    "    hprop = np.histogram2d(test_labels.sel(particle_property=clabel).values.flatten(),preds_original.sel(particle_property=clabel,hologram_number=slice(split_index,None)).values.flatten(),bins=100)\n",
    "    im = ax.pcolor(hprop[1], hprop[2],hprop[0].T/np.sum(hprop[0]))\n",
    "    diag = np.linspace(test_labels.sel(particle_property=clabel).min(), test_labels.sel(particle_property=clabel).max(), 10)\n",
    "    #ax.plot(diag, diag, 'w--' )\n",
    "    im.set_clim([0,sorted((hprop[0].flatten()/np.sum(hprop[0])))[-2]])\n",
    "    ax.set_title(clabel)\n",
    "\n",
    "plt.savefig(\"results/histogram2D_\"+nn_descript+'_'+ds_file.replace(\".nc\",\"\")+f\"{num_epochs}epochs_run{run_num}\"+\".png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,1,figsize=(12,4))\n",
    "axes.imshow(scaled_test_labels.values.T)\n",
    "axes.set_xlabel('Hologram Number')\n",
    "axes.set_ylabel('Histogram Index')\n",
    "axes.set_title('Test Labels')\n",
    "plt.savefig(\"results/Label_Histogram_\"+nn_descript+'_'+ds_file.replace(\".nc\",\"\")+f\"_{num_epochs}epochs\"+\".png\", dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "fig,axes = plt.subplots(1,1,figsize=(12,4))\n",
    "axes.imshow(preds_out[split_index:,:].T,vmin=0,vmax=0.3)\n",
    "axes.set_xlabel('Hologram Number')\n",
    "axes.set_ylabel('Histogram Index')\n",
    "axes.set_title('Test Output')\n",
    "plt.savefig(\"results/Output_Histogram_\"+nn_descript+'_'+ds_file.replace(\".nc\",\"\")+f\"_{num_epochs}epochs\"+\".png\", dpi=200, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindices = [10,234,500,1293]\n",
    "fig,axes = plt.subplots(2,2,figsize=(8,8))\n",
    "axes=axes.ravel()\n",
    "for hi,holo_index in enumerate(hindices):\n",
    "    axes[hi].plot(ds['particle_histogram'].z_bin_centers.values,scaled_test_labels.iloc[holo_index,:],label=f'Test Label {holo_index}')\n",
    "    axes[hi].plot(ds['particle_histogram'].z_bin_centers.values,preds_out[split_index+holo_index,0:],label=f'Test Output {holo_index}')\n",
    "    axes[hi].set_xlabel('Particle Diameter [$\\mu m$]')\n",
    "    \n",
    "    #axes[hi].plot(test_labels.iloc[holo_index,:],label=f'Test Label {holo_index}')\n",
    "    #axes[hi].plot(preds_out[split_index+holo_index,0:],label=f'Test Output {holo_index}')\n",
    "    \n",
    "    axes[hi].set_ylabel('Probability')\n",
    "    \n",
    "    #axes[hi].set_title(f'Hologram {holo_index}')\n",
    "    axes[hi].grid(b=True)\n",
    "    axes[hi].legend()\n",
    "\n",
    "plt.savefig(\"results/Example_Hists_\"+nn_descript+'_'+ds_file.replace(\".nc\",\"\")+f\"_{num_epochs}epochs\"+\".png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_indices = np.nonzero(scaled_test_labels.values)\n",
    "pred_values = (preds_out[split_index:,:])[part_indices]\n",
    "label_moments = []\n",
    "label_moments.append(np.sum(scaled_test_labels.values*ds['particle_histogram'].z_bin_centers.values[np.newaxis,:],axis=1)/np.sum(scaled_test_labels.values,axis=1))\n",
    "label_moments.append(np.sum(scaled_test_labels.values*ds['particle_histogram'].z_bin_centers.values[np.newaxis,:]**2,axis=1)/np.sum(scaled_test_labels.values,axis=1))\n",
    "label_moments.append(np.sum(scaled_test_labels.values*ds['particle_histogram'].z_bin_centers.values[np.newaxis,:]**3,axis=1)/np.sum(scaled_test_labels.values,axis=1))\n",
    "label_moments.append(np.sum(scaled_test_labels.values*ds['particle_histogram'].z_bin_centers.values[np.newaxis,:]**4,axis=1)/np.sum(scaled_test_labels.values,axis=1))\n",
    "\n",
    "pred_moments = []\n",
    "pred_moments.append(np.sum(preds_out[split_index:,:]*ds['particle_histogram'].z_bin_centers.values[np.newaxis,:],axis=1)/np.sum(preds_out[split_index:,:],axis=1))\n",
    "pred_moments.append(np.sum(preds_out[split_index:,:]*ds['particle_histogram'].z_bin_centers.values[np.newaxis,:]**2,axis=1)/np.sum(preds_out[split_index:,:],axis=1))\n",
    "pred_moments.append(np.sum(preds_out[split_index:,:]*ds['particle_histogram'].z_bin_centers.values[np.newaxis,:]**3,axis=1)/np.sum(preds_out[split_index:,:],axis=1))\n",
    "pred_moments.append(np.sum(preds_out[split_index:,:]*ds['particle_histogram'].z_bin_centers.values[np.newaxis,:]**4,axis=1)/np.sum(preds_out[split_index:,:],axis=1))\n",
    "std_pred = np.sqrt(pred_moments[1]-pred_moments[0]**2)\n",
    "\n",
    "mean_error = []\n",
    "std_error = []\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "for ai,ax in enumerate(axes.ravel()):\n",
    "    if ai == 0:\n",
    "        mean_error.append(np.mean(pred_moments[ai]-label_moments[ai]))\n",
    "    else:\n",
    "        mean_error.append(np.abs(np.mean(pred_moments[ai]-label_moments[ai]))**(1/(1.0+ai)))\n",
    "    std_error.append(np.std(pred_moments[ai]-label_moments[ai])**(1/(1.0+ai)))\n",
    "    ax.scatter(label_moments[ai]**(1/(1.0+ai)),pred_moments[ai]**(1/(1.0+ai)), 1, 'k')\n",
    "    diag = np.linspace(label_moments[ai].min()**(1/(1.0+ai)), label_moments[ai].max()**(1/(1.0+ai)), 10)\n",
    "    ax.plot(diag, diag, 'b--' )\n",
    "    plt.text(0.1,0.9,f\"${mean_error[ai]:.1f} \\pm {std_error[ai]:.1f} \\mu m$\",ha='left',va='top',transform=ax.transAxes)\n",
    "    ax.grid(b=True)\n",
    "    ax.set_title('moment %d'%(ai+1))\n",
    "plt.savefig(\"results/Moment_Scatter_\"+nn_descript+'_'+ds_file.replace(\".nc\",\"\")+f\"_{num_epochs}epochs\"+\".png\", dpi=200, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_moments[0]-label_moments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((pred_moments[0]-label_moments[0])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_moments[1]-pred_moments[0]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
