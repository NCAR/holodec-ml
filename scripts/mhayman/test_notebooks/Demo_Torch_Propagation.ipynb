{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "objective-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import torch\n",
    "import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bronze-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this up to point to the libararies directory in ml-holodec\n",
    "dirP_str = os.path.join(os.environ['HOME'], \n",
    "                    'Python', \n",
    "                    'holodec-ml',\n",
    "                    'library')\n",
    "if dirP_str not in sys.path:\n",
    "    sys.path.append(dirP_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "joined-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_optics_utils as optics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "weekly-variance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to use device cpu\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "if is_cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(f'Preparing to use device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "recreational-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.complex64  # fft required data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-berry",
   "metadata": {},
   "source": [
    "Load some data to use for input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "expanded-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "loaded-declaration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.) synthetic_holograms_7particle_gamma_600x400_training.nc\n",
      "1.) synthetic_holograms_10particle_gamma_512x512_validation_patches128x128.nc\n",
      "2.) synthetic_holograms_50-100particle_bidisperse_test.nc\n",
      "3.) synthetic_holograms_multiparticle_validation.nc\n",
      "4.) synthetic_holograms_1particle_training_small.nc\n",
      "5.) synthetic_holograms_6particle_gamma_600x400_test.nc\n",
      "6.) synthetic_holograms_multiparticle_training.nc\n",
      "7.) synthetic_holograms_50-100particle_gamma_private.nc\n",
      "8.) synthetic_holograms_12-25particle_gamma_600x400_validation.nc\n",
      "9.) synthetic_holograms_6particle_gamma_600x400_training.nc\n",
      "10.) synthetic_holograms_50-100particle_gamma_training.nc\n",
      "11.) synthetic_holograms_1particle_gamma_600x400_training.nc\n",
      "12.) synthetic_holograms_4particle_gamma_600x400_validation.nc\n",
      "13.) synthetic_holograms_3particle_validation.nc\n",
      "14.) synthetic_holograms_10particle_gamma_600x400_test.nc\n",
      "15.) synthetic_holograms_1particle_gamma_600x400_validation.nc\n",
      "16.) synthetic_holograms_10particle_gamma_600x400_training.nc\n",
      "17.) synthetic_holograms_50-100particle_bidisperse_training.nc\n",
      "18.) real_holograms_CSET_RF07_20150719_200000-210000_512x512.nc\n",
      "19.) synthetic_holograms_7particle_gamma_600x400_validation.nc\n",
      "20.) synthetic_holograms_2particle_gamma_600x400_validation.nc\n",
      "21.) synthetic_holograms_9particle_gamma_600x400_training.nc\n",
      "22.) synthetic_holograms_5particle_gamma_600x400_validation.nc\n",
      "23.) synthetic_holograms_12-25particle_gamma_600x400_test.nc\n",
      "24.) synthetic_holograms_4particle_gamma_600x400_training.nc\n",
      "25.) synthetic_holograms_1particle_test.nc\n",
      "26.) synthetic_holograms_10particle_gamma_600x400_validation.nc\n",
      "27.) synthetic_holograms_2particle_gamma_600x400_test.nc\n",
      "28.) synthetic_holograms_3particle_gamma_600x400_training.nc\n",
      "29.) real_holograms_CSET_RF07_20150719_203600-203700.nc\n",
      "30.) synthetic_holograms_1particle_validation.nc\n",
      "31.) synthetic_holograms_10particle_gamma_512x512_training_patches128x128.nc\n",
      "32.) synthetic_holograms_4particle_gamma_600x400_test.nc\n",
      "33.) synthetic_holograms_8particle_gamma_600x400_test.nc\n",
      "34.) synthetic_holograms_1particle_test_small.nc\n",
      "35.) synthetic_holograms_12-25particle_gamma_600x400_training.nc\n",
      "36.) synthetic_holograms_3particle_gamma_600x400_test.nc\n",
      "37.) synthetic_holograms_8particle_gamma_600x400_validation.nc\n",
      "38.) synthetic_holograms_50-100particle_bidisperse_validation.nc\n",
      "39.) synthetic_holograms_3particle_gamma_600x400_validation.nc\n",
      "40.) synthetic_holograms_50-100particle_gamma_validation.nc\n",
      "41.) synthetic_holograms_1particle_training.nc\n",
      "42.) synthetic_holograms_5particle_gamma_600x400_training.nc\n",
      "43.) synthetic_holograms_8particle_gamma_600x400_training.nc\n",
      "44.) synthetic_holograms_50-100particle_monodisperse_test.nc\n",
      "45.) synthetic_holograms_5particle_gamma_600x400_test.nc\n",
      "46.) synthetic_holograms_7particle_gamma_600x400_test.nc\n",
      "47.) synthetic_holograms_9particle_gamma_600x400_test.nc\n",
      "48.) synthetic_holograms_10particle_gamma_512x512_test_patches128x128.nc\n",
      "49.) synthetic_holograms_2particle_gamma_600x400_training.nc\n",
      "50.) synthetic_holograms_3particle_test.nc\n",
      "51.) synthetic_holograms_1particle_gamma_600x400_test.nc\n",
      "52.) real_holograms_CSET_RF07_20150719_200000-210000.nc\n",
      "53.) synthetic_holograms_50-100particle_monodisperse_training.nc\n",
      "54.) synthetic_holograms_3particle_training.nc\n",
      "55.) synthetic_holograms_50-100particle_gamma_test.nc\n",
      "56.) synthetic_holograms_9particle_gamma_600x400_validation.nc\n",
      "57.) synthetic_holograms_multiparticle_test.nc\n",
      "58.) synthetic_holograms_50-100particle_monodisperse_validation.nc\n",
      "59.) synthetic_holograms_6particle_gamma_600x400_validation.nc\n"
     ]
    }
   ],
   "source": [
    "# list all the netcdf files in data_dir\n",
    "file_list = glob.glob(data_dir+'*.nc')\n",
    "for f_idx,file in enumerate(file_list):\n",
    "    print(f'{f_idx}.) '+file.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "visible-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the file\n",
    "f_sel = 29  # selected file index (29 for real holograms)\n",
    "dataFile = file_list[f_sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "married-receipt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading real_holograms_CSET_RF07_20150719_203600-203700.nc\n"
     ]
    }
   ],
   "source": [
    "print('loading '+dataFile.split('/')[-1])\n",
    "h_ds = xr.open_dataset(dataFile)  # open the simulated data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "stopped-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "holo_idx = 0  # pick the hologram index to use\n",
    "\n",
    "# define the input tensor based as the selected input hologram\n",
    "E_input = torch.tensor(h_ds['image'].isel(hologram_number=holo_idx).values,device=device,dtype=dtype)[None,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-reply",
   "metadata": {},
   "source": [
    "These are inputs are needed to perform propagation/reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acute-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = h_ds.attrs['dx']      # horizontal resolution\n",
    "dy = h_ds.attrs['dy']      # vertical resolution\n",
    "Nx = int(h_ds.attrs['Nx']) # number of horizontal pixels\n",
    "Ny = int(h_ds.attrs['Ny']) # number of vertical pixels\n",
    "lam = h_ds.attrs['lambda'] # laser wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "considerable-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the frequency axes on the \"device\" needed for the reconstruction calculation\n",
    "fx = torch.fft.fftfreq(Nx,dx,device=device)[None,:,None]\n",
    "fy = torch.fft.fftfreq(Ny,dy,device=device)[None,None,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-executive",
   "metadata": {},
   "source": [
    "These inputs are used to define which and how many planes we reconstruct in this demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "extensive-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nplanes = 1000 #  number of z planes we want to reconstruct between z min and z max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "demanding-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation/hardware definitions for z ranges\n",
    "zMin = 0.014 # h_ds.attrs['zMin']  # minimum z in sample volume\n",
    "zMax = 0.158 # h_ds.attrs['zMax']  # maximum z in sample volume\n",
    "zCCD = 0                   # z position of the image plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "healthy-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the z position of planes we want to reconstruct\n",
    "z_plane = torch.linspace(zMin,zMax,Nplanes,device=device)[:,None,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-conservation",
   "metadata": {},
   "source": [
    "Calculate the electric field at each requested plane (z_plane)\n",
    "The output tensor has dimensions (z,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "annual-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "Eres = optics.torch_holo_set(E_input,fx,fy,z_plane,lam).detach().cpu().numpy()\n",
    "end_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "digital-activity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4872 x 3248 image\n",
      "executed 10 planes in 0.75647 seconds\n",
      " for 0.07564699999999999 seconds per plane\n"
     ]
    }
   ],
   "source": [
    "exec_time = end_time-start_time\n",
    "print(f'{E_input.shape[1]} x {E_input.shape[2]} image')\n",
    "print(f'executed {z_plane.shape[0]} planes in {exec_time.total_seconds()} seconds')\n",
    "print(f' for {exec_time.total_seconds()/z_plane.shape[0]} seconds per plane')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c5656-8cd5-44f3-a184-7fae67974c1e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acdb4601-bc36-40e1-868f-228b110044ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10  # number of planes per gpu batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a16e6346-625b-445d-8614-edce44a39c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_lst = []\n",
    "start_time = datetime.datetime.now()\n",
    "for batch_idx in range(int(np.ceil(Nplanes/batch_size))):\n",
    "    plane_lst.append(optics.torch_holo_set(E_input,fx,fy,z_plane[batch_idx*batch_size:(batch_idx+1)*batch_size],lam).detach().cpu().numpy())\n",
    "end_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "103609b6-1012-45cd-8764-23b09f1bfd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4872 x 3248 image\n",
      "executed 1000 planes in 70.8821 seconds\n",
      " for 0.07088209999999999 seconds per plane\n"
     ]
    }
   ],
   "source": [
    "exec_time = end_time-start_time\n",
    "print(f'{E_input.shape[1]} x {E_input.shape[2]} image')\n",
    "print(f'executed {z_plane.shape[0]} planes in {exec_time.total_seconds()} seconds')\n",
    "print(f' for {exec_time.total_seconds()/z_plane.shape[0]} seconds per plane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f436b363-b3a6-43ef-b18a-eb124ce8f59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4872 x 3248 image\n",
      "executed 1000 planes in 784.245014 seconds\n",
      " for 0.784245014 seconds per plane\n"
     ]
    }
   ],
   "source": [
    "exec_time = end_time-start_time\n",
    "print(f'{E_input.shape[1]} x {E_input.shape[2]} image')\n",
    "print(f'executed {z_plane.shape[0]} planes in {exec_time.total_seconds()} seconds')\n",
    "print(f' for {exec_time.total_seconds()/z_plane.shape[0]} seconds per plane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f3f936-93d4-43d8-b026-634e6f90ce8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-ml-torch]",
   "language": "python",
   "name": "conda-env-miniconda3-ml-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
