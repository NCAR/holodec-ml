{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Activation, MaxPool2D, SeparableConv2D\n",
    "from tensorflow.keras.models import Model, save_model, load_model\n",
    "from tensorflow import concat\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"/scr/sci/mhayman/holodec/holodec-ml-data/\"\n",
    "\n",
    "#ds_file = \"synthethic_holograms_ft_ac_complex_v0.nc\"\n",
    "#data_rescale = 255  # set to 1 or 255 depending on input file\n",
    "\n",
    "ds_file = \"synthethic_holograms_ft_ac_complex_amp_phase_v0.nc\" # amplitude and phase\n",
    "data_rescale = 1  # set to 1 or 255 depending on input file\n",
    "\n",
    "ds = xr.open_dataset(ds_path+ds_file)  # file with mean (DC) value removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = 7000\n",
    "all_labels = ds[[\"d\",\"z\",\"x\",\"y\"]].to_dataframe()\n",
    "train_labels = all_labels.iloc[:split_index]\n",
    "test_labels = all_labels.iloc[split_index:]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_labels = pd.DataFrame(scaler.fit_transform(train_labels), index=train_labels.index, columns=train_labels.columns)\n",
    "scaled_test_labels = pd.DataFrame(scaler.transform(test_labels), index=test_labels.index, columns=test_labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ysize', 'xsize', 'hologram_number')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['image_ft'][1,:,:,:].dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_data_p = ds[\"image_ft\"][1,:,:,:].transpose(\"hologram_number\", \"ysize\", \"xsize\").expand_dims(\"channel\", 3)\n",
    "#in_data_a = ds[\"image_ft\"][0,:,:,:].transpose(\"hologram_number\", \"ysize\", \"xsize\").expand_dims(\"channel\", 3)\n",
    "in_data = ds[\"image_ft\"].transpose(\"hologram_number\", \"ysize\", \"xsize\",\"complex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 600, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_in_data = in_data / data_rescale\n",
    "#scaled_in_data_a = in_data_a / data_rescale\n",
    "#scaled_in_data_p = in_data_p / data_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 400, 600, 2)]     0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 400, 600, 8)       74        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 400, 600, 8)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 100, 150, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 100, 150, 16)      3216      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100, 150, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 37, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 25, 37, 32)        12832     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 25, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                110656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 128,990\n",
      "Trainable params: 128,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#conv_input_a = Input(shape=in_data_a.shape[1:])  # amplitude input\n",
    "#conv_1a = Conv2D(8, (5, 5), padding=\"same\")(conv_input_a)\n",
    "#act_1a = Activation(\"relu\")(conv_1a)\n",
    "#pool_1a = MaxPool2D(pool_size=(4, 4))(act_1a)\n",
    "\n",
    "#conv_input_p = Input(shape=in_data_p.shape[1:])  # amplitude input\n",
    "#conv_1p = Conv2D(8, (5, 5), padding=\"same\")(conv_input_p)\n",
    "#act_1p = Activation(\"relu\")(conv_1p)\n",
    "#pool_1p = MaxPool2D(pool_size=(4, 4))(act_1p)\n",
    "\n",
    "#pool_1 = concat([pool_1a,pool_1p],3)  # combine results from first layer\n",
    "\n",
    "conv_input = Input(shape=in_data.shape[1:])  # amplitude input\n",
    "conv_1 = SeparableConv2D(8, (5, 5), padding=\"same\")(conv_input)\n",
    "act_1 = Activation(\"relu\")(conv_1)\n",
    "pool_1 = MaxPool2D(pool_size=(4, 4))(act_1)\n",
    "\n",
    "conv_2 = Conv2D(16, (5, 5), padding=\"same\")(pool_1)\n",
    "act_2 = Activation(\"relu\")(conv_2)\n",
    "pool_2 = MaxPool2D(pool_size=(4, 4))(act_2)\n",
    "conv_3 = Conv2D(32, (5, 5), padding=\"same\")(pool_2)\n",
    "act_3 = Activation(\"relu\")(conv_3)\n",
    "pool_3 = MaxPool2D(pool_size=(4, 4))(act_3)\n",
    "flat = Flatten()(pool_3)\n",
    "dense_1 = Dense(64, activation=\"relu\")(flat)\n",
    "dense_2 = Dense(32, activation=\"relu\")(dense_1)\n",
    "out = Dense(all_labels.shape[1])(dense_2)  # number of outputs determined by the parameters we are training to\n",
    "mod = Model(conv_input, out)\n",
    "mod.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples\n",
      "Epoch 1/30\n",
      "7000/7000 [==============================] - 217s 31ms/sample - loss: 0.2344\n",
      "Epoch 2/30\n",
      "7000/7000 [==============================] - 222s 32ms/sample - loss: 0.1548\n",
      "Epoch 3/30\n",
      "7000/7000 [==============================] - 219s 31ms/sample - loss: 0.1263\n",
      "Epoch 4/30\n",
      "7000/7000 [==============================] - 214s 31ms/sample - loss: 0.0695\n",
      "Epoch 5/30\n",
      "7000/7000 [==============================] - 216s 31ms/sample - loss: 0.0504\n",
      "Epoch 6/30\n",
      "7000/7000 [==============================] - 216s 31ms/sample - loss: 0.0457\n",
      "Epoch 7/30\n",
      "7000/7000 [==============================] - 216s 31ms/sample - loss: 0.0400\n",
      "Epoch 8/30\n",
      "7000/7000 [==============================] - 218s 31ms/sample - loss: 0.0372\n",
      "Epoch 9/30\n",
      "7000/7000 [==============================] - 224s 32ms/sample - loss: 0.0346\n",
      "Epoch 10/30\n",
      "7000/7000 [==============================] - 216s 31ms/sample - loss: 0.0325\n",
      "Epoch 11/30\n",
      "7000/7000 [==============================] - 219s 31ms/sample - loss: 0.0303\n",
      "Epoch 12/30\n",
      "7000/7000 [==============================] - 216s 31ms/sample - loss: 0.0293\n",
      "Epoch 13/30\n",
      "7000/7000 [==============================] - 218s 31ms/sample - loss: 0.0287\n",
      "Epoch 14/30\n",
      "7000/7000 [==============================] - 225s 32ms/sample - loss: 0.0274\n",
      "Epoch 15/30\n",
      "7000/7000 [==============================] - 229s 33ms/sample - loss: 0.0260\n",
      "Epoch 16/30\n",
      "7000/7000 [==============================] - 222s 32ms/sample - loss: 0.0256\n",
      "Epoch 17/30\n",
      "7000/7000 [==============================] - 221s 32ms/sample - loss: 0.0248\n",
      "Epoch 18/30\n",
      "7000/7000 [==============================] - 217s 31ms/sample - loss: 0.0238\n",
      "Epoch 19/30\n",
      "1968/7000 [=======>......................] - ETA: 2:37 - loss: 0.0237"
     ]
    }
   ],
   "source": [
    "mod.fit(scaled_in_data[:split_index].values, scaled_train_labels.values, batch_size=16, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_in_data[:split_index].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can skip the training process and just load the CNN model\n",
    "# mod = load_model(\"holodec_ft_dxyz_cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_start = datetime.datetime.now()\n",
    "preds_out = mod.predict(scaled_in_data.values, batch_size=64)\n",
    "cnn_stop = datetime.datetime.now()\n",
    "print(f\"{scaled_in_data.values.shape[0]} samples in {(cnn_stop-cnn_start).total_seconds()} seconds\")\n",
    "print(f\"for {(cnn_stop-cnn_start).total_seconds()/scaled_in_data.values.shape[0]} seconds per hologram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(mod, \"holodec_2channel_\"+ds_file.replace(\".nc\",\"\")+\"\".join(all_labels.columns)+\"_cnn.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_original = scaler.inverse_transform(preds_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_labels.max() - test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join(all_labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = {}\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "for a, clabel in enumerate(all_labels.columns):\n",
    "    ax=axes.ravel()[a]\n",
    "    ax.scatter(test_labels.iloc[:, a], preds_original[split_index:, a], 1, 'k')\n",
    "    diag = np.linspace(test_labels.iloc[:, a].min(), test_labels.iloc[:, a].max(), 10)\n",
    "    ax.plot(diag, diag, 'b--' )\n",
    "    ax.set_title(test_labels.columns[a])\n",
    "    validation_data[test_labels.columns[a]] = test_labels.iloc[:, a]\n",
    "    validation_data[test_labels.columns[a]+'_pred'] = preds_original[split_index:, a]\n",
    "plt.savefig(\"error_scatter_phase_only_\"+ds_file.replace(\".nc\",\"_\")+\"\".join(all_labels.columns)+\".png\", dpi=200, bbox_inches=\"tight\")\n",
    "validation_data_df = pd.DataFrame(validation_data)\n",
    "validation_data_df.to_csv('validation_data_phase_only_'+ds_file.replace(\".nc\",\"_\")+''.join(all_labels.columns)+'.txt')\n",
    "# for a, ax in enumerate(axes.ravel()):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "for a, clabel in enumerate(all_labels.columns):\n",
    "    ax=axes.ravel()[a]\n",
    "    ax.hist( (preds_original[split_index:, a] - test_labels.iloc[:, a].values) / (test_labels.iloc[:, a].max() - test_labels.iloc[:, a].min()),\n",
    "           bins=20)\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"Error in \"+test_labels.columns[a])\n",
    "plt.savefig(\"relative_error_histogram_phase_only_\"+ds_file.replace(\".nc\",\"_\")+\"\".join(all_labels.columns)+\".png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(preds_original[split_index:] - test_labels.values), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(preds_original[split_index:] - test_labels.values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(preds_original[split_index:] - test_labels.values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(preds_out[split_index:] - scaled_test_labels.values), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"xsize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
