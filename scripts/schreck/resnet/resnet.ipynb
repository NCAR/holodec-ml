{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.disable_eager_execution()\n",
    "\n",
    "import sys \n",
    "import yaml\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import traceback\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy.fft as FFT\n",
    "from typing import List, Dict\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "from tensorflow.keras.layers import (Input, Conv2D, Dense, Flatten, \n",
    "                                     MaxPooling2D, RepeatVector, Lambda,\n",
    "                                     LeakyReLU, Dropout, Add, Activation, AveragePooling2D,\n",
    "                                    ZeroPadding2D, BatchNormalization)\n",
    "from tensorflow.keras.models import Model, save_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from keras_radam import RAdam\n",
    "from keras_radam.training import RAdamOptimizer\n",
    "\n",
    "from holodecml.library.losses import SymmetricCrossEntropy\n",
    "from holodecml.library.callbacks import get_callbacks\n",
    "from holodecml.library.FourierOpticsLib import OpticsFFT, OpticsIFFT\n",
    "\n",
    "from multiprocessing import cpu_count, Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file) as config_file:\n",
    "    config = yaml.load(config_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"path_save\"] = \"resnet\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(config[\"path_save\"])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(levelname)s:%(name)s:%(message)s')\n",
    "\n",
    "# Stream output to stdout\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(formatter)\n",
    "root.addHandler(ch)\n",
    "#########\n",
    "\n",
    "# Save the log file\n",
    "fp = os.path.join(f'{config[\"path_save\"]}/log.txt')\n",
    "fh = logging.FileHandler(fp,\n",
    "                         mode='w',\n",
    "                         encoding='utf-8')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "root.addHandler(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up some globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = config[\"path_data\"]\n",
    "num_particles = config[\"num_particles\"]\n",
    "split = 'train'\n",
    "subset = False\n",
    "output_cols = [\"x\", \"y\", \"z\", \"d\", \"hid\"]\n",
    "\n",
    "batch_size = config[\"conv2d_network\"][\"batch_size\"]\n",
    "\n",
    "input_shape = (600, 400, 4)\n",
    "\n",
    "n_particles = config[\"num_particles\"]\n",
    "output_channels = len(output_cols) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles_dict = {\n",
    "    1: '1particle',\n",
    "    3: '3particle',\n",
    "    'multi': 'multiparticle',\n",
    "    '50-100': '50-100'}\n",
    "\n",
    "split_dict = {\n",
    "    'train' : 'training',\n",
    "    'test'   : 'test',\n",
    "    'valid': 'validation'}\n",
    "\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(\n",
    "        \n",
    "        self, \n",
    "        path_data: str, \n",
    "        num_particles: int, \n",
    "        split: str, \n",
    "        subset: bool, \n",
    "        output_cols: List[str], \n",
    "        batch_size: int, \n",
    "        shuffle: bool = True,\n",
    "        maxnum_particles: int = False,\n",
    "        scaler: Dict[str, str] = False) -> None:\n",
    "        \n",
    "        'Initialization'\n",
    "        self.ds = self.open_dataset(path_data, num_particles, split)\n",
    "        self.batch_size = batch_size\n",
    "        self.output_cols = [x for x in output_cols if x != 'hid']        \n",
    "        self.subset = subset\n",
    "        self.hologram_numbers = self.ds.hologram_number.values\n",
    "        if shuffle:\n",
    "            random.shuffle(self.hologram_numbers)\n",
    "        self.num_particles = num_particles\n",
    "        self.xsize = len(self.ds.xsize.values)\n",
    "        self.ysize = len(self.ds.ysize.values)\n",
    "        self.shuffle = shuffle\n",
    "        self.maxnum_particles = maxnum_particles\n",
    "                \n",
    "        if not scaler:\n",
    "            self.scaler = {col: StandardScaler() for col in output_cols}\n",
    "            for col in output_cols:\n",
    "                scale = self.ds[col].values\n",
    "                self.scaler[col].fit(scale.reshape(scale.shape[-1], -1))\n",
    "        else:\n",
    "            self.scaler = scaler\n",
    "        \n",
    "    def get_transform(self):\n",
    "        return self.scaler\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return math.ceil(len(self.hologram_numbers) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        'Generate one batch of data'\n",
    "        holograms = self.hologram_numbers[\n",
    "            idx * self.batch_size: (idx + 1) * self.batch_size\n",
    "        ]\n",
    "        x_out, y_out, w_out = self._batch(holograms)\n",
    "        return x_out, y_out, w_out\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle == True:\n",
    "            random.shuffle(self.hologram_numbers)\n",
    "            \n",
    "    def standardize(self, X):\n",
    "        X = (X-np.mean(X)) / (np.std(X))\n",
    "        return X\n",
    "    \n",
    "    def reshape(self, X):\n",
    "        x, y = X.shape\n",
    "        return X.reshape((x,y,1))\n",
    "            \n",
    "    def _batch(self, holograms: List[int]):\n",
    "        'Create a batch of data'\n",
    "        try:\n",
    "        \n",
    "            x_out = np.zeros((\n",
    "                len(holograms), self.xsize, self.ysize, 4\n",
    "            ))\n",
    "            y_out = np.zeros((\n",
    "                len(holograms), \n",
    "                self.maxnum_particles if self.maxnum_particles else self.num_particles, \n",
    "                len(self.output_cols)\n",
    "            ))\n",
    "            # Move the scaler.transform to here\n",
    "            \n",
    "            a = time.time()\n",
    "            for k, hologram in enumerate(holograms):\n",
    "                im = self.ds[\"image\"][hologram].values\n",
    "                A = self.standardize(im)\n",
    "                F = OpticsFFT(A)                     \n",
    "                R = self.reshape(self.standardize(np.log(np.abs(F))))\n",
    "                P = self.reshape(self.standardize(np.real(F)))\n",
    "                Q = self.reshape(self.standardize(np.imag(F)))\n",
    "                x_out[k] = np.concatenate((self.reshape(A), R, P, Q), axis = 2)\n",
    "                particles = np.where(self.ds[\"hid\"] == hologram + 1)[0]  \n",
    "                for l, p in enumerate(particles):\n",
    "                    for m, col in enumerate(self.output_cols):\n",
    "                        val = self.ds[col][p].values\n",
    "                        y_out[k, l, m] = self.scaler[col].transform(\n",
    "                            val.reshape(1, -1)\n",
    "                        )\n",
    "                if self.maxnum_particles and len(particles) < self.maxnum_particles:\n",
    "                    for l in range(len(particles), self.maxnum_particles):\n",
    "                        for m, col in enumerate(self.output_cols):\n",
    "                            val = y_out[k, l, m]\n",
    "                            y_out[k, l, m] = self.scaler[col].transform(\n",
    "                                val.reshape(1, -1)\n",
    "                            )\n",
    "            #\n",
    "            # convert y_out to sparse if we are using padding\n",
    "#             if self.maxnum_particles:\n",
    "#                 y_out = sparse_vstack([\n",
    "#                     csr_matrix(y_out[i]) for i in y_out.shape[0]\n",
    "#                 ])\n",
    "            \n",
    "            #x_out = np.expand_dims(x_out, axis=-1)\n",
    "            return x_out, y_out, [None] #class weights option\n",
    "        \n",
    "        except:\n",
    "            print(traceback.print_exc())\n",
    "    \n",
    "    def open_dataset(self, path_data, num_particles, split):\n",
    "        \"\"\"\n",
    "        Opens a HOLODEC file\n",
    "\n",
    "        Args: \n",
    "            path_data: (str) Path to dataset directory\n",
    "            num_particles: (int or str) Number of particles per hologram\n",
    "            split: (str) Dataset split of either 'train', 'valid', or 'test'\n",
    "\n",
    "        Returns:\n",
    "            ds: (xarray Dataset) Opened dataset\n",
    "        \"\"\"\n",
    "        path_data = os.path.join(path_data, self.dataset_name(num_particles, split))\n",
    "\n",
    "        if not os.path.isfile(path_data):\n",
    "            print(f\"Data file does not exist at {path_data}. Exiting.\")\n",
    "            raise \n",
    "\n",
    "        ds = xr.open_dataset(path_data)\n",
    "        return ds\n",
    "    \n",
    "    def dataset_name(self, num_particles, split, file_extension='nc'):\n",
    "        \"\"\"\n",
    "        Return the dataset filename given user inputs\n",
    "\n",
    "        Args: \n",
    "            num_particles: (int or str) Number of particles per hologram\n",
    "            split: (str) Dataset split of either 'train', 'valid', or 'test'\n",
    "            file_extension: (str) Dataset file extension\n",
    "\n",
    "        Returns:\n",
    "            ds_name: (str) Dataset name\n",
    "        \"\"\"\n",
    "\n",
    "        valid = [1,3,'multi','50-100']\n",
    "        if num_particles not in valid:\n",
    "            raise ValueError(\"results: num_particles must be one of %r.\" % valid)\n",
    "        num_particles = num_particles_dict[num_particles]\n",
    "\n",
    "        valid = ['train','test','valid']\n",
    "        if split not in valid:\n",
    "            raise ValueError(\"results: split must be one of %r.\" % valid)\n",
    "        split = split_dict[split]\n",
    "        ds_name = f'synthetic_holograms_{num_particles}_{split}.{file_extension}'\n",
    "\n",
    "        return ds_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(\n",
    "    path_data, num_particles, \"train\", subset, \n",
    "    output_cols, batch_size, maxnum_particles = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = train_gen.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = {col: StandardScaler() for col in train_gen.output_cols}\n",
    "# for col in train_gen.output_cols:\n",
    "#     scale = train_gen.ds[col].values\n",
    "#     scaler[col].fit(scale.reshape(scale.shape[-1], -1))\n",
    "#     result = scaler[col].transform(scale.reshape(scale.shape[-1], -1))\n",
    "#     print(col, min(result), max(result), np.mean(result), np.std(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scalers = train_gen.get_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    path_data, num_particles, \"test\", subset, \n",
    "    output_cols, batch_size, scaler = train_scalers, maxnum_particles = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = get_callbacks(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def R2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return 1 - SS_res/(SS_tot + K.epsilon())\n",
    "\n",
    "def keras_mse(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))\n",
    "\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wsme(y_true, y_pred):\n",
    "#     cond1 = K.equal(y_true, 0.0)\n",
    "#     zero = K.switch(cond1,K.square(y_pred - y_true), \n",
    "#                              K.zeros_like(y_true))\n",
    "#     cond2 = K.greater(y_true, 0.0)\n",
    "#     real = K.switch(cond2, \n",
    "#                              K.square(y_pred - y_true), \n",
    "#                              K.zeros_like(y_true))\n",
    "#     w1 = K.sum(K.cast(cond1, \"float\"))\n",
    "#     w2 = K.sum(K.cast(cond2, \"float\"))\n",
    "#     total = w1 + w2\n",
    "#     zero = K.sum(zero) / w1\n",
    "#     real = K.sum(real) / w2\n",
    "#     return (real + zero)\n",
    "\n",
    "def wsme(y_true, y_pred):\n",
    "    \n",
    "    w = K.abs(K.mean(y_true[1]))\n",
    "    w = w / (1 - w)\n",
    "    \n",
    "    # w = K.sum(K.cast(K.greater(y_true[1], 0), \"float\")) # Number actually not zero\n",
    "    \n",
    "    error = K.square(y_true - y_pred)\n",
    "    error = K.switch(K.equal(y_true, 0), w * error, error)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 3\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(name=bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convolutional_block\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    \"\"\"\n",
    "  \n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(name=bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((1, 1))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    #X = Dense(10, activation='relu', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    #X = Dropout(0.1)(X)\n",
    "    #X = Dense(1, activation='linear', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "   \n",
    "\n",
    "    # Create model\n",
    "    #model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return X_input, X #model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "n_particles = 3\n",
    "\n",
    "custom_losses = {\n",
    "    \"sce\": SymmetricCrossEntropy(0.5, 0.5),\n",
    "    \"weighted_mse\": wsme,\n",
    "    \"r2\": R2,\n",
    "    \"rmse\": rmse\n",
    "}\n",
    "\n",
    "class Conv2DNeuralNetwork(object):\n",
    "    \"\"\"\n",
    "    A Conv2D Neural Network Model that can support an arbitrary numbers of\n",
    "    layers.\n",
    "\n",
    "    Attributes:\n",
    "        filters: List of number of filters in each Conv2D layer\n",
    "        kernel_sizes: List of kernel sizes in each Conv2D layer\n",
    "        conv2d_activation: Type of activation function for conv2d layers\n",
    "        pool_sizes: List of Max Pool sizes\n",
    "        dense_sizes: Sizes of dense layers\n",
    "        dense_activation: Type of activation function for dense layers\n",
    "        output_activation: Type of activation function for output layer\n",
    "        lr: Optimizer learning rate\n",
    "        optimizer: Name of optimizer or optimizer object.\n",
    "        adam_beta_1: Exponential decay rate for the first moment estimates\n",
    "        adam_beta_2: Exponential decay rate for the first moment estimates\n",
    "        sgd_momentum: Stochastic Gradient Descent momentum\n",
    "        decay: Optimizer decay\n",
    "        loss: Name of loss function or loss object\n",
    "        batch_size: Number of examples per batch\n",
    "        epochs: Number of epochs to train\n",
    "        verbose: Level of detail to provide during training\n",
    "        model: Keras Model object\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        filters=(8,), \n",
    "        kernel_sizes=(5,),\n",
    "        conv2d_activation=\"relu\", \n",
    "        pool_sizes=(4,), \n",
    "        pool_dropout=0.0,\n",
    "        dense_sizes=(64,),\n",
    "        dense_activation=\"relu\", \n",
    "        dense_dropout = 0.0,\n",
    "        output_activation=\"linear\",\n",
    "        lr=0.001, \n",
    "        optimizer=\"adam\", \n",
    "        adam_beta_1=0.9,\n",
    "        adam_beta_2=0.999, \n",
    "        sgd_momentum=0.9, \n",
    "        decay=0, \n",
    "        loss=\"mse\",\n",
    "        metrics = [], \n",
    "        batch_size=32, \n",
    "        epochs=2, \n",
    "        verbose=0):\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.kernel_sizes = [tuple((v,v)) for v in kernel_sizes]\n",
    "        self.conv2d_activation = conv2d_activation\n",
    "        self.pool_sizes = [tuple((v,v)) for v in pool_sizes]\n",
    "        self.pool_dropout = pool_dropout\n",
    "        self.dense_sizes = dense_sizes\n",
    "        self.dense_activation = dense_activation\n",
    "        self.dense_dropout = dense_dropout\n",
    "        self.output_activation = output_activation\n",
    "        self.lr = lr\n",
    "        self.optimizer = optimizer\n",
    "        self.optimizer_obj = None\n",
    "        self.adam_beta_1 = adam_beta_1\n",
    "        self.adam_beta_2 = adam_beta_2\n",
    "        self.sgd_momentum = sgd_momentum\n",
    "        self.decay = decay\n",
    "        self.loss = custom_losses[loss] if loss in custom_losses else loss\n",
    "        self.metrics = []\n",
    "        for m in metrics:\n",
    "            if m in custom_losses:\n",
    "                self.metrics.append(custom_losses[m])\n",
    "            else:\n",
    "                self.metrics.append(m)\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "        \n",
    "        if self.conv2d_activation == \"leakyrelu\":\n",
    "            self.conv2d_activation = LeakyReLU(alpha=0.1)\n",
    "        if self.dense_activation == \"leakyrelu\":\n",
    "            self.dense_activation = LeakyReLU(alpha=0.1)\n",
    "        if self.output_activation == \"leakyrelu\":\n",
    "            self.output_activation = LeakyReLU(alpha=0.1)\n",
    "\n",
    "    def build_neural_network(self, input_shape, n_particles, output_shape):\n",
    "        \"\"\"Create Keras neural network model and compile it.\"\"\"\n",
    "                \n",
    "        # Input\n",
    "        conv_input, nn_model = ResNet50(input_shape)\n",
    "        nn_model = RepeatVector(n_particles, name = \"repeat\")(nn_model)\n",
    "        nn_model = Dense(output_shape,\n",
    "                         activation=self.output_activation,\n",
    "                         name=f\"dense_output\")(nn_model)\n",
    "        nn_model = Lambda(\n",
    "            self.LastLayer,\n",
    "            input_shape = (n_particles, output_shape),\n",
    "            name=\"coordinate\"\n",
    "        )(nn_model)\n",
    "        \n",
    "        self.model = Model(\n",
    "            inputs = conv_input, \n",
    "            outputs = nn_model\n",
    "        )\n",
    "        \n",
    "        if self.optimizer == \"adam\":\n",
    "            self.optimizer_obj = Adam(lr=self.lr, clipnorm = 1.0)\n",
    "        elif self.optimizer == \"sgd\":\n",
    "            self.optimizer_obj = SGD(lr=self.lr, momentum=self.sgd_momentum,\n",
    "                                     decay=self.decay)\n",
    "            \n",
    "        lr_metric = get_lr_metric(self.optimizer_obj)\n",
    "        self.model.compile(\n",
    "            optimizer=self.optimizer_obj, \n",
    "            loss=self.loss,\n",
    "            metrics=self.metrics + [lr_metric]\n",
    "        )\n",
    "        self.model.summary()\n",
    "    \n",
    "    def LastLayer(self, x):\n",
    "        return 1.75 * K.tanh(x / 100) \n",
    "\n",
    "    def predict(self, x):\n",
    "        y_out = self.model.predict(np.expand_dims(x, axis=-1),\n",
    "                                   batch_size=self.batch_size)\n",
    "        return y_out\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        y_prob = self.model.predict(x, batch_size=self.batch_size)\n",
    "        return y_prob\n",
    "    \n",
    "    def load_weights(self, weights):\n",
    "        try:\n",
    "            self.model.load_weights(weights)\n",
    "            self.model.compile(\n",
    "                optimizer=self.optimizer, \n",
    "                loss=self.loss, \n",
    "                metrics=self.metrics\n",
    "            )\n",
    "        except:\n",
    "            print(\"You must first call build_neural_network before loading weights. Exiting.\")\n",
    "            sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "ops.reset_default_graph()\n",
    "mod = Conv2DNeuralNetwork(**config[\"conv2d_network\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 600, 400, 4) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 602, 402, 4)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 298, 198, 64) 12608       zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 298, 198, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 298, 198, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 148, 98, 64)  0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 148, 98, 64)  4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 148, 98, 64)  256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 148, 98, 64)  0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 148, 98, 64)  36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 148, 98, 64)  256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 148, 98, 64)  0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 148, 98, 256) 16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 148, 98, 256) 16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 148, 98, 256) 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 148, 98, 256) 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 148, 98, 256) 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 148, 98, 256) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 148, 98, 64)  16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 148, 98, 64)  256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 148, 98, 64)  0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 148, 98, 64)  36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 148, 98, 64)  256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 148, 98, 64)  0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 148, 98, 256) 16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 148, 98, 256) 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 148, 98, 256) 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 148, 98, 256) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 148, 98, 64)  16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 148, 98, 64)  256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 148, 98, 64)  0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 148, 98, 64)  36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 148, 98, 64)  256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 148, 98, 64)  0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 148, 98, 256) 16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 148, 98, 256) 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 148, 98, 256) 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 148, 98, 256) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 74, 49, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 74, 49, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 74, 49, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 74, 49, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 74, 49, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 74, 49, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 74, 49, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 74, 49, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 74, 49, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 74, 49, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 74, 49, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 74, 49, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 74, 49, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 74, 49, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 74, 49, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 74, 49, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 74, 49, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 74, 49, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 74, 49, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 74, 49, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 74, 49, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 74, 49, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 74, 49, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 74, 49, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 74, 49, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 74, 49, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 74, 49, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 74, 49, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 74, 49, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 74, 49, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 74, 49, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 74, 49, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 74, 49, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 74, 49, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 74, 49, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 74, 49, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 74, 49, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 74, 49, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 74, 49, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 74, 49, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 74, 49, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 74, 49, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 37, 25, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 37, 25, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 37, 25, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 37, 25, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 37, 25, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 37, 25, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 37, 25, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 37, 25, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 37, 25, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 37, 25, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 37, 25, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 37, 25, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 37, 25, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 37, 25, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 37, 25, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 37, 25, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 37, 25, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 37, 25, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 37, 25, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 37, 25, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 37, 25, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 37, 25, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 37, 25, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 37, 25, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 37, 25, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 37, 25, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 37, 25, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 37, 25, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 37, 25, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 37, 25, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 37, 25, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 37, 25, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 37, 25, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 37, 25, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 37, 25, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 37, 25, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 37, 25, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 37, 25, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 37, 25, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 37, 25, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 37, 25, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 37, 25, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 37, 25, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 37, 25, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 37, 25, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 37, 25, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 37, 25, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 37, 25, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 37, 25, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 37, 25, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 37, 25, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 37, 25, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 37, 25, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 37, 25, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 37, 25, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 37, 25, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 37, 25, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 37, 25, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 37, 25, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 37, 25, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 37, 25, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 37, 25, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 19, 13, 512)  524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 19, 13, 512)  2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 19, 13, 512)  0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 19, 13, 512)  2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 19, 13, 512)  2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 19, 13, 512)  0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 19, 13, 2048) 1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 19, 13, 2048) 2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 19, 13, 2048) 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 19, 13, 2048) 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 19, 13, 2048) 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 19, 13, 2048) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 19, 13, 512)  1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 19, 13, 512)  2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 19, 13, 512)  0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 19, 13, 512)  2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 19, 13, 512)  2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 19, 13, 512)  0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 19, 13, 2048) 1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 19, 13, 2048) 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 19, 13, 2048) 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 19, 13, 2048) 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 19, 13, 512)  1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 19, 13, 512)  2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 19, 13, 512)  0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 19, 13, 512)  2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 19, 13, 512)  2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 19, 13, 512)  0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 19, 13, 2048) 1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 19, 13, 2048) 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 19, 13, 2048) 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 19, 13, 2048) 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 10, 7, 2048)  0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 143360)       0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "repeat (RepeatVector)           (None, 3, 143360)    0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_output (Dense)            (None, 3, 4)         573444      repeat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "coordinate (Lambda)             (None, 3, 4)         0           dense_output[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 24,164,292\n",
      "Trainable params: 24,111,172\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.build_neural_network(input_shape, n_particles, output_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "290/782 [==========>...................] - ETA: 12:22 - loss: 1.0793 - R2: 0.3456 - lr: 2.5000e-04"
     ]
    }
   ],
   "source": [
    "mod.model.fit_generator(\n",
    "    generator=train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=config[\"conv2d_network\"][\"epochs\"],\n",
    "    verbose=True,\n",
    "    callbacks=callbacks,\n",
    "    use_multiprocessing=True,\n",
    "    workers=16,\n",
    "    max_queue_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use sklearn to do Bayesian optimzation of hyperparameters\n",
    "\n",
    "##### (Based on https://medium.com/@crawftv/parameter-hyperparameter-tuning-with-bayesian-optimization-7acf42d348e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import skopt\n",
    "# from skopt import gbrt_minimize, gp_minimize\n",
    "# from skopt.utils import use_named_args\n",
    "# from skopt.space import Real, Categorical, Integer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter1 = Integer(low=1, high=64, name='filter1')\n",
    "# filter2 = Integer(low=1, high=64, name='filter2')\n",
    "# filter3 = Integer(low=1, high=64, name='filter3')\n",
    "# kernel_sizes = Integer(low=1, high=10, name='kernel_sizes')\n",
    "# pool_sizes = Integer(low=1, high=50, name='pool_sizes')\n",
    "# dense_1 = Integer(low=10, high=1000, name='dense_1')\n",
    "# dense_2 = Integer(low=10, high=1000, name='dense_2')\n",
    "# learning_rate = Real(low=1e-5, high=1e-2, prior='log-uniform',\n",
    "#                          name='learning_rate')\n",
    "\n",
    "# # To add \n",
    "# ## kernel size dimensions \n",
    "# ## pool size dimensions \n",
    "# ## dropout for pool layers\n",
    "# ## dropout for dense layers\n",
    "# ## Number of dense layers\n",
    "# ## scaling factor I use in Lambda function\n",
    "\n",
    "# dimensions = [\n",
    "#     filter1,\n",
    "#     filter2,\n",
    "#     filter3,\n",
    "#     kernel_sizes,\n",
    "#     pool_sizes,\n",
    "#     dense_1,\n",
    "#     dense_2,\n",
    "#     learning_rate\n",
    "# ]\n",
    "\n",
    "# default_parameters = [52, 64, 41, 2, 29, 175, 912, 0.01]\n",
    "\n",
    "# #[57, 57, 18, 6, 10, 781, 607, 0.005285282058684279]\n",
    "# # [8, 12, 16, 5, 5, 64, 32, 1e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @use_named_args(dimensions=dimensions)\n",
    "# def fitness(\n",
    "#     filter1, filter2, filter3,\n",
    "#     kernel_sizes, pool_sizes,\n",
    "#     dense_1, dense_2, learning_rate):\n",
    "    \n",
    "    \n",
    "#     a = time.time()\n",
    "    \n",
    "#     # Update the configuration\n",
    "#     c = config[\"conv2d_network\"]\n",
    "#     c[\"filters\"] = [filter1, filter2, filter3]\n",
    "#     c[\"kernel_sizes\"] = [kernel_sizes, kernel_sizes, kernel_sizes]\n",
    "#     c[\"pool_sizes\"] = [pool_sizes, pool_sizes, pool_sizes]\n",
    "#     c[\"dense_sizes\"] = [dense_1, dense_2]\n",
    "#     c[\"lr\"] = learning_rate\n",
    "#     c[\"epochs\"] = 1\n",
    "    \n",
    "#     save_path = os.path.join(config[\"path_save\"], \"log.txt\")\n",
    "#     with open(save_path, \"a+\") as fid:\n",
    "#         fid.write(\"------------------------------------\\n\")\n",
    "#         fid.write(\"Starting run\\n\")\n",
    "#         fid.write(f\"filters: {filter1,filter2,filter3} kernel_size: {kernel_sizes} pool_size: {pool_sizes} dense1: {dense_1} dense2: {dense_2} lr: {learning_rate}\\n\")\n",
    "\n",
    "#     # Load the model\n",
    "#     model = Conv2DNeuralNetwork(**c)\n",
    "#     model.build_neural_network(input_shape, n_particles, output_channels)\n",
    "    \n",
    "#     # Load callbacks, though we prob. wont need them for 1 epoch optimization\n",
    "#     callbacks = get_callbacks(config)\n",
    "    \n",
    "#     # Train a model\n",
    "#     blackbox = model.model.fit(\n",
    "#         train_gen,\n",
    "#         validation_data=valid_gen,\n",
    "#         epochs=config[\"conv2d_network\"][\"epochs\"],\n",
    "#         verbose=True,\n",
    "#         callbacks=callbacks,\n",
    "#         use_multiprocessing=True,\n",
    "#         workers=24,\n",
    "#         max_queue_size=100\n",
    "#     )\n",
    "    \n",
    "#     # Return the validation accuracy for the last epoch.\n",
    "#     objective = blackbox.history['val_R2'][-1]\n",
    "    \n",
    "#     with open(save_path, \"a+\") as fid:\n",
    "#         fid.write(f\"Final result: {objective}\\n\")\n",
    "#         fid.write(f\"This iteration took {time.time() - a} s\\n\")\n",
    "\n",
    "#     # Delete the Keras model with these hyper-parameters from memory.\n",
    "#     del model\n",
    "    \n",
    "#     # Garbage collection\n",
    "#     gc.collect()\n",
    "    \n",
    "#     # Clear the Keras session, otherwise it will keep adding new\n",
    "#     # models to the same TensorFlow graph each time we create\n",
    "#     # a model with a different set of hyper-parameters.\n",
    "#     K.clear_session()\n",
    "#     #tf.compat.v1.reset_default_graph()\n",
    "#     ops.reset_default_graph()\n",
    "    \n",
    "#     # The optimizer aims for the lowest score\n",
    "#     # For categorical problems, return the negative accuracy\n",
    "#     return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Multi-GPU multiprocessing potentially \n",
    "# # https://github.com/scikit-optimize/scikit-optimize/issues/737\n",
    "\n",
    "# gp_result = gp_minimize(\n",
    "#     func=fitness,\n",
    "#     dimensions=dimensions,\n",
    "#     n_calls=50,\n",
    "#     noise=0.01,\n",
    "#     n_jobs=-1,\n",
    "#     kappa = 5,\n",
    "#     x0=default_parameters\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
