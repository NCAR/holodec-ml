{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import accuracy_score as Accuracy\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch import nn\n",
    "\n",
    "from typing import List, Dict, Callable, Union, Any, TypeVar, Tuple\n",
    "from multiprocessing import cpu_count, Manager, Process, Pool\n",
    "from shutil import copyfile\n",
    "\n",
    "# custom\n",
    "from holodecml.vae.checkpointer import *\n",
    "from holodecml.vae.data_loader import *\n",
    "from holodecml.vae.optimizers import *\n",
    "from holodecml.vae.transforms import *\n",
    "from holodecml.vae.spectral import *\n",
    "\n",
    "from holodecml.vae.trainers import *\n",
    "from holodecml.vae.models import *\n",
    "from holodecml.vae.visual import *\n",
    "from holodecml.vae.losses import *\n",
    "\n",
    "from aimlutils.gpu import gpu_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 24860)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(gpu_report().items(), key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\") as config_file:\n",
    "    config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "\n",
    "data_save = config[\"log\"]\n",
    "model_type = config[\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(levelname)s:%(name)s:%(message)s')\n",
    "\n",
    "# Stream output to stdout\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(formatter)\n",
    "root.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Preparing to use device cuda:0\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")\n",
    "    \n",
    "logging.info(f'Preparing to use device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.vae.transforms:Loaded Rescale transformation with output size 600\n",
      "INFO:holodecml.vae.transforms:Loaded Normalize transformation that normalizes data in the range 0 to 1\n",
      "INFO:holodecml.vae.transforms:Loaded ToTensor transformation, putting tensors on device cuda:0\n"
     ]
    }
   ],
   "source": [
    "transform = LoadTransformations(config[\"transforms\"], device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.vae.data_loader:Loading reader-type encoder-vae\n",
      "INFO:holodecml.vae.data_loader:Loaded train hologram data containing 5000 images\n",
      "INFO:holodecml.vae.data_loader:Loading reader-type encoder-vae\n",
      "INFO:holodecml.vae.data_loader:Loaded test hologram data containing 1000 images\n"
     ]
    }
   ],
   "source": [
    "train_gen = LoadReader(\n",
    "    reader_type = model_type, \n",
    "    split = \"train\", \n",
    "    transform = transform,\n",
    "    scaler = None,\n",
    "    config = config[\"data\"]\n",
    ")\n",
    "\n",
    "valid_gen = LoadReader(\n",
    "    reader_type = model_type, \n",
    "    split = \"test\", \n",
    "    transform = transform, \n",
    "    scaler = train_gen.get_transform(),\n",
    "    config = config[\"data\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.info(f\"Loading training data iterator using {config['iterator']['num_workers']} workers\")\n",
    "\n",
    "# dataloader = DataLoader(\n",
    "#     train_gen,\n",
    "#     **config[\"iterator\"]\n",
    "# )\n",
    "\n",
    "# valid_dataloader = DataLoader(\n",
    "#     valid_gen,\n",
    "#     **config[\"iterator\"]\n",
    "# ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsynchronousDataLoader:\n",
    "    \n",
    "    def __init__(self, DataReader, Queue, workers = 1, epochs = 100, batch_size = 32, max_queue_size = 32, shuffle = True):\n",
    "        self.DataReader = DataReader\n",
    "        self.q = Queue\n",
    "        self.workers = workers\n",
    "        self.batch_size = batch_size\n",
    "        self.max_queue_size = max_queue_size\n",
    "        self.total_items = list(range(self.DataReader.__len__()))\n",
    "        self.epochs = epochs\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.total_items)\n",
    "            \n",
    "    def local(self, batch):\n",
    "        return [self.DataReader.__getitem__(item) for item in batch]\n",
    "        \n",
    "    def __call__(self):  \n",
    "        for epoch in range(self.epochs):\n",
    "            x_batch = []\n",
    "            y_batch = defaultdict(list)\n",
    "            w_batch = []\n",
    "            with Pool(self.workers) as p:\n",
    "                batches = len(self.total_items) / 100\n",
    "                chunked = np.array_split(self.total_items, batches)\n",
    "                for chunk in p.imap(self.local, chunked):\n",
    "                    for (x, y, w) in chunk:\n",
    "                        x_batch.append(x)\n",
    "                        for key, value in y.items():\n",
    "                            y_batch[key].append(torch.from_numpy(value))\n",
    "                        w_batch.append(torch.from_numpy(w))\n",
    "                        if len(x_batch) == self.batch_size:\n",
    "                            x_batch = torch.stack(x_batch, 0)\n",
    "                            w_batch = torch.stack(w_batch, 0)\n",
    "                            for key in y_batch:\n",
    "                                y_batch[key] = torch.stack(y_batch[key], 0)\n",
    "                            while (self.q.qsize() >= self.max_queue_size):\n",
    "                                time.sleep(0.1)\n",
    "                            self.q.put((x_batch, y_batch, w_batch))\n",
    "                            x_batch = []\n",
    "                            y_batch = defaultdict(list)\n",
    "                            w_batch = []\n",
    "                if len(x_batch) > 0:\n",
    "                    x_batch = torch.stack(x_batch, 0)\n",
    "                    w_batch = torch.stack(w_batch, 0)\n",
    "                    for key in y_batch:\n",
    "                        y_batch[key] = torch.stack(y_batch[key], 0)\n",
    "                    self.q.put((x_batch, y_batch, w_batch))\n",
    "                \n",
    "                # Send message to Reciever so it knows to die.\n",
    "                self.q.put('stop')\n",
    "            \n",
    "            if self.shuffle:\n",
    "                random.shuffle(self.total_items)\n",
    "            \n",
    "class AsynchronousDataReciever:\n",
    "    \n",
    "    def __init__(self, Queue, batch_size):\n",
    "        self.q = Queue\n",
    "        self.wait = True\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self): \n",
    "        while self.q.empty():\n",
    "            time.sleep(0.1)\n",
    "        result = self.q.get()\n",
    "        if result == 'stop':\n",
    "            raise StopIteration\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queue = Manager().Queue()\n",
    "valid_queue = Manager().Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataload = AsynchronousDataLoader(train_gen, train_queue, \n",
    "                                        workers = 16, batch_size = 32, max_queue_size = 128)\n",
    "p1 = Process(target=train_dataload)\n",
    "p1.start()\n",
    "dataloader = AsynchronousDataReciever(train_queue, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataload = AsynchronousDataLoader(valid_gen, valid_queue, \n",
    "                                        workers = 16, batch_size = 32, max_queue_size = 128)\n",
    "p2 = Process(target=valid_dataload)\n",
    "p2.start()\n",
    "valid_dataloader = AsynchronousDataReciever(valid_queue, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.vae.models:Loading model-type encoder-vae\n",
      "INFO:holodecml.vae.models:Loaded a self-attentive encoder-decoder VAE model\n",
      "INFO:root:Loaded VAE weights pretrained/pretrained.pt and froze these parameters\n",
      "INFO:holodecml.vae.models:The model contains 6890500 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = LoadModel(model_type, config[\"model\"], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.vae.optimizers:Loaded the lookahead-diffgrad optimizer with learning rate 0.000631 and L2 penalty 0.0\n"
     ]
    }
   ],
   "source": [
    "retrain = config[\"trainer\"][\"start_epoch\"] > 0\n",
    "\n",
    "optimizer_config = config[\"optimizer\"]\n",
    "learning_rate = optimizer_config[\"lr\"] #if not retrain else model_dict[\"lr\"]\n",
    "optimizer_type = optimizer_config[\"type\"]\n",
    "\n",
    "optimizer = LoadOptimizer(optimizer_type, model.parameters(), learning_rate)\n",
    "\n",
    "#if retrain:\n",
    "#   optimizer.load_state_dict(model_dict[\"optimizer_state_dict\"])\n",
    "#   logging.info(f\"Loaded optimizer weights from {model_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.vae.trainers:Loading trainer-type encoder-vae\n",
      "INFO:holodecml.vae.trainers:Clipping gradients to range [-1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "trainer = LoadTrainer(\n",
    "    model_type, \n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    train_gen = train_gen,\n",
    "    valid_gen = valid_gen,\n",
    "    dataloader = dataloader,\n",
    "    valid_dataloader = valid_dataloader,\n",
    "    device = device,\n",
    "    config = config[\"trainer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded ExponentialLR learning rate annealer with reduce factor 0.95\n",
      "INFO:holodecml.vae.checkpointer:Loaded EarlyStopping checkpointer with patience 5\n",
      "INFO:holodecml.vae.checkpointer:Loaded a metrics logger test/training_log.csv to track the training results\n"
     ]
    }
   ],
   "source": [
    "# Initialize LR annealing scheduler \n",
    "if \"ReduceLROnPlateau\" in config[\"callbacks\"]:\n",
    "    schedule_config = config[\"callbacks\"][\"ReduceLROnPlateau\"]\n",
    "    scheduler = ReduceLROnPlateau(trainer.optimizer, **schedule_config)\n",
    "    logging.info(\n",
    "        f\"Loaded ReduceLROnPlateau learning rate annealer with patience {schedule_config['patience']}\"\n",
    "    )\n",
    "elif \"ExponentialLR\" in config[\"callbacks\"]:\n",
    "    schedule_config = config[\"callbacks\"][\"ExponentialLR\"]\n",
    "    scheduler = ExponentialLR(trainer.optimizer, **schedule_config)\n",
    "    logging.info(\n",
    "        f\"Loaded ExponentialLR learning rate annealer with reduce factor {schedule_config['gamma']}\"\n",
    "    )\n",
    "\n",
    "# Early stopping\n",
    "checkpoint_config = config[\"callbacks\"][\"EarlyStopping\"]\n",
    "early_stopping = EarlyStopping(**checkpoint_config)\n",
    "\n",
    "# Write metrics to csv each epoch\n",
    "metrics_logger = MetricsLogger(**config[\"callbacks\"][\"MetricsLogger\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.vae.trainers:Training the model for up to 100 epochs starting at epoch 0\n",
      "Epoch: 0 loss: 0.191 mse: 0.194 bce: 0.163 acc: 0.846: 100%|██████████| 157/157 [01:10<00:00,  2.21it/s]\n",
      "Epoch: 0 val_loss: 0.547 val_mse: 0.273 val_bce: 0.274 val_acc: 0.858: 100%|██████████| 32/32 [00:04<00:00,  7.59it/s]\n",
      "INFO:holodecml.vae.checkpointer:Validation loss decreased on epoch 0 (inf --> -0.857607).  Saving model.\n",
      "Epoch: 1 loss: 0.174 mse: 0.179 bce: 0.130 acc: 0.862: 100%|██████████| 157/157 [01:14<00:00,  2.11it/s]\n",
      "Epoch: 1 val_loss: 0.561 val_mse: 0.274 val_bce: 0.287 val_acc: 0.854: 100%|██████████| 32/32 [00:04<00:00,  7.10it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 1 out of 5\n",
      "Epoch: 2 loss: 0.168 mse: 0.172 bce: 0.124 acc: 0.868: 100%|██████████| 157/157 [01:13<00:00,  2.13it/s]\n",
      "Epoch: 2 val_loss: 0.545 val_mse: 0.272 val_bce: 0.273 val_acc: 0.864: 100%|██████████| 32/32 [00:03<00:00,  8.27it/s]\n",
      "INFO:holodecml.vae.checkpointer:Validation loss decreased on epoch 2 (-0.857607 --> -0.863779).  Saving model.\n",
      "Epoch: 3 loss: 0.163 mse: 0.168 bce: 0.119 acc: 0.875: 100%|██████████| 157/157 [01:13<00:00,  2.14it/s]\n",
      "Epoch: 3 val_loss: 0.535 val_mse: 0.274 val_bce: 0.261 val_acc: 0.870: 100%|██████████| 32/32 [00:04<00:00,  7.12it/s]\n",
      "INFO:holodecml.vae.checkpointer:Validation loss decreased on epoch 3 (-0.863779 --> -0.869805).  Saving model.\n",
      "Epoch: 4 loss: 0.159 mse: 0.163 bce: 0.114 acc: 0.882: 100%|██████████| 157/157 [01:11<00:00,  2.21it/s]\n",
      "Epoch: 4 val_loss: 0.549 val_mse: 0.275 val_bce: 0.275 val_acc: 0.863: 100%|██████████| 32/32 [00:04<00:00,  7.51it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 1 out of 5\n",
      "Epoch: 5 loss: 0.154 mse: 0.158 bce: 0.107 acc: 0.889: 100%|██████████| 157/157 [01:13<00:00,  2.12it/s]\n",
      "Epoch: 5 val_loss: 0.563 val_mse: 0.278 val_bce: 0.285 val_acc: 0.859: 100%|██████████| 32/32 [00:03<00:00,  8.68it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 2 out of 5\n",
      "Epoch: 6 loss: 0.149 mse: 0.154 bce: 0.100 acc: 0.897: 100%|██████████| 157/157 [01:15<00:00,  2.08it/s]\n",
      "Epoch: 6 val_loss: 0.561 val_mse: 0.279 val_bce: 0.282 val_acc: 0.863: 100%|██████████| 32/32 [00:04<00:00,  7.44it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 3 out of 5\n",
      "Epoch: 7 loss: 0.145 mse: 0.150 bce: 0.093 acc: 0.907: 100%|██████████| 157/157 [01:17<00:00,  2.02it/s]\n",
      "Epoch: 7 val_loss: 0.554 val_mse: 0.279 val_bce: 0.276 val_acc: 0.867: 100%|██████████| 32/32 [00:04<00:00,  7.88it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 4 out of 5\n",
      "Epoch: 8 loss: 0.141 mse: 0.146 bce: 0.086 acc: 0.915: 100%|██████████| 157/157 [01:15<00:00,  2.08it/s]\n",
      "Epoch: 8 val_loss: 0.557 val_mse: 0.281 val_bce: 0.276 val_acc: 0.866: 100%|██████████| 32/32 [00:03<00:00,  8.36it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 5 out of 5\n",
      "INFO:holodecml.vae.trainers:Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 8,\n",
       " 'train_loss': 0.14090711884437854,\n",
       " 'train_mse': 0.14639340872597542,\n",
       " 'train_bce': 0.0860442709486196,\n",
       " 'valid_loss': 0.5567045044153929,\n",
       " 'valid_mse': 0.2807715078815818,\n",
       " 'valid_bce': 0.27593300212174654,\n",
       " 'lr': 0.00041861829214339834,\n",
       " 'train_acc': 0.9149840550058207,\n",
       " 'valid_acc': 0.8661230225116014}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(scheduler, early_stopping, metrics_logger, metric = \"val_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
