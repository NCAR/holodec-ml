{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import yaml\n",
    "import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import logging\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from holodecml.torch.losses import *\n",
    "from holodecml.torch.models import *\n",
    "from holodecml.torch.trainers import *\n",
    "from holodecml.torch.transforms import *\n",
    "from holodecml.torch.optimizers import *\n",
    "from holodecml.torch.data_loader import *\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(levelname)s:%(name)s:%(message)s')\n",
    "\n",
    "# Stream output to stdout\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(formatter)\n",
    "root.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.yml\") as config_file:\n",
    "    conf = yaml.load(config_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the device: CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(torch.cuda.current_device()) if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.torch.transforms:Loaded RandomVerticalFlip transformation with probability 0.5\n",
      "INFO:holodecml.torch.transforms:Loaded RandomHorizontalFlip transformation with probability 0.5\n",
      "INFO:holodecml.torch.transforms:Loaded Normalize transformation that scales pixel values between 0 to 1\n",
      "INFO:holodecml.torch.transforms:Loaded ToTensor transformation, putting tensors on device cpu\n",
      "INFO:holodecml.torch.transforms:Loaded Normalize transformation that scales pixel values between 0 to 1\n",
      "INFO:holodecml.torch.transforms:Loaded ToTensor transformation, putting tensors on device cpu\n"
     ]
    }
   ],
   "source": [
    "train_transform = LoadTransformations(conf[\"train_transforms\"], device = device)\n",
    "valid_transform = LoadTransformations(conf[\"test_transforms\"], device = device)\n",
    "\n",
    "scaler_path = os.path.join(conf[\"trainer\"][\"path_save\"], \"scalers.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.torch.data_loader:Loading reader-type multi\n",
      "INFO:holodecml.torch.data_loader:Loaded {'/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_1particle_gamma_600x400_training.nc': 10000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_2particle_gamma_600x400_training.nc': 10000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_3particle_gamma_600x400_training.nc': 10000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_4particle_gamma_600x400_training.nc': 10000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_5particle_gamma_600x400_training.nc': 10000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_6particle_gamma_600x400_training.nc': 10000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_7particle_gamma_600x400_training.nc': 10000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_8particle_gamma_600x400_training.nc': 10000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_9particle_gamma_600x400_training.nc': 10000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_10particle_gamma_600x400_training.nc': 10000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_12-25particle_gamma_600x400_training.nc': 80000} hologram data containing 180000 images\n",
      "INFO:holodecml.torch.data_loader:Loading reader-type multi\n",
      "INFO:holodecml.torch.data_loader:Loaded {'/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_1particle_gamma_600x400_test.nc': 1000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_2particle_gamma_600x400_test.nc': 1000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_3particle_gamma_600x400_test.nc': 1000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_4particle_gamma_600x400_test.nc': 1000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_5particle_gamma_600x400_test.nc': 1000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_6particle_gamma_600x400_test.nc': 1000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_7particle_gamma_600x400_test.nc': 1000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_8particle_gamma_600x400_test.nc': 1000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_9particle_gamma_600x400_test.nc': 1000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_10particle_gamma_600x400_test.nc': 1000, '/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_12-25particle_gamma_600x400_test.nc': 8000} hologram data containing 18000 images\n"
     ]
    }
   ],
   "source": [
    "train_gen = LoadReader(\n",
    "    transform = train_transform,\n",
    "    scaler = joblib.load(scaler_path) if os.path.isfile(scaler_path) else True,\n",
    "    config = conf[\"train_data\"]\n",
    ")\n",
    "\n",
    "if not os.path.isfile(scaler_path):\n",
    "    joblib.dump(train_gen.scaler, scaler_path)\n",
    "\n",
    "test_gen = LoadReader(\n",
    "    transform = valid_transform, \n",
    "    scaler = joblib.load(scaler_path),\n",
    "    config = conf[\"test_data\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data iterators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf[\"test_iterator\"][\"batch_size\"] = 1\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_gen,\n",
    "    **conf[\"test_iterator\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf[\"model\"][\"weights\"] = \"/glade/work/schreck/repos/holodec-ml/scripts/schreck/vae/results/double_channel_0203/best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.torch.models:Loading model-type att-vae with settings\n",
      "INFO:holodecml.torch.models:image_channels: 1\n",
      "INFO:holodecml.torch.models:out_image_channels: 2\n",
      "INFO:holodecml.torch.models:hidden_dims: [114, 59, 34, 627, 544, 2000]\n",
      "INFO:holodecml.torch.models:z_dim: 1014\n",
      "INFO:holodecml.torch.models:weights: /glade/work/schreck/repos/holodec-ml/scripts/schreck/vae/results/double_channel_0203/best.pt\n",
      "INFO:holodecml.torch.models.cnn:Loaded a self-attentive encoder-decoder VAE model\n",
      "INFO:holodecml.torch.models.cnn:The model contains 198732538 trainable parameters\n",
      "INFO:holodecml.torch.models.cnn:Loading weights from /glade/work/schreck/repos/holodec-ml/scripts/schreck/vae/results/double_channel_0203/best.pt\n"
     ]
    }
   ],
   "source": [
    "model = LoadModel(conf[\"model\"])\n",
    "model.build()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a generator so we can predict and draw a hologram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_generator(model):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        batch_size = test_dataloader.batch_size\n",
    "        batches_per_epoch = int(np.ceil(test_gen.__len__() / batch_size))\n",
    "\n",
    "        criterion = WeightedCrossEntropyLoss()\n",
    "\n",
    "        epoch_losses = {\"mse\": [], \"bce\": [], \"frac\": [], \n",
    "                        \"accuracy\": [], \"stop_accuracy\": [], \"seq_acc\": []}\n",
    "\n",
    "        for idx, images in enumerate(test_dataloader):\n",
    "            images = images.to(device)\n",
    "            with torch.no_grad():\n",
    "                # Predict the latent vector and image reconstruction\n",
    "                z, mu, logvar, encoder_att = model.encode(images)\n",
    "                image_pred, decoder_att = model.decode(z)\n",
    "                \n",
    "                combined_att = torch.cat([\n",
    "                    encoder_att[2].flatten(start_dim = 1),\n",
    "                    decoder_att[0].flatten(start_dim = 1)\n",
    "                ], 1)\n",
    "                combined_att = combined_att.clone()\n",
    "\n",
    "                encoder_att = [x.detach().cpu().numpy() for x in encoder_att]\n",
    "                decoder_att = [x.detach().cpu().numpy() for x in decoder_att]\n",
    "                \n",
    "                if model.out_image_channels > 1:\n",
    "                    z_real = np.sqrt(0.5) * image_pred[:,0,:,:]\n",
    "                    z_imag = image_pred[:,1,:,:]\n",
    "                    image_pred = torch.square(z_real) + torch.square(z_imag)\n",
    "                    image_pred = torch.unsqueeze(image_pred, 1)\n",
    "                \n",
    "            images = torch.transpose(images.squeeze(0).squeeze(0), 1, 0).cpu().numpy()\n",
    "            image_pred = torch.transpose(image_pred.squeeze(0).squeeze(0), 1, 0).cpu().numpy()\n",
    "            \n",
    "            yield (images, image_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = predict_generator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16\n",
    "\n",
    "x, y = next(data_gen)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax1.imshow(x)\n",
    "ax2.imshow(y)\n",
    "\n",
    "ax1.set_xlabel(\"horizontal particle position (µm)\", fontsize=fs)\n",
    "ax2.set_xlabel(\"horizontal particle position (µm)\", fontsize=fs)\n",
    "ax1.set_ylabel(\"vertical particle position (µm)\", fontsize=fs)\n",
    "\n",
    "ax1.set_title(\"Real image\", fontsize=fs)\n",
    "ax2.set_title(\"Predicted image\", fontsize=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
