{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch import nn\n",
    "\n",
    "from typing import List, Dict, Callable, Union, Any, TypeVar, Tuple\n",
    "from multiprocessing import cpu_count\n",
    "from shutil import copyfile\n",
    "\n",
    "# custom\n",
    "from holodecml.vae.checkpointer import *\n",
    "from holodecml.vae.data_loader import *\n",
    "from holodecml.vae.optimizers import *\n",
    "from holodecml.vae.transforms import *\n",
    "from holodecml.vae.spectral import *\n",
    "from holodecml.vae.trainers import *\n",
    "from holodecml.vae.models import *\n",
    "from holodecml.vae.visual import *\n",
    "from holodecml.vae.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/glade/work/schreck/repos/holodec-ml/scripts/schreck/vae/results/50_100/attention/config.yml\") as config_file:\n",
    "    config = yaml.load(config_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(levelname)s:%(name)s:%(message)s')\n",
    "\n",
    "# Stream output to stdout\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(formatter)\n",
    "root.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Preparing to use device cuda:0\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")\n",
    "    \n",
    "logging.info(f'Preparing to use device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.vae.transforms:Loaded RandomVerticalFlip transformation with probability 0.5\n",
      "INFO:holodecml.vae.transforms:Loaded RandomHorizontalFlip transformation with probability 0.5\n",
      "INFO:holodecml.vae.transforms:Loaded Rescale transformation with output size 600\n",
      "INFO:holodecml.vae.transforms:Loaded Normalize transformation that normalizes data in the range 0 to 1\n",
      "INFO:holodecml.vae.transforms:Loaded ToTensor transformation, putting tensors on device cuda:0\n"
     ]
    }
   ],
   "source": [
    "tforms = []\n",
    "transform_config = config[\"transforms\"]\n",
    "\n",
    "if \"RandomVerticalFlip\" in transform_config:\n",
    "    tforms.append(RandVerticalFlip(0.5))\n",
    "if \"RandomHorizontalFlip\" in transform_config:\n",
    "    tforms.append(RandHorizontalFlip(0.5))\n",
    "if \"Rescale\" in transform_config:\n",
    "    rescale = transform_config[\"Rescale\"]\n",
    "    tforms.append(Rescale(rescale))\n",
    "if \"Normalize\" in transform_config:\n",
    "    mode = transform_config[\"Normalize\"]\n",
    "    tforms.append(Normalize(mode))\n",
    "if \"ToTensor\" in transform_config:\n",
    "    tforms.append(ToTensor(device))\n",
    "if \"RandomCrop\" in transform_config:\n",
    "    tforms.append(RandomCrop())\n",
    "if \"Standardize\" in transform_config:\n",
    "    tforms.append(Standardize())\n",
    "\n",
    "transform = transforms.Compose(tforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.vae.data_loader:Loaded train hologram data containing 5000 images\n",
      "INFO:holodecml.vae.data_loader:Loaded test hologram data containing 1000 images\n"
     ]
    }
   ],
   "source": [
    "train_gen = HologramDataset(\n",
    "    split = \"train\", \n",
    "    transform = transform,\n",
    "    **config[\"data\"]\n",
    ")\n",
    "\n",
    "train_scalers = train_gen.get_transform()\n",
    "\n",
    "valid_gen = HologramDataset(\n",
    "    split = \"test\",\n",
    "    transform = transform,\n",
    "    **config[\"data\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading training data iterator using 8 workers\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"Loading training data iterator using {config['iterator']['num_workers']} workers\")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    train_gen,\n",
    "    **config[\"iterator\"]\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_gen,\n",
    "    **config[\"iterator\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attention(nn.Module):\n",
    "    \n",
    "    \"\"\" Self attention Layer\n",
    "        Based on https://github.com/heykeetae/Self-Attention-GAN/blob/master/sagan_models.py\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_dim):\n",
    "        \n",
    "        super(Self_Attention, self).__init__()\n",
    "        \n",
    "        self.chanel_in = in_dim\n",
    "        \n",
    "        self.query_conv = nn.Conv2d(in_channels = in_dim, out_channels = in_dim, kernel_size = 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels = in_dim, out_channels = in_dim, kernel_size = 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels = in_dim, out_channels = in_dim, kernel_size = 1)\n",
    "        \n",
    "        self.query_conv = SpectralNorm(self.query_conv)\n",
    "        self.key_conv = SpectralNorm(self.key_conv)\n",
    "        self.value_conv = SpectralNorm(self.value_conv)\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1) #\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \"\"\"\n",
    "            inputs :\n",
    "                x : input feature maps(B X C X W X H)\n",
    "            returns :\n",
    "                out : self attention value + input feature \n",
    "                attention: B X N X N (N is Width*Height)\n",
    "        \"\"\"\n",
    "        \n",
    "        B, C, width, height = x.size()\n",
    "        proj_query = self.query_conv(x).view(B, -1, width*height).permute(0,2,1) # B X CX(N)\n",
    "        proj_key = self.key_conv(x).view(B, -1, width*height) # B X C x (*W*H)\n",
    "        energy = torch.bmm(proj_query, proj_key) # transpose check\n",
    "        attention = self.softmax(energy) # BX (N) X (N) \n",
    "        proj_value = self.value_conv(x).view(B, -1, width*height) # B X C X N\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0,2,1))\n",
    "        out = out.view(B, C, width, height)\n",
    "        out = self.gamma * out + x\n",
    "        \n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATTENTION_VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 image_channels=1,\n",
    "                 hidden_dims=[8, 16, 32, 64, 128, 256],\n",
    "                 z_dim=10):\n",
    "        \n",
    "        super(ATTENTION_VAE, self).__init__()\n",
    "        \n",
    "        self.image_channels = image_channels\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.encoder_block1 = self.encoder_block(self.image_channels, self.hidden_dims[0], 4, 2, 1)\n",
    "        self.encoder_atten1 = Self_Attention(self.hidden_dims[0])\n",
    "        self.encoder_block2 = self.encoder_block(self.hidden_dims[0], self.hidden_dims[1], 4, 2, 1)\n",
    "        self.encoder_atten2 = Self_Attention(self.hidden_dims[1])\n",
    "        self.encoder_block3 = self.encoder_block(self.hidden_dims[1], self.hidden_dims[2], 4, 2, 1)\n",
    "        self.encoder_atten3 = Self_Attention(self.hidden_dims[2])\n",
    "        self.encoder_block4 = self.encoder_block(self.hidden_dims[2], self.hidden_dims[3], (3,2), (3,2), 0)\n",
    "        self.encoder_atten4 = Self_Attention(self.hidden_dims[3])\n",
    "        self.encoder_block5 = self.encoder_block(self.hidden_dims[3], self.hidden_dims[4], 5, 5, 0)\n",
    "        self.encoder_atten5 = Self_Attention(self.hidden_dims[4])\n",
    "        self.encoder_block6 = self.encoder_block(self.hidden_dims[4], self.hidden_dims[5], 5, 5, 0)\n",
    "                \n",
    "        self.fc1 = nn.Linear(self.hidden_dims[-1], self.z_dim)\n",
    "        self.fc2 = nn.Linear(self.hidden_dims[-1], self.z_dim)\n",
    "        self.fc3 = nn.Linear(self.z_dim, self.hidden_dims[-1])\n",
    "        \n",
    "        self.decoder_block1 = self.decoder_block(self.hidden_dims[5], self.hidden_dims[4], 5, 5, 0)\n",
    "        self.decoder_atten1 = Self_Attention(self.hidden_dims[4])\n",
    "        self.decoder_block2 = self.decoder_block(self.hidden_dims[4], self.hidden_dims[3], 5, 5, 0)\n",
    "        self.decoder_atten2 = Self_Attention(self.hidden_dims[3])\n",
    "        self.decoder_block3 = self.decoder_block(self.hidden_dims[3], self.hidden_dims[2], (3,2), (3,2), 0)\n",
    "        self.decoder_atten3 = Self_Attention(self.hidden_dims[2])\n",
    "        self.decoder_block4 = self.decoder_block(self.hidden_dims[2], self.hidden_dims[1], 4, 2, 1)\n",
    "        self.decoder_atten4 = Self_Attention(self.hidden_dims[1])\n",
    "        self.decoder_block5 = self.decoder_block(self.hidden_dims[1], self.hidden_dims[0], 4, 2, 1)\n",
    "        self.decoder_atten5 = Self_Attention(self.hidden_dims[0])\n",
    "        self.decoder_block6 = self.decoder_block(self.hidden_dims[0], self.image_channels, 4, 2, 1)\n",
    "        \n",
    "        logger.info(\"Loaded a self-attentive encoder-decoder VAE model\")    \n",
    "    \n",
    "    def encoder_block(self, dim1, dim2, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            SpectralNorm(\n",
    "                nn.Conv2d(dim1, dim2, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "            ),\n",
    "            nn.BatchNorm2d(dim2),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "    def decoder_block(self, dim1, dim2, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            SpectralNorm(\n",
    "                nn.ConvTranspose2d(dim1, dim2, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "            ),\n",
    "            nn.BatchNorm2d(dim2),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        # return torch.normal(mu, std)                               \n",
    "        esp = torch.randn(*mu.size()).to(std.device)\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "\n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = self.encoder_block1(x)\n",
    "        #h, att_map1 = self.encoder_atten1(h)\n",
    "        h = self.encoder_block2(h)\n",
    "        #h, att_map2 = self.encoder_atten2(h)\n",
    "        h = self.encoder_block3(h)\n",
    "        h, att_map3 = self.encoder_atten3(h)\n",
    "        h = self.encoder_block4(h)\n",
    "        h, att_map4 = self.encoder_atten4(h)\n",
    "        h = self.encoder_block5(h)\n",
    "        h, att_map5 = self.encoder_atten5(h)\n",
    "        h = self.encoder_block6(h)\n",
    "        h = h.view(h.size(0), -1) # flatten\n",
    "        z, mu, logvar = self.bottleneck(h)\n",
    "        return z, mu, logvar#, att_map\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.fc3(z)\n",
    "        z = z.view(z.size(0), self.hidden_dims[-1], 1, 1) #flatten/reshape\n",
    "        z = self.decoder_block1(z)\n",
    "        z, att_map1 = self.decoder_atten1(z)\n",
    "        z = self.decoder_block2(z)\n",
    "        z, att_map2 = self.decoder_atten2(z)\n",
    "        z = self.decoder_block3(z)\n",
    "        z, att_map3 = self.decoder_atten3(z)\n",
    "        z = self.decoder_block4(z)\n",
    "        #z, att_map4 = self.decoder_atten4(z)\n",
    "        z = self.decoder_block5(z)\n",
    "        #z, att_map5 = self.decoder_atten5(z)\n",
    "        z = self.decoder_block6(z)\n",
    "        return z#, att_map\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar#, encoder_att_map, decoder_att_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.vae.losses:Loaded a self-attentive encoder-decoder VAE model\n",
      "INFO:root:The model contains 41987627 parameters\n"
     ]
    }
   ],
   "source": [
    "#vae = ConvVAE().to(device)\n",
    "vae = ATTENTION_VAE(**config[\"model\"]).to(device)\n",
    "    \n",
    "# Print the total number of model parameters\n",
    "logging.info(\n",
    "    f\"The model contains {count_parameters(vae)} parameters\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dict = torch.load(\"attention/best.pt\", map_location=lambda storage, loc: storage)\n",
    "# vae.load_state_dict(model_dict[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded the lookahead-diffgrad optimizer with learning rate 0.001\n"
     ]
    }
   ],
   "source": [
    "retrain = config[\"trainer\"][\"start_epoch\"] > 0\n",
    "\n",
    "optimizer_config = config[\"optimizer\"]\n",
    "learning_rate = optimizer_config[\"lr\"] if not retrain else model_dict[\"lr\"]\n",
    "optimizer_type = optimizer_config[\"type\"]\n",
    "\n",
    "if optimizer_type == \"lookahead-diffgrad\":\n",
    "    optimizer = LookaheadDiffGrad(vae.parameters(), lr=learning_rate)\n",
    "elif optimizer_type == \"diffgrad\":\n",
    "    optimizer = DiffGrad(vae.parameters(), lr=learning_rate)\n",
    "elif optimizer_type == \"lookahead-radam\":\n",
    "    optimizer = LookaheadRAdam(vae.parameters(), lr=learning_rate)\n",
    "elif optimizer_type == \"radam\":\n",
    "    optimizer = RAdam(vae.parameters(), lr=learning_rate)\n",
    "elif optimizer_type == \"adam\":\n",
    "    optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "elif optimizer_type == \"sgd\":\n",
    "    optimizer = torch.optim.SGD(vae.parameters(), lr=learning_rate)\n",
    "else:\n",
    "    logging.warning(\n",
    "        f\"Optimzer type {optimizer_type} is unknown. Exiting with error.\"\n",
    "    )\n",
    "    sys.exit(1)\n",
    "\n",
    "logging.info(\n",
    "    f\"Loaded the {optimizer_type} optimizer with learning rate {learning_rate}\"\n",
    ")\n",
    "\n",
    "if retrain:\n",
    "    optimizer.load_state_dict(model_dict[\"optimizer_state_dict\"])\n",
    "\n",
    "#logging.info(f\"Loaded optimizer weights from {model_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.vae.losses:Loaded Symmetric MSE loss ...\n",
      "INFO:holodecml.vae.losses:... with alpha = 1.0, gamma = 1.0, and kld_weight = 0.0064\n",
      "INFO:holodecml.vae.losses:Loaded Symmetric MSE loss ...\n",
      "INFO:holodecml.vae.losses:... with alpha = 1.0, gamma = 1.0, and kld_weight = 0.032\n",
      "INFO:holodecml.vae.trainers:Clipping gradients to range [-1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "trainer = BaseTrainer(\n",
    "    model = vae,\n",
    "    optimizer = optimizer,\n",
    "    train_gen = train_gen,\n",
    "    valid_gen = valid_gen, \n",
    "    dataloader = dataloader, \n",
    "    valid_dataloader = valid_dataloader,\n",
    "    device = device,\n",
    "    **config[\"trainer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded ExponentialLR learning rate annealer with reduce factor 0.95\n",
      "INFO:holodecml.vae.checkpointer:Loaded EarlyStopping checkpointer with patience 10000000\n",
      "INFO:holodecml.vae.checkpointer:Loaded a metrics logger /glade/work/schreck/repos/holodec-ml/scripts/schreck/vae/results/50_100/attention/training_log.csv to track the training results\n"
     ]
    }
   ],
   "source": [
    "# Initialize LR annealing scheduler \n",
    "if \"ReduceLROnPlateau\" in config[\"callbacks\"]:\n",
    "    schedule_config = config[\"callbacks\"][\"ReduceLROnPlateau\"]\n",
    "    scheduler = ReduceLROnPlateau(trainer.optimizer, **schedule_config)\n",
    "    logging.info(\n",
    "        f\"Loaded ReduceLROnPlateau learning rate annealer with patience {schedule_config['patience']}\"\n",
    "    )\n",
    "elif \"ExponentialLR\" in config[\"callbacks\"]:\n",
    "    schedule_config = config[\"callbacks\"][\"ExponentialLR\"]\n",
    "    scheduler = ExponentialLR(trainer.optimizer, **schedule_config)\n",
    "    logging.info(\n",
    "        f\"Loaded ExponentialLR learning rate annealer with reduce factor {schedule_config['gamma']}\"\n",
    "    )\n",
    "\n",
    "# Early stopping\n",
    "checkpoint_config = config[\"callbacks\"][\"EarlyStopping\"]\n",
    "early_stopping = EarlyStopping(**checkpoint_config)\n",
    "\n",
    "# Write metrics to csv each epoch\n",
    "metrics_logger = MetricsLogger(**config[\"callbacks\"][\"MetricsLogger\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:holodecml.vae.trainers:Training the model for up to 100 epochs starting at epoch 0\n",
      "loss: 525624.485 bce: 477338.731 kld: 7544649.418: 100%|██████████| 157/157 [01:12<00:00,  2.17it/s]\n",
      "val_loss: 302711.242 val_bce: 293364.262 val_kld: 292093.090: 100%|██████████| 32/32 [00:06<00:00,  4.91it/s]\n",
      "INFO:holodecml.vae.checkpointer:Validation loss decreased on epoch 0 (inf --> 302711.242310).  Saving model.\n",
      "loss: 343985.422 bce: 339558.788 kld: 691661.538: 100%|██████████| 157/157 [01:12<00:00,  2.17it/s]\n",
      "val_loss: 343817.781 val_bce: 321395.951 val_kld: 700682.086: 100%|██████████| 32/32 [00:06<00:00,  4.67it/s] \n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 1 out of 10000000\n",
      "loss: 275243.692 bce: 272796.998 kld: 382296.083: 100%|██████████| 157/157 [01:11<00:00,  2.18it/s]\n",
      "val_loss: 341882.345 val_bce: 335105.186 val_kld: 211786.183: 100%|██████████| 32/32 [00:06<00:00,  4.82it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 2 out of 10000000\n",
      "loss: 235419.699 bce: 234525.045 kld: 139789.638: 100%|██████████| 157/157 [01:11<00:00,  2.19it/s]\n",
      "val_loss: 292646.387 val_bce: 284834.089 val_kld: 244134.289: 100%|██████████| 32/32 [00:07<00:00,  4.48it/s]\n",
      "INFO:holodecml.vae.checkpointer:Validation loss decreased on epoch 3 (302711.242310 --> 292646.386719).  Saving model.\n",
      "loss: 207133.735 bce: 206639.032 kld: 77297.258: 100%|██████████| 157/157 [01:12<00:00,  2.17it/s]\n",
      "val_loss: 262330.813 val_bce: 258903.384 val_kld: 107107.182: 100%|██████████| 32/32 [00:07<00:00,  4.54it/s]\n",
      "INFO:holodecml.vae.checkpointer:Validation loss decreased on epoch 4 (292646.386719 --> 262330.813477).  Saving model.\n",
      "loss: 183478.953 bce: 183079.591 kld: 62400.396: 100%|██████████| 157/157 [01:12<00:00,  2.17it/s]\n",
      "val_loss: 165525.002 val_bce: 163986.123 val_kld: 48089.961: 100%|██████████| 32/32 [00:07<00:00,  4.52it/s]\n",
      "INFO:holodecml.vae.checkpointer:Validation loss decreased on epoch 5 (262330.813477 --> 165525.001953).  Saving model.\n",
      "loss: 167046.519 bce: 166714.737 kld: 51841.021: 100%|██████████| 157/157 [01:11<00:00,  2.19it/s]\n",
      "val_loss: 138992.466 val_bce: 137856.740 val_kld: 35491.432: 100%|██████████| 32/32 [00:07<00:00,  4.47it/s]\n",
      "INFO:holodecml.vae.checkpointer:Validation loss decreased on epoch 6 (165525.001953 --> 138992.465698).  Saving model.\n",
      "loss: 155637.671 bce: 155324.590 kld: 48918.728: 100%|██████████| 157/157 [01:12<00:00,  2.18it/s]\n",
      "val_loss: 151506.814 val_bce: 148383.719 val_kld: 97596.736: 100%|██████████| 32/32 [00:07<00:00,  4.44it/s] \n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 1 out of 10000000\n",
      "loss: 147362.846 bce: 147028.911 kld: 52177.251: 100%|██████████| 157/157 [01:12<00:00,  2.17it/s]\n",
      "val_loss: 158359.137 val_bce: 154351.660 val_kld: 125233.653: 100%|██████████| 32/32 [00:07<00:00,  4.57it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 2 out of 10000000\n",
      "loss: 139366.896 bce: 139064.568 kld: 47238.866: 100%|██████████| 157/157 [01:12<00:00,  2.17it/s]\n",
      "val_loss: 119947.880 val_bce: 118443.901 val_kld: 46999.335: 100%|██████████| 32/32 [00:07<00:00,  4.53it/s]\n",
      "INFO:holodecml.vae.checkpointer:Validation loss decreased on epoch 9 (138992.465698 --> 119947.880188).  Saving model.\n",
      "loss: 154085.263 bce: 153789.029 kld: 46286.462: 100%|██████████| 157/157 [01:12<00:00,  2.16it/s]\n",
      "val_loss: 157753.098 val_bce: 149901.683 val_kld: 245356.664: 100%|██████████| 32/32 [00:07<00:00,  4.32it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 1 out of 10000000\n",
      "loss: 131434.453 bce: 131194.223 kld: 37536.038: 100%|██████████| 157/157 [01:12<00:00,  2.18it/s]\n",
      "val_loss: 132080.879 val_bce: 129420.503 val_kld: 83136.740: 100%|██████████| 32/32 [00:07<00:00,  4.56it/s] \n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 2 out of 10000000\n",
      "loss: 130839.316 bce: 130663.608 kld: 27454.314: 100%|██████████| 157/157 [01:12<00:00,  2.17it/s]\n",
      "val_loss: 120402.124 val_bce: 119692.218 val_kld: 22184.591: 100%|██████████| 32/32 [00:06<00:00,  4.73it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 3 out of 10000000\n",
      "loss: 120951.649 bce: 120809.699 kld: 22179.710: 100%|██████████| 157/157 [01:12<00:00,  2.17it/s]\n",
      "val_loss: 121925.055 val_bce: 119728.285 val_kld: 68649.043: 100%|██████████| 32/32 [00:06<00:00,  4.82it/s] \n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 4 out of 10000000\n",
      "loss: 118303.262 bce: 118170.580 kld: 20731.536: 100%|██████████| 157/157 [01:12<00:00,  2.17it/s]\n",
      "val_loss: 154058.030 val_bce: 152373.019 val_kld: 52656.580: 100%|██████████| 32/32 [00:06<00:00,  4.64it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 5 out of 10000000\n",
      "loss: 114873.332 bce: 114774.999 kld: 15364.485: 100%|██████████| 157/157 [01:12<00:00,  2.18it/s]\n",
      "val_loss: 138014.446 val_bce: 136988.143 val_kld: 32071.961: 100%|██████████| 32/32 [00:07<00:00,  4.49it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 6 out of 10000000\n",
      "loss: 111694.796 bce: 111617.594 kld: 12062.731: 100%|██████████| 157/157 [01:12<00:00,  2.17it/s]\n",
      "val_loss: 102666.819 val_bce: 102205.280 val_kld: 14423.089: 100%|██████████| 32/32 [00:07<00:00,  4.49it/s]\n",
      "INFO:holodecml.vae.checkpointer:Validation loss decreased on epoch 16 (119947.880188 --> 102666.818726).  Saving model.\n",
      "loss: 109547.464 bce: 109470.527 kld: 12021.445: 100%|██████████| 157/157 [01:12<00:00,  2.18it/s]\n",
      "val_loss: 110082.912 val_bce: 109663.330 val_kld: 13111.942: 100%|██████████| 32/32 [00:06<00:00,  4.63it/s]\n",
      "INFO:holodecml.vae.checkpointer:EarlyStopping counter: 1 out of 10000000\n",
      "loss: 107601.345 bce: 107520.329 kld: 12658.863:  34%|███▍      | 53/157 [00:25<00:50,  2.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-452ddce0f414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/glade/work/schreck/py37/lib/python3.7/site-packages/holodecml-0.0.1-py3.7.egg/holodecml/vae/trainers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, scheduler, early_stopping, metrics_logger)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_kld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/schreck/py37/lib/python3.7/site-packages/holodecml-0.0.1-py3.7.egg/holodecml/vae/trainers.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mepoch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bce\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kld\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_group_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mrecon_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/schreck/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d04eb871a834>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;31m#, encoder_att_map, decoder_att_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d04eb871a834>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_block4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m#z, att_map4 = self.decoder_atten4(z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_block5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;31m#z, att_map5 = self.decoder_atten5(z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_block6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/schreck/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/schreck/py37/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/schreck/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/schreck/py37/lib/python3.7/site-packages/holodecml-0.0.1-py3.7.egg/holodecml/vae/spectral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_u_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/schreck/py37/lib/python3.7/site-packages/holodecml-0.0.1-py3.7.egg/holodecml/vae/spectral.py\u001b[0m in \u001b[0;36m_update_u_v\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(scheduler, early_stopping, metrics_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_video(f\"{path_save}\", \"generated_hologram.avi\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
