{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import copy\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "import logging\n",
    "import traceback\n",
    "import numpy as np\n",
    "\n",
    "from holodecml.torch.utils import *\n",
    "from holodecml.torch.losses import *\n",
    "from holodecml.torch.visual import *\n",
    "from holodecml.torch.models import *\n",
    "from holodecml.torch.trainers import *\n",
    "from holodecml.torch.transforms import *\n",
    "from holodecml.torch.optimizers import *\n",
    "from holodecml.torch.data_loader import *\n",
    "from holodecml.torch.beam_search import *\n",
    "\n",
    "from aimlutils.hyper_opt.base_objective import *\n",
    "from aimlutils.torch.checkpoint import *\n",
    "#from aimlutils.torch.losses import *\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Dict, Callable, Union, Any, TypeVar, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/test/model.yml\") as config_file:\n",
    "    conf = yaml.load(config_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf[\"validation_data\"][\"path_data\"] = ['/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_12-25particle_gamma_600x400_training.nc']\n",
    "# conf[\"validation_data\"][\"maxnum_particles\"] = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cpu\":\n",
    "    conf[\"train_iterator\"][\"pin_memory\"] = False\n",
    "    conf[\"valid_iterator\"][\"pin_memory\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image and data transformations\n",
    "train_transform = LoadTransformations(conf[\"train_transforms\"], device = device)\n",
    "valid_transform = LoadTransformations(conf[\"validation_transforms\"], device = device)\n",
    "\n",
    "scaler_path = os.path.join(conf[\"trainer\"][\"path_save\"], \"scalers.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data scaler transformation {'x': StandardScaler(copy=True, with_mean=True, with_std=True), 'y': StandardScaler(copy=True, with_mean=True, with_std=True), 'z': StandardScaler(copy=True, with_mean=True, with_std=True), 'd': StandardScaler(copy=True, with_mean=True, with_std=True)}\n",
      "Loaded data scaler transformation {'x': StandardScaler(copy=True, with_mean=True, with_std=True), 'y': StandardScaler(copy=True, with_mean=True, with_std=True), 'z': StandardScaler(copy=True, with_mean=True, with_std=True), 'd': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "# Load the readers\n",
    "\n",
    "train_gen = LoadReader(\n",
    "    transform = train_transform,\n",
    "    scaler = joblib.load(scaler_path) if os.path.isfile(scaler_path) else True,\n",
    "    config = conf[\"train_data\"]\n",
    ")\n",
    "\n",
    "if not os.path.isfile(scaler_path):\n",
    "    joblib.dump(train_gen.scaler, scaler_path)\n",
    "\n",
    "valid_gen = LoadReader(\n",
    "    transform = valid_transform, \n",
    "    scaler = train_gen.scaler,\n",
    "    config = conf[\"validation_data\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data iterators \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_gen,\n",
    "    **conf[\"train_iterator\"]\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_gen,\n",
    "    **conf[\"valid_iterator\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_conf = conf[\"vae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_conf = conf[\"decoder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_conf = conf[\"regressor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = LoadModel(vae_conf)\n",
    "vae.build()\n",
    "vae = vae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dict = torch.load(\n",
    "#     vae_model_weights,\n",
    "#     map_location=lambda storage, loc: storage\n",
    "# )\n",
    "# vae.load_state_dict(model_dict[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load RNN and regression models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    }
   ],
   "source": [
    "decoder_conf[\"output_size\"] = len(train_gen.token_lookup) + 3\n",
    "decoder = DecoderRNN(**decoder_conf).to(device)\n",
    "print(decoder_conf[\"output_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_model_weights = conf[\"callbacks\"][\"MetricsLogger\"][\"path_save\"] + \"/best_rnn.pt\"\n",
    "model_dict = torch.load(\n",
    "    decoder_model_weights,\n",
    "    map_location=lambda storage, loc: storage\n",
    ")\n",
    "decoder.load_state_dict(model_dict[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DenseNet2(**conf[\"regressor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.build(vae_conf[\"z_dim\"] + decoder_conf[\"hidden_size\"] + 1250)\n",
    "regressor = regressor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model_weights = conf[\"callbacks\"][\"MetricsLogger\"][\"path_save\"] + \"/best_linear.pt\"\n",
    "model_dict = torch.load(\n",
    "    linear_model_weights,\n",
    "    map_location=lambda storage, loc: storage\n",
    ")\n",
    "regressor.load_state_dict(model_dict[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the beam-search object\n",
    "\n",
    "beam_search = BeamSearch(\n",
    "    end_index = EOS_token, \n",
    "    max_steps = valid_gen.maxnum_particles, \n",
    "    beam_size = 10\n",
    ")\n",
    "_bleu = BLEU(exclude_indices={PAD_token, EOS_token, SOS_token})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(epoch = 0):\n",
    "    \n",
    "    vae.eval()\n",
    "    decoder.eval()\n",
    "    regressor.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        batch_size = conf[\"valid_iterator\"][\"batch_size\"]\n",
    "        batches_per_epoch = int(np.ceil(valid_gen.__len__() / batch_size))\n",
    "\n",
    "#         batch_group_generator = tqdm(\n",
    "#             enumerate(valid_dataloader), \n",
    "#             total=batches_per_epoch, \n",
    "#             leave=True\n",
    "#         )\n",
    "\n",
    "        epoch_losses = {\"mse\": [], \"cce\": [], \"accuracy\": [], \"stop_accuracy\": [], \"bleu\": []}\n",
    "        for idx, (images, y_out, w_out) in enumerate(valid_dataloader):\n",
    "            images = images.to(device)\n",
    "            y_out = {task: value.to(device) for task, value in y_out.items()}\n",
    "            w_out = w_out.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # 1. Predict the latent vector and image reconstruction\n",
    "                z, mu, logvar, encoder_att = vae.encode(images)\n",
    "                image_pred, decoder_att = vae.decode(z)\n",
    "                \n",
    "                combined_att = torch.cat([\n",
    "                    encoder_att[2].flatten(start_dim = 1),\n",
    "                    decoder_att[0].flatten(start_dim = 1)\n",
    "                ], 1)\n",
    "                combined_att = combined_att.clone()\n",
    "                \n",
    "                encoder_att = [x.detach().cpu().numpy() for x in encoder_att]\n",
    "                decoder_att = [x.detach().cpu().numpy() for x in decoder_att]\n",
    "\n",
    "                if vae.out_image_channels > 1:\n",
    "                    z_real = np.sqrt(0.5) * image_pred[:,0,:,:]\n",
    "                    z_imag = image_pred[:,1,:,:]\n",
    "                    image_pred = torch.square(z_real) + torch.square(z_imag)\n",
    "                    image_pred = torch.unsqueeze(image_pred, 1)\n",
    "\n",
    "            # 2. Predict the number of particles\n",
    "            decoder_input = torch.LongTensor([SOS_token] * w_out.shape[0]).to(device)\n",
    "            encoded_image = z.to(device)\n",
    "            decoder_hidden = encoded_image.clone().reshape((1, w_out.shape[0], z.size(-1)))\n",
    "            \n",
    "            n_dims = 2 if decoder.bidirectional else 1\n",
    "            n_dims *= decoder.n_layers\n",
    "            if n_dims > 1:\n",
    "                decoder_hidden = torch.cat([decoder_hidden for k in range(n_dims)])\n",
    "\n",
    "            target_tensor = w_out.long()\n",
    "            target_length = w_out.shape[1]\n",
    "            seq_lens = w_out.max(axis = 1)[0] + 1\n",
    "            class_weights = torch.ones(w_out.shape).to(device)\n",
    "\n",
    "            hidden_vectors = []\n",
    "            bleu, accuracy, stop_accuracy, rnn_loss = [], [], [], []\n",
    "\n",
    "            # Use beam search to get predictions\n",
    "            predictions, probabilities = beam_search.search(\n",
    "                decoder_input, decoder_hidden, decoder\n",
    "            )\n",
    "\n",
    "            # Validate on top-1 most likely sequence\n",
    "            top_preds = predictions[:, 0, :]\n",
    "\n",
    "            # Compute bleu metric for each sequence in the batch\n",
    "            for pred, true in zip(top_preds, target_tensor):\n",
    "                _bleu(pred.unsqueeze(0), true.unsqueeze(0))\n",
    "            epoch_losses[\"bleu\"].append(_bleu.get_metric(reset=False)[\"BLEU\"])\n",
    "\n",
    "            # Reshape the predicted tensor to match with the target_tensor\n",
    "            ## This will work only if limit the beam search = target size\n",
    "            B, T = target_tensor.size()\n",
    "            _, t = top_preds.size()\n",
    "            if t < T:\n",
    "                reshaped_preds = torch.zeros(B, T)\n",
    "                reshaped_preds[:, :t] = top_preds\n",
    "                reshaped_preds = reshaped_preds.long().to(device)\n",
    "            else:\n",
    "                reshaped_preds = top_preds\n",
    "\n",
    "            # Use greedy evaluation to get the loss\n",
    "            di = 0\n",
    "            while (di < 101):\n",
    "            #for di in range(target_length + 1):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, seq_lens)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                #if batch_size > 1:\n",
    "                #decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "                decoder_input = reshaped_preds[:, di].detach()\n",
    "                c1 = (reshaped_preds[:, di] != PAD_token)\n",
    "                c2 = (reshaped_preds[:, di] != EOS_token)\n",
    "                condition = c1 & c2\n",
    "                real_plus_stop = torch.where(c1)\n",
    "                real_particles = torch.where(condition)\n",
    "                stop_token = torch.where(~c2)\n",
    "\n",
    "                if real_plus_stop[0].size(0) == 0:\n",
    "                    break\n",
    "\n",
    "                rnn_loss.append(\n",
    "                    nn.NLLLoss()(\n",
    "                        decoder_output[real_plus_stop], \n",
    "                        target_tensor[:, di][real_plus_stop]\n",
    "                    )\n",
    "                )\n",
    "                accuracy += [\n",
    "                    int(i.item()==j.item())\n",
    "                    for i, j in zip(reshaped_preds[:, di][real_particles], \n",
    "                                    target_tensor[:, di][real_particles])\n",
    "                ]\n",
    "\n",
    "                if stop_token[0].size(0) > 0:\n",
    "                    stop_accuracy += [\n",
    "                        int(i.item()==j.item()) \n",
    "                        for i, j in zip(reshaped_preds[:, di][stop_token], \n",
    "                                        target_tensor[:, di][stop_token])\n",
    "                    ]\n",
    "\n",
    "                if real_particles[0].size(0) > 0:\n",
    "                    token_input = reshaped_preds[:, di] # topi.squeeze()\n",
    "                    embedding = decoder.embed(token_input).squeeze(0)\n",
    "                    hidden_vectors.append([real_particles, embedding])\n",
    "                    \n",
    "                di += 1\n",
    "                \n",
    "            accuracy = np.mean(accuracy)\n",
    "            epoch_losses[\"accuracy\"].append(accuracy)\n",
    "            epoch_losses[\"stop_accuracy\"].append(np.mean(stop_accuracy))\n",
    "\n",
    "            rnn_loss = torch.mean(torch.stack(rnn_loss))\n",
    "            epoch_losses[\"cce\"].append(rnn_loss.item())\n",
    "\n",
    "            if len(hidden_vectors) == 0:\n",
    "                continue\n",
    "\n",
    "            particle_results = {\"x\": [], \"y\": [], \"z\": [], \"d\": [], \"tokens\": []}\n",
    "            particle_true = {\"x\": [], \"y\": [], \"z\": [], \"d\": []}\n",
    "            \n",
    "            # 3. Use particle embeddings to predict (x,y,z,d)\n",
    "            real_parts = []\n",
    "            regressor_loss = []\n",
    "            for di in range(len(hidden_vectors)):\n",
    "                real_particles, h_vecs = hidden_vectors[di]\n",
    "                x_input = torch.cat([h_vecs.detach(), encoded_image, combined_att], axis = 1)\n",
    "                particle_attributes = regressor(x_input[real_particles])\n",
    "                loss = []\n",
    "                for task in [\"x\", \"y\", \"z\", \"d\"]:\n",
    "                    _loss = nn.L1Loss()(\n",
    "                        particle_attributes[task].squeeze(1), \n",
    "                        y_out[task][:, di][real_particles].float()\n",
    "                    )\n",
    "                    loss.append(_loss)\n",
    "                    particle_results[task].append(particle_attributes[task].cpu().numpy().squeeze(1))\n",
    "                    particle_true[task].append(y_out[task][:, di].float().cpu().numpy())\n",
    "                real_parts.append(real_particles[0].cpu().numpy()) \n",
    "                regressor_loss.append(torch.mean(torch.stack(loss)))\n",
    "                particle_results[\"tokens\"].append(real_particles)\n",
    "            regressor_loss = torch.mean(torch.stack(regressor_loss))\n",
    "            epoch_losses[\"mse\"].append(regressor_loss.item())\n",
    "    \n",
    "            result = {\n",
    "                    \"image_true\": images.cpu().numpy(),\n",
    "                    \"image_pred\": image_pred.cpu().numpy(),\n",
    "                    \"particle_true\": particle_true,\n",
    "                    \"particle_pred\": particle_results,\n",
    "                    \"accuracy\": accuracy,\n",
    "                    \"stop_accuracy\": np.mean(stop_accuracy),\n",
    "                    \"cce\": rnn_loss.item(),\n",
    "                    \"rmae\": regressor_loss.item(),\n",
    "                    \"real_particles\": real_parts,\n",
    "                    \"encoder_att\": encoder_att,\n",
    "                    \"decoder_att\": decoder_att\n",
    "                }\n",
    "            \n",
    "            yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(val_gen):\n",
    "    batch_size = conf[\"valid_iterator\"][\"batch_size\"]\n",
    "    batches_per_epoch = int(np.ceil(valid_gen.__len__() / batch_size))\n",
    "    batch_group_generator = tqdm(\n",
    "        enumerate(val_gen), \n",
    "        total=batches_per_epoch, \n",
    "        leave=True\n",
    "    )\n",
    "#     results = {\n",
    "#         \"accuracy\": [],\n",
    "#         \"stop_accuracy\": [],\n",
    "#         \"cce\": [],\n",
    "#         \"mae\": []\n",
    "#     }\n",
    "    results = defaultdict(list)\n",
    "    for result in batch_group_generator:\n",
    "        for key, val in result.items():\n",
    "            results[key].append(val)\n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hologram(inputs, outputs, particles, n = 0, scaler = None, true = True, vmin = None, vmax = None):\n",
    "    \"\"\"\n",
    "    Given a hologram number, plot hologram and particle point\n",
    "    \n",
    "    Args: \n",
    "        h: (int) hologram index\n",
    "        inputs: (pd df) input images\n",
    "        outputs: (pd df) output x, y, z, and d values by hid\n",
    "    \n",
    "    Returns:\n",
    "        print of pseudocolor plot of hologram and hologram particles\n",
    "    \"\"\"    \n",
    "    #outputs = {x: y[n] for x,y in outputs.items()}\n",
    "    \n",
    "    N = 0\n",
    "    for k in range(len(particles)):\n",
    "        real_particles = particles[k]\n",
    "        if n in real_particles:\n",
    "            N += 1\n",
    "    \n",
    "    preds = range(N)\n",
    "    \n",
    "    _outputs = {\"x\": np.zeros(N), \"y\": np.zeros(N), \"z\": np.zeros(N), \"d\": np.zeros(N)}\n",
    "    \n",
    "    for k in range(len(particles)):\n",
    "        real_particles = particles[k]\n",
    "        if n in real_particles:\n",
    "            listed = np.where(real_particles == n)[0]\n",
    "            K = listed[0] if not true else n\n",
    "            for task in _outputs:\n",
    "                _outputs[task][k] = outputs[task][k][K]\n",
    "    \n",
    "    outputs = _outputs\n",
    "\n",
    "    inputs = inputs[n].squeeze(0)\n",
    "\n",
    "    x_vals = np.linspace(-888, 888, inputs.shape[0])\n",
    "    y_vals = np.linspace(-592, 592, inputs.shape[1])\n",
    "\n",
    "    plt.figure(figsize=(12, 8))    \n",
    "    plt.pcolormesh(x_vals, y_vals, inputs.T, cmap=\"RdBu_r\")\n",
    "    \n",
    "    if isinstance(scaler, dict):\n",
    "        shape = outputs[\"x\"].shape[0]\n",
    "        outputs[\"x\"] = scaler[\"x\"].inverse_transform(outputs[\"x\"].reshape(-1, shape))[0]\n",
    "        outputs[\"y\"] = scaler[\"y\"].inverse_transform(outputs[\"y\"].reshape(-1, shape))[0]\n",
    "        outputs[\"z\"] = scaler[\"z\"].inverse_transform(outputs[\"z\"].reshape(-1, shape))[0]\n",
    "        outputs[\"d\"] = scaler[\"d\"].inverse_transform(outputs[\"d\"].reshape(-1, shape))[0]\n",
    "    \n",
    "    print(f\"The model predicts that there are {N} particles in the hologram\")\n",
    "    \n",
    "    if vmax is None:\n",
    "        vmax = outputs[\"z\"].max()\n",
    "    if vmin is None:\n",
    "        vmin = outputs[\"z\"].min()\n",
    "    \n",
    "    for h in preds: \n",
    "        plt.scatter(outputs[\"x\"][h],\n",
    "                    outputs[\"y\"][h],\n",
    "                    outputs[\"d\"][h] ** 2,\n",
    "                    outputs[\"z\"][h],\n",
    "                    vmin=vmin,\n",
    "                    vmax=vmax,\n",
    "                    cmap=\"cool\")\n",
    "        plt.annotate(f\"d: {(outputs['d'][h]):.1f} µm\",\n",
    "                     (outputs[\"x\"][h], outputs[\"y\"][h]))\n",
    "    \n",
    "    plt.xlabel(\"horizontal particle position (µm)\", fontsize=16)\n",
    "    if true:\n",
    "        plt.ylabel(\"vertical particle position (µm)\", fontsize=16)\n",
    "    if true:\n",
    "        plt.title(\"True\", fontsize=20, pad=20)\n",
    "    else:\n",
    "        plt.title(\"Predicted\", fontsize=20, pad=20)\n",
    "    plt.colorbar().set_label(label=\"z-axis particle position (µm)\", size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, coordinates):\n",
    "        x, y, z, d = coordinates\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.d = d\n",
    "        \n",
    "def distance(p1, p2):\n",
    "     return ((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_generator = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_result = next(results_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model returns batch results, so use N here to pick single examples\n",
    "\n",
    "def batch_plot(result, N):\n",
    "\n",
    "    ### Make the plot -- use the same z scale in both images\n",
    "    z_dist_true = [train_gen.scaler[\"z\"].inverse_transform([dd[N]])[0] for dd in result['particle_true'][\"z\"]]\n",
    "    z_dist_pred = [train_gen.scaler[\"z\"].inverse_transform([dd[N]])[0] for dd in result['particle_pred'][\"z\"]]\n",
    "\n",
    "    vmin = min(min(z_dist_true), min(z_dist_pred))\n",
    "    vmax = max(max(z_dist_true), max(z_dist_pred))\n",
    "\n",
    "    plot_hologram(result[\"image_true\"], result['particle_true'], result['real_particles'], \n",
    "                  n = N, scaler = train_gen.scaler, true = True, vmin = vmin, vmax = vmax)\n",
    "    plot_hologram(result[\"image_pred\"], result['particle_pred'], result['real_particles'], \n",
    "                  n = N, scaler = train_gen.scaler, true = False, vmin = vmin, vmax = vmax)\n",
    "\n",
    "    ### Sort the particles by distance to each other and compute the loss \n",
    "    pred_part = []\n",
    "    true_part = []\n",
    "    for particle in range(3):\n",
    "        cx1, cx2 = [], []\n",
    "        for task in [\"x\", \"y\", \"z\", \"d\"]:\n",
    "            x1 = train_gen.scaler[task].inverse_transform([result[\"particle_true\"][task][particle][N]])[0]\n",
    "            x2 = train_gen.scaler[task].inverse_transform([result[\"particle_pred\"][task][particle][N]])[0]\n",
    "            cx1.append(x1)\n",
    "            cx2.append(x2)\n",
    "        true_part.append(Point(cx1))\n",
    "        pred_part.append(Point(cx2))\n",
    "\n",
    "    tosort = []\n",
    "    for p1 in range(3):\n",
    "        for p2 in range(3):\n",
    "            tosort.append([distance(pred_part[p1], true_part[p2]), p1, p2])\n",
    "\n",
    "    paired = []\n",
    "    seen_true = []\n",
    "    seen_pred = []\n",
    "    for (a,b,c) in sorted(tosort): # sort by distance\n",
    "        if b not in seen_pred and c not in seen_true:\n",
    "            paired.append([c, b])\n",
    "            seen_true.append(c)\n",
    "            seen_pred.append(b)\n",
    "\n",
    "    this_error = defaultdict(list)\n",
    "    for (x,y) in paired:\n",
    "        xe = abs(true_part[x].x - pred_part[y].x)\n",
    "        ye = abs(true_part[x].y - pred_part[y].y)\n",
    "        ze = abs(true_part[x].z - pred_part[y].z)\n",
    "        de = abs(true_part[x].d - pred_part[y].d)\n",
    "\n",
    "        this_error[\"x\"].append(xe)\n",
    "        this_error[\"y\"].append(ye)\n",
    "        this_error[\"z\"].append(ze)\n",
    "        this_error[\"d\"].append(de)\n",
    "\n",
    "    for key, val in this_error.items():\n",
    "        print(key, np.mean(val))\n",
    "        \n",
    "    #paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-77fe3acdee21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-ceb0844c9815>\u001b[0m in \u001b[0;36mbatch_plot\u001b[0;34m(result, N)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     plot_hologram(result[\"image_true\"], result['particle_true'], result['real_particles'], \n\u001b[0;32m---> 13\u001b[0;31m                   n = N, scaler = train_gen.scaler, true = True, vmin = vmin, vmax = vmax)\n\u001b[0m\u001b[1;32m     14\u001b[0m     plot_hologram(result[\"image_pred\"], result['particle_pred'], result['real_particles'], \n\u001b[1;32m     15\u001b[0m                   n = N, scaler = train_gen.scaler, true = False, vmin = vmin, vmax = vmax)\n",
      "\u001b[0;32m<ipython-input-43-25109a6578e4>\u001b[0m in \u001b[0;36mplot_hologram\u001b[0;34m(inputs, outputs, particles, n, scaler, true, vmin, vmax)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "batch_plot(next_result, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute errors for the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2500 [00:21<1:40:18,  2.42s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 31 is out of bounds for axis 0 with size 31",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2e130057b11a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"z\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"d\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"particle_true\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparticle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"particle_pred\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparticle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mcx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mcx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 31 is out of bounds for axis 0 with size 31"
     ]
    }
   ],
   "source": [
    "batch_size = conf[\"valid_iterator\"][\"batch_size\"]\n",
    "batches_per_epoch = int(np.ceil(valid_gen.__len__() / batch_size))\n",
    "\n",
    "batch_group_generator = tqdm(\n",
    "    enumerate(predict()), \n",
    "    total=batches_per_epoch, \n",
    "    leave=True\n",
    ")\n",
    "\n",
    "errors = defaultdict(list)\n",
    "\n",
    "for m, result in batch_group_generator:\n",
    "    for N in range(len(result[\"particle_true\"][\"x\"][0])):\n",
    "        pred_part = []\n",
    "        true_part = []\n",
    "        for particle in range(3):\n",
    "            cx1, cx2 = [], []\n",
    "            for task in [\"x\", \"y\", \"z\", \"d\"]:\n",
    "                x1 = train_gen.scaler[task].inverse_transform([result[\"particle_true\"][task][particle][N]])[0]\n",
    "                x2 = train_gen.scaler[task].inverse_transform([result[\"particle_pred\"][task][particle][N]])[0]\n",
    "                cx1.append(x1)\n",
    "                cx2.append(x2)\n",
    "            true_part.append(Point(cx1))\n",
    "            pred_part.append(Point(cx2))\n",
    "\n",
    "        tosort = []\n",
    "        for p1 in range(3):\n",
    "            for p2 in range(3):\n",
    "                tosort.append([distance(pred_part[p1], true_part[p2]), p1, p2])\n",
    "\n",
    "        paired = []\n",
    "        seen_true = []\n",
    "        seen_pred = []\n",
    "        for (a,b,c) in sorted(tosort):\n",
    "            if b not in seen_pred and c not in seen_true:\n",
    "                paired.append([c, b])\n",
    "                seen_true.append(c)\n",
    "                seen_pred.append(b)\n",
    "\n",
    "        for (x,y) in paired:\n",
    "            xe = abs(true_part[x].x - pred_part[y].x)\n",
    "            ye = abs(true_part[x].y - pred_part[y].y)\n",
    "            ze = abs(true_part[x].z - pred_part[y].z)\n",
    "            de = abs(true_part[x].d - pred_part[y].d)\n",
    "\n",
    "            errors[\"x\"].append(xe)\n",
    "            errors[\"y\"].append(ye)\n",
    "            errors[\"z\"].append(ze)\n",
    "            errors[\"d\"].append(de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, values in errors.items():\n",
    "    print(task, np.mean(values), np.std(values) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(np.log(result['encoder_att'][0][0]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(result['decoder_att'][0][0].T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
