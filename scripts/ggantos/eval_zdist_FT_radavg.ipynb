{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, minmax_scale\n",
    "\n",
    "import holodecml.ml_utils as ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matt_train = \"/glade/scratch/mhayman/holodec/holodec-ml-data/histogram/histogram_training_data_5000count20200819T091551.nc\"\n",
    "matt_valid = \"/glade/scratch/mhayman/holodec/holodec-ml-data/histogram/histogram_validation_data_5000count20200819T091551.nc\"\n",
    "matt_test = \"/glade/scratch/mhayman/holodec/holodec-ml-data/histogram/histogram_test_data_5000count20200819T091551.nc\"\n",
    "\n",
    "\n",
    "path_data_z = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/ft_rad_bidis_z/\"\n",
    "path_data_z_realimag = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/ft_rad_bidis_z_realimag/\"\n",
    "\n",
    "batch_size = 256\n",
    "input_variable = \"input_image\"\n",
    "label_variable = \"histogram\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bins(var):\n",
    "    ds = xr.open_dataset('/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_50-100particle_bidisperse_training.nc')\n",
    "    if var == 'z':\n",
    "        delta = (round(ds[var].values.max()+1000) -\n",
    "                 round(ds[var].values.min()-1000))\n",
    "        step = int(delta / 20)\n",
    "        edges = np.arange(round(ds[var].values.min()-1000),\n",
    "                         round(ds[var].values.max()+1000),\n",
    "                         step)\n",
    "    else:\n",
    "        edges = np.arange(0,200,5)\n",
    "    centers = 0.5*np.diff(edges) \\\n",
    "                    + edges[:-1]\n",
    "    return centers\n",
    "\n",
    "def ranked_probability_score(y_true, y_pred):\n",
    "    return np.mean((np.cumsum(y_true, axis=1) - np.cumsum(y_pred, axis=1)) ** 2) / (y_true.shape[1] -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TRAINING dataset\n",
      "\ttrain_inputs_matt.shape:(5000, 600, 1)\n",
      "\ttrain_inputs_matt.shape:(5000, 600, 1)\n",
      "\ttrain_outputs_matt.shape:(5000, 19, 1)\n",
      "\ttrain_outputs_matt.shape:(5000, 19, 1)\n"
     ]
    }
   ],
   "source": [
    "with xr.open_dataset(matt_train, chunks={'hologram_number': batch_size}) as ds:\n",
    "    print(\"Loading TRAINING dataset\")\n",
    "\n",
    "    if len(ds[input_variable].dims) == 4:\n",
    "        train_inputs_matt = ds[input_variable].transpose('hologram_number','xsize','ysize','input_channels')\n",
    "    elif len(ds[input_variable].dims) == 3:\n",
    "        train_inputs_matt = ds[input_variable].transpose('hologram_number','rsize','input_channels')\n",
    "    print(f\"\\ttrain_inputs_matt.shape:{train_inputs_matt.shape}\")    \n",
    "    \n",
    "    input_scaler_matt = ml.MinMaxScalerX(train_inputs_matt)\n",
    "    train_inputs_matt = input_scaler_matt.fit_transform(train_inputs_matt)\n",
    "    print(f\"\\ttrain_inputs_matt.shape:{train_inputs_matt.shape}\")\n",
    "\n",
    "    train_outputs_matt = ds[label_variable]\n",
    "    print(f\"\\ttrain_outputs_matt.shape:{train_outputs_matt.shape}\")\n",
    "   \n",
    "    output_scaler_matt = ml.MinMaxScalerX(train_outputs_matt)\n",
    "    train_outputs_matt = output_scaler_matt.fit_transform(train_outputs_matt)\n",
    "    print(f\"\\ttrain_outputs_matt.shape:{train_outputs_matt.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['histogram_validation_data_5000count20201009T085713.nc', 'histogram_test_data_5000count20201009T085713.nc', 'histogram_training_data_5000count20201009T085713.nc']\n",
      "Loading TRAINING dataset\n",
      "\ttrain_inputs.shape:(5000, 600, 1)\n",
      "\ttrain_inputs.shape:(5000, 600, 1)\n",
      "\ttrain_outputs.shape:(5000, 39, 1)\n",
      "\ttrain_outputs.shape:(5000, 39, 1)\n",
      "Loading VALIDATION dataset\n",
      "\tvalid_inputs.shape:(1000, 600, 1)\n",
      "\tvalid_inputs.shape:(1000, 600, 1)\n",
      "\tvalid_outputs.shape:(1000, 39, 1)\n",
      "\tvalid_outputs.shape:(1000, 39, 1)\n"
     ]
    }
   ],
   "source": [
    "path_data = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/ft_rad_bidis/\"\n",
    "\n",
    "fns = [x for x in os.listdir(path_data)]\n",
    "fn_train = [x for x in fns if 'training' in x][0]\n",
    "fn_valid = [x for x in fns if 'validation' in x][0]\n",
    "fn_test = [x for x in fns if 'test' in x][0]\n",
    "print(fns)\n",
    "\n",
    "with xr.open_dataset(path_data + fn_train, chunks={'hologram_number': batch_size}) as ds:\n",
    "    print(\"Loading TRAINING dataset\")\n",
    "\n",
    "    if len(ds[input_variable].dims) == 4:\n",
    "        train_inputs = ds[input_variable].transpose('hologram_number','xsize','ysize','input_channels')\n",
    "    elif len(ds[input_variable].dims) == 3:\n",
    "        train_inputs = ds[input_variable].transpose('hologram_number','rsize','input_channels')\n",
    "    print(f\"\\ttrain_inputs.shape:{train_inputs.shape}\")    \n",
    "    \n",
    "    input_scaler = ml.MinMaxScalerX(train_inputs)\n",
    "    train_inputs = input_scaler.fit_transform(train_inputs)\n",
    "    print(f\"\\ttrain_inputs.shape:{train_inputs.shape}\")\n",
    "\n",
    "    train_outputs = ds[label_variable]\n",
    "    print(f\"\\ttrain_outputs.shape:{train_outputs.shape}\")\n",
    "   \n",
    "    output_scaler = ml.MinMaxScalerX(train_outputs)\n",
    "    train_outputs = output_scaler.fit_transform(train_outputs)\n",
    "    print(f\"\\ttrain_outputs.shape:{train_outputs.shape}\")\n",
    "\n",
    "with xr.open_dataset(path_data+fn_valid, chunks={'hologram_number': batch_size}) as ds:\n",
    "    print(\"Loading VALIDATION dataset\")\n",
    "\n",
    "    if len(ds[input_variable].dims) == 4:\n",
    "        valid_inputs = ds[input_variable].transpose('hologram_number','xsize','ysize','input_channels')\n",
    "    elif len(ds[input_variable].dims) == 3:\n",
    "        valid_inputs = ds[input_variable].transpose('hologram_number','rsize','input_channels')\n",
    "    print(f\"\\tvalid_inputs.shape:{valid_inputs.shape}\")    \n",
    "    \n",
    "    input_scaler = ml.MinMaxScalerX(valid_inputs)\n",
    "    valid_inputs = input_scaler.fit_transform(valid_inputs)\n",
    "    print(f\"\\tvalid_inputs.shape:{valid_inputs.shape}\")\n",
    "\n",
    "    valid_outputs = ds[label_variable]\n",
    "    print(f\"\\tvalid_outputs.shape:{valid_outputs.shape}\")\n",
    "   \n",
    "    output_scaler = ml.MinMaxScalerX(valid_outputs)\n",
    "    valid_outputs = output_scaler.fit_transform(valid_outputs)\n",
    "    print(f\"\\tvalid_outputs.shape:{valid_outputs.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array_equal(train_inputs.values, train_inputs_matt.values))\n",
    "print(np.array_equal(train_outputs.values, train_outputs_matt.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/glade/p/cisl/aiml/ggantos/holodec/ft_rad_bidis/d/',\n",
       " '/glade/p/cisl/aiml/ggantos/holodec/ft_rad_bidis/z/',\n",
       " '/glade/p/cisl/aiml/ggantos/holodec/ft_rad_bidis/z_realimag/']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\"/glade/p/cisl/aiml/ggantos/holodec/ft_rad_bidis/d/\",\n",
    "          \"/glade/p/cisl/aiml/ggantos/holodec/ft_rad_bidis/z/\",\n",
    "          \"/glade/p/cisl/aiml/ggantos/holodec/ft_rad_bidis/z_realimag/\"]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_index = 11\n",
    "    \n",
    "model = models[0]\n",
    "model_name = \"diameter\"\n",
    "\n",
    "# var = 'z'\n",
    "# valid_outputs = np.squeeze(data_loaded['z_valid_outputs'].values) \n",
    "# bins = calc_bins(var)\n",
    "var = 'd'\n",
    "valid_outputs = np.squeeze(data_loaded['base_valid_outputs'].values) \n",
    "bins = calc_bins(var)[:-1]\n",
    "    \n",
    "bin_size = bins[1] - bins[0]\n",
    "\n",
    "train_outputs_pred = np.genfromtxt(os.path.join(model, \"train_outputs_pred.csv\"))\n",
    "valid_outputs_pred = np.genfromtxt(os.path.join(model, \"valid_outputs_pred.csv\"))\n",
    "\n",
    "loss = np.genfromtxt(os.path.join(model, \"loss.csv\"))\n",
    "val_loss = np.genfromtxt(os.path.join(model, \"val_loss.csv\"))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "axes[0].plot(loss)\n",
    "axes[0].plot(val_loss)\n",
    "axes[0].set_title(f'{model_name} loss')\n",
    "axes[0].set_ylabel('loss')\n",
    "axes[0].set_xlabel('epoch')\n",
    "axes[0].legend(['training', 'validation'], loc='upper left')\n",
    "\n",
    "axes[1].bar(bins / 1000, valid_outputs_pred[valid_index], bin_size / 1000, color='red', label=\"Predicted\")\n",
    "axes[1].bar(bins / 1000, valid_outputs[valid_index], bin_size / 1000, edgecolor='blue', facecolor=\"none\", lw=3, label=\"True\")\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].set_xlabel(f\"{var}-axis particle position (mm)\")\n",
    "axes[1].set_ylabel(f\"relative {var} distribtion\")\n",
    "axes[1].legend(loc=\"best\")\n",
    "\n",
    "axes[2].bar(bins / 1000, valid_outputs_pred.mean(axis=0), bin_size / 1000, color='red')\n",
    "axes[2].bar(bins / 1000, valid_outputs.mean(axis=0), bin_size / 1000, edgecolor='blue', facecolor=\"none\", lw=3)\n",
    "axes[2].set_xlabel(f\"{var} location (mm)\")\n",
    "axes[2].set_ylabel(f\"Mean {var} Distribution\")\n",
    "\n",
    "rps_nn = ranked_probability_score(valid_outputs, valid_outputs_pred)\n",
    "rps_climo = ranked_probability_score(valid_outputs, np.ones(valid_outputs_pred.shape) / valid_outputs_pred.shape[1])\n",
    "print(f\"RPS_nn: {rps_nn:0.3f}\", f\"RPS_climo: {rps_climo:0.3f}\")\n",
    "rpss = 1 - rps_nn / rps_climo\n",
    "print(f\"RPSS: {rpss:0.3f}\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
