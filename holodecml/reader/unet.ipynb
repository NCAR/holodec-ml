{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tqdm\n",
    "import time\n",
    "import yaml\n",
    "import torch\n",
    "import pickle\n",
    "import joblib\n",
    "import random\n",
    "import sklearn\n",
    "import logging\n",
    "import datetime\n",
    "import torch.fft\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "#torch.multiprocessing.set_start_method('spawn')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from collections import defaultdict\n",
    "from scipy.signal import convolve2d\n",
    "from torch.optim.lr_scheduler import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from typing import List, Dict, Callable, Union, Any, TypeVar, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the GPU device id, or CPU if no GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")\n",
    "\n",
    "if is_cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    #torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load all of the data into memory\n",
    "# images = []\n",
    "# labels = []\n",
    "# masks = []\n",
    "\n",
    "# loaded = 0\n",
    "# # when training, load 10k to 20k images at once\n",
    "# max_images = 10\n",
    "\n",
    "# start_time = time.time()\n",
    "# with open(\"/glade/work/schreck/repos/HOLO/holodec-ml/holodecml/reader/training_512x512_128_50000.pkl\", \"rb\") as fid:\n",
    "#     while True:\n",
    "        \n",
    "#         try:\n",
    "#             image, label, u_net_mask, image_tile_idx, image_tile_coors = pickle.load(fid)\n",
    "#             images.append(np.expand_dims(image, 0))\n",
    "#             labels.append(label)\n",
    "#             masks.append(np.expand_dims(u_net_mask, 0))\n",
    "            \n",
    "#             loaded += 1\n",
    "            \n",
    "#             if len(images) == max_images:\n",
    "#                 break\n",
    "            \n",
    "#         except Exception as E:\n",
    "#             break\n",
    "            \n",
    "# images = np.vstack(images)\n",
    "# labels = np.vstack(labels)\n",
    "# masks = np.vstack(masks)\n",
    "\n",
    "# end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"It took {end_time - start_time} s to load {loaded} (x,y) points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images.shape, labels.shape, masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indices = random.sample(list(range(images.shape[0])), 4 * images.shape[0] // 5)\n",
    "# test_indices = list(set(range(images.shape[0])) - set(train_indices))\n",
    "\n",
    "# X_train = images[train_indices]\n",
    "# X_test = images[test_indices]\n",
    "# y_train = masks[train_indices]\n",
    "# y_test = masks[test_indices]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HologramLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, fn, max_buffer_size = 5000, max_images = 40000, shuffle = True):\n",
    "        self.fn = fn\n",
    "        self.buffer = []\n",
    "        self.max_buffer_size = max_buffer_size\n",
    "        self.shuffle = shuffle\n",
    "        self.max_images = max_images\n",
    "            \n",
    "        self.fid = open(self.fn, \"rb\")\n",
    "        self.loaded = 0 \n",
    "        self.epoch = 0\n",
    "        \n",
    "    def __getitem__(self, idx):    \n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        try:\n",
    "            data = joblib.load(self.fid)\n",
    "            image, label, mask = data\n",
    "            image = torch.FloatTensor(image.squeeze(0))\n",
    "            #label = torch.LongTensor([label])\n",
    "            mask = torch.FloatTensor(mask.squeeze(0))\n",
    "            data = (image, mask)\n",
    "            \n",
    "            self.loaded += 1\n",
    "\n",
    "            if not self.shuffle:\n",
    "                return data\n",
    "            self.buffer.append(data)\n",
    "            random.shuffle(self.buffer)\n",
    "\n",
    "            if len(self.buffer) > self.max_buffer_size:\n",
    "                self.buffer = self.buffer[:self.max_buffer_size]\n",
    "                \n",
    "            if self.epoch > 0:\n",
    "                return self.buffer.pop()\n",
    "            \n",
    "            else: # wait until all data has been seen before sampling from the buffer\n",
    "                return data\n",
    "            \n",
    "\n",
    "        except EOFError:\n",
    "            self.fid = open(self.fn, \"rb\")\n",
    "            self.loaded = 0\n",
    "            return #raise StopIteration\n",
    "\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return self.max_images\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.loaded == self.__len__():\n",
    "            self.fid = open(self.fn, \"rb\")\n",
    "            self.loaded = 0\n",
    "            self.epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the binary model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3)\n",
    "    def forward(self, x):\n",
    "        return self.conv2(self.relu(self.conv1(x)))\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs=(3,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "        self.pool       = nn.MaxPool2d(2)\n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return ftrs\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs=(1024, 512, 256, 128, 64)):\n",
    "        super().__init__()\n",
    "        self.chs         = chs\n",
    "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
    "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "    def forward(self, x, encoder_features):\n",
    "        for i in range(len(self.chs)-1):\n",
    "            x        = self.upconvs[i](x)\n",
    "            enc_ftrs = self.crop(encoder_features[i], x)\n",
    "            x        = torch.cat([x, enc_ftrs], dim=1)\n",
    "            x        = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    def crop(self, enc_ftrs, x):\n",
    "        _, _, H, W = x.shape\n",
    "        enc_ftrs   = torchvision.transforms.CenterCrop([H, W])(enc_ftrs)\n",
    "        return enc_ftrs\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 enc_chs=(2, 64, 128, 256, 512, 1024),\n",
    "                 dec_chs=(1024, 512, 256, 128, 64),\n",
    "                 num_class=1,\n",
    "                 retain_dim=False, out_sz=(572,572)):\n",
    "        super().__init__()\n",
    "        self.encoder     = Encoder(enc_chs)\n",
    "        self.decoder     = Decoder(dec_chs)\n",
    "        self.head        = nn.Conv2d(dec_chs[-1], num_class, 1)\n",
    "        self.retain_dim  = retain_dim\n",
    "        self.out_sz = out_sz\n",
    "    def forward(self, x):\n",
    "        enc_ftrs = self.encoder(x)\n",
    "        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
    "        out      = self.head(out)\n",
    "        if self.retain_dim:\n",
    "            out = F.interpolate(out, self.out_sz)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_train = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/tiled_synthetic/training_512x512_128_40000.pkl\"\n",
    "fn_valid = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/tiled_synthetic/validation_512x512_128_10000.pkl\"\n",
    "\n",
    "epochs = 200\n",
    "train_batch_size = 32\n",
    "valid_batch_size = 32\n",
    "batches_per_epoch = 100\n",
    "\n",
    "stopping_patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = torch.utils.data.TensorDataset(\n",
    "#     torch.from_numpy(X_train), \n",
    "#     torch.from_numpy(y_train)\n",
    "# )\n",
    "\n",
    "# test_dataset = torch.utils.data.TensorDataset(\n",
    "#     torch.from_numpy(X_test), \n",
    "#     torch.from_numpy(y_test)\n",
    "# )\n",
    "\n",
    "train_dataset = HologramLoader(\n",
    "    fn_train, \n",
    "    max_images = 40000, \n",
    "    max_buffer_size = 5000, \n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_dataset = HologramLoader(\n",
    "    fn_valid, \n",
    "    max_images = 10000, \n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size, \n",
    "    num_workers=8, # can increase to number of CPUs you asked for in launch script; usually 8\n",
    "    pin_memory=True,\n",
    "    shuffle=False) # let the reader do the shuffling\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=valid_batch_size,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_dim = True\n",
    "mask_size = (512,512)\n",
    "\n",
    "unet = UNet(\n",
    "    retain_dim = retain_dim,\n",
    "    out_sz = mask_size\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-04\n",
    "weight_decay = 0.0\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    unet.parameters(), \n",
    "    lr=learning_rate, \n",
    "    weight_decay=weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_criterion = torch.nn.SmoothL1Loss() # Huber (MSE, but once converges, MAE)\n",
    "test_criterion = torch.nn.L1Loss() # MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    patience = 1, \n",
    "    min_lr = 1.0e-10,\n",
    "    verbose = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 train_loss: 0.5359 lr: 0.000100000000:  10%|█         | 10/100 [00:26<03:58,  2.65s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-81afe3665ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# get gradients w.r.t to parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_test_losses = []\n",
    "results_dict = defaultdict(list)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    ### Train the model \n",
    "    unet.train()\n",
    "\n",
    "    batch_loss = []\n",
    "        \n",
    "    # set up a custom tqdm\n",
    "    batch_group_generator = tqdm.tqdm(\n",
    "        enumerate(train_loader), \n",
    "        total=batches_per_epoch,\n",
    "        leave=True\n",
    "    )\n",
    " \n",
    "    for k, (inputs, y) in batch_group_generator:\n",
    "        \n",
    "        # Move data to the GPU, if not there already\n",
    "        inputs = inputs.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        \n",
    "        # Clear gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output from the model, given the inputs\n",
    "        pred_mask = unet(inputs)\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        loss = train_criterion(pred_mask, y)\n",
    "                \n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # update tqdm\n",
    "        to_print = \"Epoch {} train_loss: {:.4f}\".format(epoch, np.mean(batch_loss))\n",
    "        to_print += \" lr: {:.12f}\".format(optimizer.param_groups[0]['lr'])\n",
    "        batch_group_generator.set_description(to_print)\n",
    "        batch_group_generator.update()\n",
    "                     \n",
    "        # stop the training epoch when train_batches_per_epoch have been used to update \n",
    "        # the weights to the model\n",
    "        if k >= batches_per_epoch and k > 0:\n",
    "            break\n",
    "            \n",
    "        #lr_scheduler.step(epoch + k / batches_per_epoch)\n",
    "        \n",
    "    # Compuate final performance metrics before doing validation\n",
    "    train_loss = np.mean(batch_loss)\n",
    "        \n",
    "    # clear the cached memory from the gpu\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ### Test the model \n",
    "    unet.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        batch_loss = []\n",
    "        \n",
    "        # set up a custom tqdm\n",
    "        batch_group_generator = tqdm.tqdm(\n",
    "            enumerate(train_loader),\n",
    "            leave=True\n",
    "        )\n",
    "\n",
    "        for k, (inputs, y) in batch_group_generator:\n",
    "            # Move data to the GPU, if not there already\n",
    "            inputs = inputs.to(device).float()\n",
    "            y = y.to(device).long()\n",
    "            # get output from the model, given the inputs\n",
    "            pred_mask = unet(inputs)\n",
    "            # get loss for the predicted output\n",
    "            loss = test_criterion(pred_mask, y)\n",
    "            batch_loss.append(loss.item())\n",
    "            # update tqdm\n",
    "            to_print = \"Epoch {} test_loss: {:.4f}\".format(epoch, np.mean(batch_loss))\n",
    "            batch_group_generator.set_description(to_print)\n",
    "            batch_group_generator.update()\n",
    "\n",
    "    # Use the accuracy as the performance metric to toggle learning rate and early stopping\n",
    "    test_loss = np.mean(batch_loss)\n",
    "    epoch_test_losses.append(test_loss)\n",
    "    \n",
    "    # Lower the learning rate if we are not improving\n",
    "    lr_scheduler.step(test_loss)\n",
    "\n",
    "    # Save the model if its the best so far.\n",
    "    if test_loss == min(epoch_test_losses):\n",
    "        state_dict = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': unet.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': test_loss\n",
    "        }\n",
    "        #TODO: add directory\n",
    "        torch.save(state_dict, \"best_unet.pt\")\n",
    "        \n",
    "    # Get the last learning rate\n",
    "    learning_rate = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "    # Put things into a results dictionary -> dataframe\n",
    "    results_dict['epoch'].append(epoch)\n",
    "    results_dict['train_loss'].append(train_loss)\n",
    "    results_dict['valid_loss'].append(np.mean(batch_loss))\n",
    "    results_dict[\"learning_rate\"].append(learning_rate)\n",
    "    df = pd.DataFrame.from_dict(results_dict).reset_index()\n",
    "\n",
    "    # Save the dataframe to disk\n",
    "    #TODO: add directory\n",
    "    df.to_csv(\"training_log_unet.csv\", index = False)\n",
    "        \n",
    "    # Stop training if we have not improved after X epochs (stopping patience)\n",
    "    best_epoch = [i for i,j in enumerate(epoch_test_losses) if j == min(epoch_test_losses)][0]\n",
    "    offset = epoch - best_epoch\n",
    "    if offset >= stopping_patience:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
